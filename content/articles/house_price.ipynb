{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data exploration is important. Before jumping into analysis, you will get some intuition as to how to use data and establish more sophisticated modeling. In some cases, how to use data improve even models robust to high dimensional input like Deep Learning. In this article, we work on data exploration and visualization for the house price data from [a kaggle competition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data). This gives effective features selection, which has better performance than random feature selection. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "House prices are determined through various factors such as location, quality, and size. Before jumping into analysis, we explore given data. Our data exploration process is divided into a few steps:\n",
    "\n",
    "1. Understand the Problem:\n",
    "Figure out characteristics of given data and the meaning of each feature \n",
    "\n",
    "2. Univariate Study:\n",
    "Focus on understanding the characteristic of target value, 'SalePrice'. \n",
    "\n",
    "3. Multivariate Study:\n",
    "Explore the relations among input features and target value. \n",
    "\n",
    "4. Feature Selection:\n",
    "Determine which features have to be employed as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understand the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we look into basic information of given data. We have two kinds of data: train data and test data. Train data and test data have 1460 and 1459 candidates respectively. While both have 80 input features, target value, 'SalePrice', is given to train data additionally; i.e., shapes of train and test data are (1460, 81) and (1459, 80) respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we consider classifying input features into a few categories. In given data, we have the following features:\n",
    "\n",
    "\n",
    "'Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
    "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
    "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
    "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
    "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
    "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
    "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
    "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
    "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
    "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
    "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
    "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
    "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
    "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
    "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
    "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
    "       'SaleCondition'\n",
    "\n",
    "When considering purchasing a house, what comes into your mind first is the location. Convenience of access to your workplace or school is one of the most important factors. Next, we may consider the size. If you have your family in your house, you may need larger house. Finally, we consider the quality. The higher quality, the more expensive. Considering above, we divide input features into three categories: location, size, and quality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location:\n",
    "    'Neighborhood', 'Condition1', 'Condition2'\n",
    "    \n",
    "### Size:\n",
    "    'LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtUnfSF', 'TotalBsmtSF', \n",
    "    'BsmtFinSF1', 'BsmtFinSF2', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
    "    'GrLivArea', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
    "    'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea'\n",
    "\n",
    "### Quality:\n",
    "    'MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour',\n",
    "    'Utilities', 'LotConfig', 'LandSlope',  'BldgType', 'HouseStyle', \n",
    "    'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle',\n",
    "    'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', \n",
    "    'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
    "    'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir',\n",
    "    'Electrical',  'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', \n",
    "    'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n",
    "    'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType', 'GarageYrBlt',\n",
    "    'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC',\n",
    "    'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
    "    'SaleCondition', 'SalePrice'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than above categorization, we have to consider types of data. Given data has two kinds: numerical and categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numerical = [x for x in df_train.columns if df_train.dtypes[x]!='object']\n",
    "# index is used instead of Id to identify an element\n",
    "numerical.remove('Id')\n",
    "numerical.remove('SalePrice')\n",
    "\n",
    "categorical = [x for x in df_train.columns if df_train.dtypes[x]=='object']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical:\n",
    "'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType', 'SaleCondition'\n",
    "\n",
    "\n",
    "### Categorical:\n",
    "'MSZoning', 'LotFrontage', 'Street', 'Alley', 'LotShape', 'LandContour',\n",
    "'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1',\n",
    "'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl',\n",
    "'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual',\n",
    "'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
    "'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir',\n",
    "'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType',\n",
    "'GarageYrBlt', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive',\n",
    "'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Univariate Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider characteristics of target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df_train['SalePrice']\n",
    "sns.distplot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![y_dist]({filename}/images/house_price/y_dist.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure describes the distribution of target variable. It does not look like a normal distribution and seems to have heavy tail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(y.skew())\n",
    "print(y.kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skew and kurtosis of the distribution are 1.88 and 6.54 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "stats.probplot(y, plot=plt, dist='norm', fit=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![y_probplot]({filename}/images/house_price/y_probplot.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure is probaility plot. Considering skew, kurtosis, and probability plot, we conclude that the distribution is not nomral distribution. Let's try a transform of the target variable with log(x). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats.probplot(np.log(y), plot=plt, dist='norm', fit=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logy_probplot]({filename}/images/house_price/logy_probplot.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(np.log(y).skew())\n",
    "print(np.log(y).kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did it!\n",
    "\n",
    "Given data seem to be on the line in the probability plot. Skew and kurtosis are 0.12 and 0.81 respectively. These facts imply that the target data spread with a normal distribution. In many cases, quadratic cost functions assume the gaussian noise, which gives you the normal distribution. Therefore, the transformed target variable is more convenient when working on optimization. \n",
    "\n",
    "From now on, we use log(y) instead of y as a target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['SalePrice'] = np.log(df_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While some features have significant effects on the behavior SalePrice, otheres do not. In this section, we work on figuring relations between variables. \n",
    "\n",
    "Before working on analysis, we have to deal with missing data. Let's roll!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total = df_train.isnull().sum().sort_values(ascending=False)\n",
    "total[:10].plot(kind='bar')\n",
    "plt.title('The Number of Misssing Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![missing]({filename}/images/house_price/missing.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of candidates are missing top 3 features: PoolQC, MscFeature, and Alley. This may come from the fact that we do not care about these features when buying a house; e.g., we do not determine to purchase a house just because of the quality of pool (PoolQC). \n",
    "\n",
    "For the sake of simplicity, we just treat these missing values as a new category 'MISSING' for category variables. For numerical variables, we use mean imputation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imp = Imputer()\n",
    "for c in numerical:\n",
    "    if df_train[c].isnull().any():\n",
    "        df_train[c] = imp.fit_transform(df_train[c].values[:, np.newaxis])[:, 0]\n",
    "\n",
    "for c in categorical:\n",
    "    df_train[c] = df_train[c].astype('category')\n",
    "    if df_train[c].isnull().any():\n",
    "        df_train[c] = df_train[c].cat.add_categories(['MISSING'])\n",
    "        df_train[c] = df_train[c].fillna('MISSING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze categorial variables along with numerical variables, we convert categorical variables into dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yx_data = df_train[['SalePrice', ] + numerical + categorical]\n",
    "yx_data = pd.get_dummies(yx_data)\n",
    "\n",
    "corrmat = yx_data.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "sns.heatmap(corrmat);\n",
    "plt.title('Correlation Coefficient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![corr_dummies]({filename}/images/house_price/corr_dummies.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops! Too many columns! \n",
    "We consider reducing the number of features to a subset of features strongly correlated with the target variable. \n",
    "\n",
    "We here use 20 features. We extract 20 features that have the largest abolute value of correlation coefficient with the target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abs_corrmat = corrmat.copy()\n",
    "abs_corrmat = abs_corrmat.set_value(\n",
    "        index=corrmat.index, \n",
    "        col=corrmat.columns, \n",
    "        value=np.abs(corrmat.values)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick up only higly correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "large_cols = abs_corrmat.nlargest(20, 'SalePrice')['SalePrice'].index\n",
    "large_corrmat = corrmat.loc[large_cols, large_cols]\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "sns.heatmap(large_corrmat, square=True, \n",
    "                       annot=True, cbar=True, fmt='.2f', \n",
    "                       xticklabels=large_cols.values, \n",
    "                       yticklabels=large_cols.values);\n",
    "plt.title('Correlation Coefficient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![20corr]({filename}/images/house_price/20corr.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are strong correlations in the following pairs: (GarageArea, GarageCars), (TotalBsmtSF, 1stFlrSF), (ExterQual_Gd, ExterQual_TA), (GarageYrBuilt, YearBuilt), and (TotRmsAbvTrd, GrLivArea).  In the first pair, both express the size of garage. The second one describes the area of basement and first floor. The third one is separated just because of introducing dummy. Both elements in the fourth one explain how old. In the last one, each element expresses living area and total rooms. In any of the above five pairs, it is natural that two elements are correlated to each other within each pair. Therefore, it is good enough to use either of two elements for each pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_cols = ['GarageCars', '1stFlrSF', 'ExterQual_TA', \n",
    "                            'GrLivArea', 'GarageYrBlt']\n",
    "for x in remove_cols:\n",
    "    large_cols = large_cols.drop(x)\n",
    "\n",
    "large_corrmat = corrmat.loc[large_cols, large_cols]\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "sns.heatmap(large_corrmat, square=True, \n",
    "                       annot=True, cbar=True, fmt='.2f', \n",
    "                       xticklabels=large_cols.values, \n",
    "                       yticklabels=large_cols.values);\n",
    "plt.title('Correlation Coefficient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![15corr]({filename}/images/house_price/15corr.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see more precise relations between the target variable and selected features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract only feature name and avoid duplication\n",
    "large_cat = list(set([x.split('_')[0] for x in large_cols.values if '_' in x]))\n",
    "large_num = [x.split('_')[0] for x in large_cols.values if '_' not in x]\n",
    "# make figures for YearBuilt and OverallQual seperately\n",
    "large_num.remove('OverallQual')\n",
    "large_num.remove('YearBuilt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.boxplot(x=df_train['OverallQual'], y=df_train['SalePrice']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![overallqual]({filename}/images/house_price/overallqual.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we expected, the more OverallQual, the higher SalePrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12,  6))\n",
    "sns.boxplot(x=df_train['YearBuilt'], y=df_train['SalePrice']);\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![yearbuilt]({filename}/images/house_price/yearbuilt.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a tendency that newer houses have higher prices. Let's see the effects of other categorical variables on the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "melted_train = pd.melt(df_train, id_vars=['SalePrice'], value_vars=large_cat)\n",
    "\n",
    "def boxplot(x, y, **kwargs):\n",
    "    sns.boxplot(x=x, y=y)\n",
    "    plt.xticks(rotation=90);\n",
    "    \n",
    "g = sns.FacetGrid(melted_train, col='variable', col_wrap=3, \n",
    "                               sharex=False, sharey=False)\n",
    "g.map(boxplot, 'value', 'SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![categorical]({filename}/images/house_price/categorical.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df_train[large_num], size=1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![numerical]({filename}/images/house_price/numerical.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the top raw. Generally speaking, the larger value feature tend to have higer prices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have been analyzing the relation through correlation coefficient and visualization. Random forest work as an alternative method to figure out the relations. Indeed, random forest is one of the most popular methods to select important features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_full = yx_data[yx_data.columns.drop('SalePrice')]\n",
    "y, X = df_train['SalePrice'].values[:, np.newaxis], X_full.values\n",
    "clf = RandomForestRegressor(n_estimators=100)\n",
    "clf.fit(X, y)\n",
    "\n",
    "importance = clf.feature_importances_\n",
    "argidx = np.argsort(importance)[::-1]\n",
    "df_importance = pd.DataFrame(importance[argidx[:20]],\n",
    "                                                       index=yx_data.columns.values[argidx[:20]])\n",
    "imp_cols = yx_data.columns.values[argidx][:20]\n",
    "df_importance.plot(kind='bar');\n",
    "plt.title('Feature Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![importance]({filename}/images/house_price/importance.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure describes the 20 features with the largest feature of importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features selected Through correlation coefficient are\n",
    "\n",
    "'LotArea', 'LowQualFinSF', 'BsmtUnfSF', 'GarageCars', 'GarageYrBlt',\n",
    "'MasVnrArea', 'TotalBsmtSF', 'OverallCond', 'HeatingQC_TA',\n",
    "'OverallQual', 'CentralAir_N', 'LotFrontage', '1stFlrSF',\n",
    "'YearBuilt', 'BsmtFinSF2', 'GarageType_CarPort', 'MSSubClass',\n",
    "'TotRmsAbvGrd', 'MSZoning_RL', 'WoodDeckSF'\n",
    "\n",
    "In the feature of importance, selected features are \n",
    "\n",
    "'SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea',\n",
    "'TotalBsmtSF', '1stFlrSF', 'ExterQual_TA', 'FullBath', 'YearBuilt',\n",
    "'YearRemodAdd', 'KitchenQual_TA', 'TotRmsAbvGrd', 'Foundation_PConc',\n",
    "'FireplaceQu_MISSING', 'ExterQual_Gd', 'GarageYrBlt', 'Fireplaces',\n",
    "'BsmtQual_TA', 'HeatingQC_Ex'\n",
    "\n",
    "They share the following features:\n",
    "\n",
    "'1stFlrSF', 'GarageCars', 'GarageYrBlt', 'OverallQual', 'TotRmsAbvGrd', 'TotalBsmtSF', 'YearBuilt'\n",
    "\n",
    "0nly 7 features are shared. Besides that, the feature with the largest importance, 'LotArea' is not even selected as top 20 through correlation coefficient. Let's compare the performances through linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error(y, y_pred):\n",
    "    return np.mean((y - y_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(5)\n",
    "\n",
    "y, X =yx_data['SalePrice'], yx_data[large_cols]\n",
    "\n",
    "error_lr = []\n",
    "for train, test in kf.split(X.values):\n",
    "    X_train, X_test = X.values[train], X.values[test]\n",
    "    y_train, y_test = y.values[train], y.values[test]\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train[:, np.newaxis])\n",
    "    y_pred = lr.predict(X_test)[:, 0]\n",
    "    error_lr.append(error(y_test, y_pred))\n",
    "error_lr = np.mean(error_lr)\n",
    "    \n",
    "y, X =yx_data['SalePrice'], yx_data[imp_cols]\n",
    "    \n",
    "error_rf = []\n",
    "for train, test in kf.split(X.values):\n",
    "    X_train, X_test = X.values[train], X.values[test]\n",
    "    y_train, y_test = y.values[train], y.values[test]\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    error_rf.append(error(y_test, y_pred))\n",
    "error_rf = np.mean(error_rf)\n",
    "\n",
    "index = np.arange(len(yx_data.columns))\n",
    "np.random.shuffle(index)\n",
    "random_cols = yx_data.columns[index[:20]]\n",
    "y, X =yx_data['SalePrice'], yx_data[random_cols]\n",
    "    \n",
    "error_random = []\n",
    "for train, test in kf.split(X.values):\n",
    "    X_train, X_test = X.values[train], X.values[test]\n",
    "    y_train, y_test = y.values[train], y.values[test]\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    error_random.append(error(y_test, y_pred))\n",
    "error_random = np.mean(error_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Method</th>\n",
    "    <th>Error</th> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Correlation Coefficient</td>\n",
    "    <td>0.0299</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Random Forest</td>\n",
    "    <td>0.0300</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Random</td>\n",
    "    <td>0.0935</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above figure is the cross validation of squared error with 20 features chosen by the following methods: correlation coefficient, random forest, and random.  The first two methods have been discussed so far. Random means here choosing 20 features at random. First two methods have way better results than the random one. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
