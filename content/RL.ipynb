{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reinforcement learning is one of categories of machine learning method along with unsupervised and supervised learning. In this frame work, we use reward. Maximizing sumation of rewards is set as the main goal, i.e., finding mapping from givne input data to actions that maximize rewards. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we cound not fetch data from the following companies\n",
      "['ABBV', 'ALLE', 'CFG', 'COTY', 'CSRA', 'EVHC', 'FB', 'FTV', 'HPE', 'KHC', 'MNK', 'NAVI', 'NWSA', 'NWS', 'NEE', 'PYPL', 'PSX', 'QRVO', 'SYF', 'UA', 'WRK', 'WLTW', 'ZTS']\n",
      "CPU times: user 10.6 s, sys: 1.2 s, total: 11.8 s\n",
      "Wall time: 9min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "symbols = utils.get_sap_symbols('sap500')\n",
    "start_date=\"2012-01-01\"\n",
    "end_date=\"2017-01-01\"\n",
    "# use Open data\n",
    "input_data = utils.get_data_list_key(symbols, start_date, end_date, key='Volume')\n",
    "target_data = utils.get_data('^OEX', start_date, end_date)['Open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1240, 482)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vol = np.mean(input_data.values, axis=0)\n",
    "notsym = ['ABBV', 'ALLE', 'CFG', 'COTY', 'CSRA', 'EVHC', 'FB', 'FTV', 'HPE', 'KHC', 'MNK', 'NAVI', 'NWSA', 'NWS', 'NEE', 'PYPL', 'PSX', 'QRVO', 'SYF', 'UA', 'WRK', 'WLTW', 'ZTS']\n",
    "symbols = [s for s in symbols if s not in notsym]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "symvol = zip(symbols, vol)\n",
    "symvol = sorted(symvol, key=lambda x: x[1], reverse=True)\n",
    "chosen_symbol = [x[0] for x in symvol[:10]]\n",
    "chosen_volume = [x[1] for x in symvol[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdMAAAHXCAYAAADnb7C7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1216ae4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.arange(len(chosen_symbol))  \n",
    "height = 0.5\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[5,5])\n",
    "_ = ax.barh(idx, chosen_volume[::-1], height)\n",
    "\n",
    "# add some text for labels, title and axes ticks\n",
    "ax.set_xlabel('Volume')\n",
    "ax.set_title('The 50 biggest volume companies')\n",
    "ax.set_yticks(idx + height)\n",
    "_ = ax.set_yticklabels(chosen_symbol[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chosen_symbol = ['BAC', 'AAPL', 'GE', 'MSFT', 'F', 'CSCO', 'INTC', 'HPQ', 'PFE', 'MU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BAC', 'AAPL', 'GE', 'MSFT', 'F', 'CSCO', 'INTC', 'HPQ', 'PFE', 'MU']\n"
     ]
    }
   ],
   "source": [
    "print(chosen_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 612 ms, sys: 40 ms, total: 652 ms\n",
      "Wall time: 8.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "st = time.time()\n",
    "symbols = utils.get_sap_symbols('sap500')\n",
    "start_date=\"2012-01-01\"\n",
    "end_date=\"2017-01-01\"\n",
    "# use Open data\n",
    "input_data = utils.get_data_list_key(chosen_symbol, start_date, end_date)\n",
    "target_data = utils.get_data('^OEX', start_date, end_date)['Open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque, namedtuple\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "\n",
    "Experiecne = namedtuple('Experience', 'state0,  action, reward, state1')\n",
    "\n",
    "class RingBuffer(object):\n",
    "    def __init__(self, maxlen):\n",
    "        self.maxlen = maxlen\n",
    "        self.start = 0\n",
    "        self.length = 0\n",
    "        # self.data = [None for _ in range(maxlen)]\n",
    "        self.data = []\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx< 0 or idx >= self.length:\n",
    "            raise KeyError()\n",
    "        return self.data[(self.start + idx) % self.maxlen]\n",
    "    \n",
    "    def append(self, v):\n",
    "        if self.length < self.maxlen:\n",
    "            # We have space, simply increase the length\n",
    "            self.length += 1\n",
    "        elif self.length == self.maxlen:\n",
    "            # No space, \"remove\" the first item\n",
    "            self.data[:-1] = self.data[1:]\n",
    "        else:\n",
    "            # This should never happen\n",
    "            raise RuntimeError()\n",
    "        self.data.append(v)\n",
    "        \n",
    "class SequentialMemory(object):\n",
    "    def __init__(self, limit=1000):\n",
    "        self.limit = limit\n",
    "        self.priority = []\n",
    "        self.actions = RingBuffer(limit)\n",
    "        self.rewards = RingBuffer(limit)\n",
    "        self.observations = RingBuffer(limit)\n",
    "        self.batch_idx = None\n",
    "\n",
    "        \n",
    "    def sample(self, batch_size, window_length, alpha=1.0, beta=1.0, epsilon=0.05):\n",
    "        # udpate priority when sampling\n",
    "        if len(self.priority) > self.limit:\n",
    "            self.priority = self.priority[-self.limit:]\n",
    "        # draw random indexes such that is bigger than window_length to enough length data\n",
    "        index_space = np.arange(window_length, self.nb_entries)\n",
    "        # prioritized sample\n",
    "        p = np.array(self.priority)[window_length:]\n",
    "        p_tilde = p + np.ones(self.nb_entries - window_length) * np.mean(p) * epsilon\n",
    "        p_tilde[-1] = np.mean(p)\n",
    "        p_tilde = p_tilde ** alpha\n",
    "        p_tilde = p_tilde / np.sum(p_tilde)\n",
    "        batch_idx = choice(index_space, p=p_tilde, size=batch_size - 1)\n",
    "        # take the newest data\n",
    "        batch_idx = np.concatenate((batch_idx, [self.nb_entries - 1]))\n",
    "        assert len(batch_idx) == batch_size\n",
    "        # keep batch_idx to update pritority\n",
    "        self.batch_idx = batch_idx\n",
    "        \n",
    "        # weights to modify biased update\n",
    "        weights = 1. / (p_tilde**beta)\n",
    "        weights = weights / np.max(weights)\n",
    "        ret_w = weights[batch_idx - window_length]\n",
    "        \n",
    "        # create experiences\n",
    "        state0 = np.array([[self.observations[i] for i in range(idx - window_length,idx)] for idx in batch_idx])\n",
    "        action = np.array([self.actions[idx - 1] for idx in batch_idx])\n",
    "        reward = np.array([self.rewards[idx - 1] for idx in batch_idx])\n",
    "        state1 = np.array([[self.observations[i] for i in range(idx - window_length + 1,idx + 1)] for idx in batch_idx])\n",
    "        return Experiecne(state0, action, reward, state1), ret_w\n",
    "    \n",
    "    def sample_state(self, batch_size, window_length, alpha=0.5, epsilon=0.05):\n",
    "        # udpate priority when sampling\n",
    "        if len(self.priority) > self.limit:\n",
    "            self.priority = self.priority[-self.limit:]\n",
    "        # draw random indexes such that is bigger than window_length to enough length data\n",
    "        index_space = np.arange(window_length, self.nb_entries)\n",
    "        # prioritized sample\n",
    "        p = np.array(self.priority)[window_length:]\n",
    "        p_tilde = p + np.ones(self.nb_entries - window_length) * np.mean(p) * epsilon\n",
    "        p_tilde[-1] = np.mean(p)\n",
    "        p_tilde = p_tilde ** alpha\n",
    "        p_tilde = p_tilde / np.sum(p_tilde)\n",
    "        batch_idx = choice(index_space, p=p_tilde, size=batch_size - 1)\n",
    "        # take the newest data\n",
    "        batch_idx = np.concatenate((batch_idx, [self.nb_entries]))\n",
    "        assert len(batch_idx) == batch_size\n",
    "        \n",
    "        # create experiences\n",
    "        state = np.array([[self.observations[i] for i in range(idx - window_length,idx)] for idx in batch_idx])\n",
    "        return state\n",
    "    \n",
    "    def sample_state_uniform(self, batch_size, window_length):\n",
    "        # draw random indexes such that is bigger than window_length to enough length data\n",
    "        batch_idx = np.random.random_integers(window_length, self.nb_entries - 1, size=batch_size - 1)\n",
    "        # take the newest data\n",
    "        batch_idx = np.concatenate((batch_idx, [self.nb_entries]))\n",
    "        assert len(batch_idx) == batch_size\n",
    "        \n",
    "        # create experiences\n",
    "        state = np.array([[self.observations[i] for i in range(idx - window_length, idx)] for idx in batch_idx])\n",
    "        return state\n",
    "    \n",
    "    def update_priority(self,error):\n",
    "        for idx, i in enumerate(self.batch_idx):\n",
    "            self.priority[i] = error[idx]\n",
    "    \n",
    "    \n",
    "    def append(self, observation, action, reward):\n",
    "        self.observations.append(observation)\n",
    "        self.actions.append(action)\n",
    "        self.rewards.append(reward)\n",
    "        # initialize new sample with 1\n",
    "        self.priority.append(1.0)\n",
    "    \n",
    "    @property\n",
    "    def nb_entries(self):\n",
    "        return  len(self.observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D \n",
    "from keras.layers.core import Flatten, Lambda\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.engine.topology import Merge\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers import SpatialDropout2D\n",
    "from keras.layers import Dropout\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "# local library\n",
    "from memory import SequentialMemory\n",
    "\n",
    "class DDPG(object):\n",
    "    \"\"\"Deep Deterministic Poilicy Gradient\n",
    "    \n",
    "    Basend on DDPG and Multiscale CNN, seek out \n",
    "    optimal strategy for stock trading.\n",
    "    \n",
    "    Available function\n",
    "    - build_model: build network based on tensorflow and keras\n",
    "    - train: given DateFrame stock data, train network\n",
    "    - predict_action: givne DataFrame stock data, return optimal protfolio\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        \"\"\"initialized approximate value function\n",
    "        \n",
    "        config should have the following attributes\n",
    "        \n",
    "        Args:\n",
    "            device: the device to use computation, e.g. '/gpu:0'\n",
    "            gamma(float): the decay rate for value at RL\n",
    "            history_length(int): input_length for each scale at CNN\n",
    "            n_feature(int): the number of type of input \n",
    "                (e.g. the number of company to use at stock trading)\n",
    "            trade_stock_idx(int): trading stock index\n",
    "            gam (float): discount factor\n",
    "            n_history(int): the nubmer of history that will be used as input\n",
    "            n_smooth, n_down(int): the number of smoothed and down sampling input at CNN\n",
    "            k_w(int): the size of filter at CNN\n",
    "            n_hidden(int): the size of fully connected layer\n",
    "            n_batch(int): the size of mini batch\n",
    "            n_epochs(int): the training epoch for each time\n",
    "            update_rate (0, 1): parameter for soft update\n",
    "            learning_rate(float): learning rate for SGD\n",
    "            memory_length(int): the length of Replay Memory\n",
    "            n_memory(int): the number of different Replay Memories\n",
    "            alpha, beta: [0, 1] parameters for Prioritized Replay Memories\n",
    "            action_scale(float): the scale of initialized ation\n",
    "        \"\"\"\n",
    "        self.device = config.device\n",
    "        self.save_path = config.save_path\n",
    "        self.is_load = config.is_load\n",
    "        self.gamma = config.gamma\n",
    "        self.history_length = config.history_length\n",
    "        self.n_stock = config.n_stock\n",
    "        self.n_smooth = config.n_smooth\n",
    "        self.n_down = config.n_down\n",
    "        self.n_batch = config.n_batch\n",
    "        self.n_epoch = config.n_epoch\n",
    "        self.update_rate = config.update_rate\n",
    "        self.alpha = config.alpha\n",
    "        self.beta = config.beta\n",
    "        self.lr = config.learning_rate\n",
    "        self.memory_length = config.memory_length\n",
    "        self.n_memory = config.n_memory\n",
    "        self.noise_scale = config.noise_scale\n",
    "        self.model_config = config.model_config\n",
    "        # the length of the data as input\n",
    "        self.n_history = max(self.n_smooth + self.history_length, (self.n_down + 1) * self.history_length)\n",
    "        print (\"building model....\")\n",
    "        # have compatibility with new tensorflow\n",
    "        tf.python.control_flow_ops = tf\n",
    "        # avoid creating _LEARNING_PHASE outside the network\n",
    "        K.clear_session()\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\n",
    "        K.set_session(self.sess)\n",
    "        with self.sess.as_default():\n",
    "            with tf.device(self.device):\n",
    "                self.build_model()\n",
    "        print('finished building model!')\n",
    "    \n",
    "    def train(self, input_data):\n",
    "        self.max_action = 100\n",
    "        \"\"\"training DDPG, where action is confined to integer space\n",
    "        \n",
    "        Args:\n",
    "            data (DataFrame): stock price for self.n_feature companies\n",
    "        \"\"\"\n",
    "        stock_data = input_data.values\n",
    "        date = input_data.index\n",
    "        T = len(stock_data)\n",
    "        \n",
    "        # frequency for output\n",
    "        print_freq = int(T / 10)\n",
    "        if print_freq == 0:\n",
    "            print_freq = 1\n",
    "        print_freq = 1\n",
    "            \n",
    "        print (\"training....\")\n",
    "        st = time.time()\n",
    "        # prioritizomg parameter\n",
    "        db = (1 - self.beta) / 1000\n",
    "        \n",
    "        # result for return value\n",
    "        values = []\n",
    "        date_label = []\n",
    "        value = 0\n",
    "        values.append(value)\n",
    "        date_label.append(date[0])\n",
    "        # keep half an year data \n",
    "        t0 = self.n_history + self.n_batch\n",
    "        self.initialize_memory(stock_data[:t0])\n",
    "        plot_freq = 10\n",
    "        save_freq = 100000\n",
    "        count = 0\n",
    "        for t in range(t0, T - 1):\n",
    "            self.update_memory(stock_data[t], stock_data[t+1])\n",
    "            reward = self.take_action(stock_data[t], stock_data[t+1])\n",
    "            value += reward\n",
    "            date_label.append(date[t+1])\n",
    "            values.append(value)\n",
    "            count += 1\n",
    "            for epoch in range(self.n_epoch):    \n",
    "                # select transition from pool\n",
    "                self.update_weight()\n",
    "                # update prioritizing paramter untill it goes over 1\n",
    "                # self.beta  += db\n",
    "                if self.beta >= 1.0:\n",
    "                    self.beta = 1.0\n",
    "                 \n",
    "            if t % print_freq == 0:\n",
    "                print (\"time:\",  date[t + 1])\n",
    "                action = self.predict_action(stock_data[t+1])\n",
    "                print(\"portfolio:\", action)\n",
    "                print(\"reward:\", reward)\n",
    "                print(\"value:\", value)\n",
    "                print (\"elapsed time\", time.time() - st)\n",
    "                print(\"********************************************************************\")\n",
    "                \n",
    "            if count % plot_freq == 0:\n",
    "                result = pd.DataFrame(values, index=pd.DatetimeIndex(date_label))\n",
    "                result.to_csv(\"training_result.csv\")\n",
    "                \n",
    "            if count % save_freq == 0:\n",
    "                save_path = self.saver.save(self.sess, self.save_path)\n",
    "                print(\"Model saved in file: %s\" % self.save_path)\n",
    "\n",
    "        save_path = self.saver.save(self.sess, self.save_path)\n",
    "        print(\"Model saved in file: %s\" % self.save_path)\n",
    "        print (\"finished training\")\n",
    "           \n",
    "        return pd.DataFrame(values, index=pd.DatetimeIndex(date_label))\n",
    "    \n",
    "    def norm_action(self, action):\n",
    "        max_action = np.max(np.abs(action))\n",
    "        if max_action > 1:\n",
    "            return action / max_action\n",
    "        else:\n",
    "            return action\n",
    "    \n",
    "    def predict_action(self, state):\n",
    "        \"\"\"Preduct Optimal Portfolio\n",
    "        \n",
    "        Args:\n",
    "            state(float): stock data with size: [self.n_stock, ]\n",
    "        Retrun:\n",
    "            np.array with size: [self.n_stock, ]\n",
    "        \"\"\"\n",
    "        pred_state = self.memory[0].sample_state_uniform(self.n_batch, self.n_history)\n",
    "        new_state = pred_state[-1]\n",
    "        new_state = np.concatenate((new_state[1:], [state]), axis=0)\n",
    "        pred_state = np.concatenate((pred_state[:-1], [new_state]), axis=0)\n",
    "        action = self.actor_output.eval(\n",
    "            session=self.sess,\n",
    "            feed_dict={self.state: pred_state, K.learning_phase(): 0})[-1]\n",
    "        # action = self.norm_action(action)\n",
    "        return action\n",
    "    \n",
    "    def update_weight(self):\n",
    "        # pararel memory update\n",
    "        idx = np.random.randint(0, self.n_memory)\n",
    "        experiences, weights = self.memory[idx].sample(self.n_batch, self.n_history, self.alpha, self.beta)\n",
    "        self.sess.run(self.critic_optim, \n",
    "                      feed_dict={self.state: experiences.state0,\n",
    "                                 self.state_target: experiences.state1,\n",
    "                                 self.reward: experiences.reward,\n",
    "                                 self.action: experiences.action,\n",
    "                                 self.weights: weights,\n",
    "                                 self.learning_rate: self.lr,\n",
    "                                 K.learning_phase(): 1})  \n",
    "        self.sess.run(self.actor_optim,\n",
    "                      feed_dict={self.state: experiences.state0,\n",
    "                                 self.learning_rate: self.lr,\n",
    "                                 K.learning_phase(): 1})  \n",
    "                \n",
    "        error = self.sess.run(self.error,\n",
    "                              feed_dict={self.state: experiences.state0,\n",
    "                                         self.state_target: experiences.state1,\n",
    "                                         self.reward: experiences.reward,\n",
    "                                         self.action: experiences.action,\n",
    "                                         K.learning_phase(): 0})\n",
    "        self.memory[idx].update_priority(error)\n",
    "                    \n",
    "        # softupdate for critic network\n",
    "        old_weights = self.critic_target.get_weights()\n",
    "        new_weights = self.critic.get_weights()\n",
    "        weights = [self.update_rate * new_w + (1 - self.update_rate) * old_w\n",
    "                   for new_w, old_w in zip(new_weights, old_weights)]\n",
    "        self.critic_target.set_weights(weights)\n",
    "        \n",
    "    def initialize_memory(self, stocks):\n",
    "        self.memory = []\n",
    "        for i in range(self.n_memory):\n",
    "            self.memory.append(SequentialMemory(self.memory_length))\n",
    "        for t in range(len(stocks) - 1):\n",
    "            for idx_memory in range(self.n_memory):\n",
    "                action = np.random.normal(0, self.noise_scale, self.n_stock)\n",
    "                action = self.norm_action(action)\n",
    "                reward = np.sum((stocks[t + 1] - stocks[t]) * action)\n",
    "                self.memory[idx_memory].append(stocks[t], action, reward)\n",
    "        \n",
    "    def update_memory(self, state, state_forward):\n",
    "        # update memory without updating weight\n",
    "        for i in range(self.n_memory):\n",
    "            self.memory[i].observations.append(state)\n",
    "            self.memory[i].priority.append(1.0)\n",
    "        # to stabilize batch normalization, use other samples for prediction\n",
    "        pred_state = self.memory[0].sample_state_uniform(self.n_batch, self.n_history)\n",
    "        # off policy action and update portfolio\n",
    "        actor_action = self.actor_output.eval(session=self.sess,\n",
    "                                      feed_dict={self.state: pred_state,\n",
    "                                                          K.learning_phase(): 0})[-1]\n",
    "        # action_off = np.round(actor_value_off + np.random.normal(0, noise_scale, self.n_stock))\n",
    "        for i in range(self.n_memory):\n",
    "            action_off = actor_action + np.random.normal(0, self.noise_scale, self.n_stock)\n",
    "            action_off = self.norm_action(action_off)\n",
    "            # action_off = actor_value_off\n",
    "            reward_off = reward = np.sum((state_forward - state) * action_off)\n",
    "            self.memory[i].rewards.append(reward_off)\n",
    "            self.memory[i].actions.append(action_off)\n",
    "       \n",
    "    def take_action(self, state, state_forward):\n",
    "        # to stabilize batch normalization, use other samples for prediction\n",
    "        pred_state = self.memory[0].sample_state_uniform(self.n_batch, self.n_history)\n",
    "        # off policy action and update portfolio\n",
    "        action = self.actor_output.eval(session=self.sess,\n",
    "                                      feed_dict={self.state: pred_state,\n",
    "                                                          K.learning_phase(): 0})[-1]\n",
    "        reward = np.sum((state_forward - state) * action)\n",
    "        return reward\n",
    "    \n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"Build all of the network and optimizations\n",
    "        \n",
    "        just for conveninece of trainig, seprate placehoder for train and target network\n",
    "        critic network input: [raw_data, smoothed, downsampled, action]\n",
    "        actor network input: [raw_data, smoothed, downsampled]\n",
    "        \"\"\"\n",
    "        self.critic = self.build_critic()\n",
    "        self.critic_target = self.build_critic()\n",
    "        # actor network input should be [raw_data, smoothed, downsampled]\n",
    "        self.actor = self.build_actor()\n",
    "        # transform input into the several scales and smoothing\n",
    "        self.state =  tf.placeholder(tf.float32, [None, self.n_history, self.n_stock], name='state')\n",
    "        self.state_target = tf.placeholder(tf.float32, [None, self.n_history, self.n_stock], name='state_target')\n",
    "        # reshape to convolutional input\n",
    "        state_ = tf.reshape(self.state, [-1, self.n_history, self.n_stock, 1])\n",
    "        state_target_ = tf.reshape(self.state_target, [-1, self.n_history, self.n_stock, 1])\n",
    "        raw, smoothed, down = self.transform_input(state_)\n",
    "        raw_target, smoothed_target, down_target = self.transform_input(state_target_)\n",
    "        \n",
    "        # build graph for citic training\n",
    "        self.action = tf.placeholder(tf.float32, [None, self.n_stock])\n",
    "        input_q = [raw,] +  smoothed + down + [self.action,]\n",
    "        self.Q = tf.squeeze(self.critic(input_q))\n",
    "        # target network\n",
    "        # for double q-learning we use actor network not for target network\n",
    "        self.actor_target_output = self.actor([raw_target,] +  smoothed_target + down_target)\n",
    "        input_q_target = [raw_target,] +  smoothed_target + down_target + [self.actor_target_output,]\n",
    "        Q_target = tf.squeeze(self.critic_target(input_q_target))\n",
    "        self.reward = tf.placeholder(tf.float32, [None], name='reward')\n",
    "        target = self.reward  + self.gamma * Q_target\n",
    "        self.target_value = self.reward  + self.gamma * Q_target\n",
    "        # optimization\n",
    "        self.learning_rate = tf.placeholder(tf.float32, shape=[], name=\"learning_rate\")\n",
    "        # get rid of bias of prioritized\n",
    "        self.weights = tf.placeholder(tf.float32, shape=[None], name=\"weights\")\n",
    "        self.loss = tf.reduce_mean(self.weights * tf.square(target - self.Q), name='loss')\n",
    "        # TD-error for priority\n",
    "        self.error = tf.abs(target - self.Q)\n",
    "        self.critic_optim = tf.train.AdamOptimizer(self.learning_rate) \\\n",
    "            .minimize(self.loss, var_list=self.critic.trainable_weights)\n",
    "        \n",
    "        # build graph for actor training\n",
    "        self.actor_output = self.actor([raw,] +  smoothed + down)\n",
    "        input_q_actor = [raw,] +  smoothed + down + [self.actor_output,]\n",
    "        self.Q_actor = tf.squeeze(self.critic(input_q_actor))\n",
    "        # optimization\n",
    "        self.actor_optim = tf.train.AdamOptimizer(self.learning_rate) \\\n",
    "            .minimize(-self.Q_actor, var_list=self.actor.trainable_weights)\n",
    "        \n",
    "        self.saver = tf.train.Saver()\n",
    "        is_initialize = True\n",
    "        if self.is_load:\n",
    "            if self.load(self.save_path):\n",
    "                print('succeded to load')\n",
    "                is_initialize = False\n",
    "            else:\n",
    "                print('failed to load')\n",
    "        \n",
    "        # initialize network\n",
    "        if is_initialize:\n",
    "            tf.global_variables_initializer().run(session=self.sess)\n",
    "            weights = self.critic.get_weights()\n",
    "            self.critic_target.set_weights(weights)\n",
    "        \n",
    "    def build_critic(self):\n",
    "        \"\"\"Build critic network\n",
    "        \n",
    "        recieve convereted tensor: raw_data, smooted_data, and downsampled_data\n",
    "        \"\"\"\n",
    "        # lower layer\n",
    "        lower_model = [self.build_network(self.model_config['critic_lower'], input_shape=(self.history_length, self.n_stock, 1)) \n",
    "                       for _ in range(1  + self.n_smooth + self.n_down)]\n",
    "        merged = Merge(lower_model, mode='concat')\n",
    "        # upper layer\n",
    "        upper_model = self.build_network(self.model_config['critic_upper'],  model=merged)\n",
    "        # action layer\n",
    "        action = self.build_network(self.model_config['critic_action'], input_shape=(self.n_stock,), is_conv=False)\n",
    "        # output layer\n",
    "        merged = Merge([upper_model, action], mode='mul')\n",
    "        model = Sequential()\n",
    "        model.add(merged)\n",
    "        model.add(Dense(1))\n",
    "        return model\n",
    "    \n",
    "    def build_actor(self):\n",
    "        \"\"\"Build actor network\n",
    "        \n",
    "        recieve convereted tensor: raw_data, smooted_data, and downsampled_data\n",
    "        \"\"\"\n",
    "        # lower layer\n",
    "        lower_model = [self.build_network(self.model_config['actor_lower'], input_shape=(self.history_length, self.n_stock, 1)) \n",
    "                       for _ in range(1  + self.n_smooth + self.n_down)]\n",
    "        merged = Merge(lower_model, mode='concat')\n",
    "        # upper layer\n",
    "        model = self.build_network(self.model_config['actor_upper'],  model=merged)\n",
    "        return model\n",
    "    \n",
    "    def build_network(self, conf, model=None, input_shape=None, is_conv=True):\n",
    "        \"\"\"Build network\"\"\"\n",
    "        _model = model\n",
    "        model = Sequential()\n",
    "        if _model is None:\n",
    "            model.add(Lambda(lambda x: x,  input_shape=input_shape))\n",
    "        else:\n",
    "            model.add(_model)\n",
    "            \n",
    "        for x in conf:\n",
    "            if x['is_drop']:\n",
    "                model.add(Dropout(x['drop_rate']))\n",
    "            if x['type'] is 'full':\n",
    "                if is_conv:\n",
    "                    model.add(Flatten())\n",
    "                    is_conv = False\n",
    "                model.add(Dense(x['n_feature']))\n",
    "            elif x['type'] is 'conv':\n",
    "                model.add(Convolution2D(nb_filter=x['n_feature'], \n",
    "                                        nb_row=x['kw'], \n",
    "                                        nb_col=1, \n",
    "                                        border_mode='same'))  \n",
    "                is_conv=True\n",
    "            if x['is_batch']:\n",
    "                if x['type'] is 'full':\n",
    "                    model.add(BatchNormalization(mode=1, axis=-1))\n",
    "                if x['type'] is 'conv':\n",
    "                    model.add(BatchNormalization(mode=2, axis=-1))\n",
    "            model.add(x['activation'])\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def transform_input(self, input):\n",
    "        \"\"\"Transform data into the Multi Scaled one\n",
    "        \n",
    "        Args:\n",
    "            input: tensor with shape: [None, self.n_history, self.n_stock]\n",
    "        Return:\n",
    "            list of the same shape tensors, [None, self.length_history, self.n_stock]\n",
    "        \"\"\"\n",
    "        # the last data is the newest information\n",
    "        raw = input[:, self.n_history - self.history_length:, :, :]\n",
    "        # smooth data\n",
    "        smoothed = []\n",
    "        for n_sm in range(2, self.n_smooth + 2):\n",
    "            smoothed.append(\n",
    "                tf.reduce_mean(tf.pack([input[:, self.n_history - st - self.history_length:self.n_history - st, :, :]\n",
    "                                        for st in range(n_sm)]),0))\n",
    "        # downsample data\n",
    "        down = []\n",
    "        for n_dw in range(2, self.n_down + 2):\n",
    "            sampled_ = tf.pack([input[:, idx, :, :] \n",
    "                                for idx in range(self.n_history-n_dw*self.history_length, self.n_history, n_dw)])\n",
    "            down.append(tf.transpose(sampled_, [1, 0, 2, 3]))\n",
    "        return raw, smoothed, down\n",
    "    \n",
    "    def load(self, checkpoint_dir):\n",
    "        print(\" [*] Reading checkpoints...\")\n",
    "        try:\n",
    "            self.saver.restore(self.sess, self.save_path)\n",
    "            return True\n",
    "        except:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DDPGConfig(object):\n",
    "    def __init__(self, n_stock):\n",
    "        self.device = '/gpu:0'\n",
    "        self.save_path = '/home/tomoaki/work/github/jjakimoto.github.io/content'\n",
    "        self.is_load = False\n",
    "        self.gamma = 1.0\n",
    "        self.history_length = 10\n",
    "        self.n_stock = n_stock\n",
    "        self.n_smooth = 5\n",
    "        self.n_down = 5\n",
    "        self.n_batch = 32\n",
    "        self.n_epoch = 100\n",
    "        self.update_rate = 1e-1\n",
    "        self.learning_rate = 1e-3\n",
    "        self.model_config = {'critic_lower':[{'type':'conv', 'n_feature': 32, 'kw': 4,\n",
    "                                              'activation': PReLU(), 'is_batch': True, 'is_drop': False},\n",
    "                                             {'type':'conv', 'n_feature': 64, 'kw': 4,\n",
    "                                              'activation': PReLU(), 'is_batch': True, 'is_drop': False},\n",
    "                                             {'type':'conv', 'n_feature': 32, 'kw': 4,\n",
    "                                              'activation': PReLU(), 'is_batch': True, 'is_drop': False}],\n",
    "                             'critic_upper':[{'type':'full', 'n_feature': 32, 'kw': 4,\n",
    "                                              'activation': PReLU(), 'is_batch': True, 'is_drop': False},\n",
    "                                             {'type':'full', 'n_feature': 10, 'kw': 4,\n",
    "                                              'activation': PReLU(), 'is_batch': True, 'is_drop': False}],\n",
    "                             'critic_action':[{'type':'full', 'n_feature': 32, 'kw': 4,\n",
    "                                              'activation': PReLU(), 'is_batch': True, 'is_drop': False},\n",
    "                                             {'type':'full', 'n_feature': 10, 'kw': 4,\n",
    "                                              'activation': PReLU(), 'is_batch': True, 'is_drop': False}],\n",
    "                             'actor_lower':[{'type':'conv', 'n_feature': 32, 'kw': 4,\n",
    "                                              'activation': PReLU(), 'is_batch': True, 'is_drop': False},\n",
    "                                             {'type':'conv', 'n_feature': 64, 'kw': 4,\n",
    "                                              'activation': PReLU(), 'is_batch': True, 'is_drop': False},\n",
    "                                             {'type':'conv', 'n_feature': 32, 'kw': 4,\n",
    "                                              'activation': PReLU(), 'is_batch': True, 'is_drop': False}],\n",
    "                             'actor_upper':[{'type':'full', 'n_feature': 32, 'kw': 4,\n",
    "                                              'activation': PReLU(), 'is_batch': True, 'is_drop': False},\n",
    "                                             {'type':'full', 'n_feature': self.n_stock, 'kw': 4,\n",
    "                                              'activation': Activation('tanh'), 'is_batch': True, 'is_drop': False}]}\n",
    "        self.memory_length = 200\n",
    "        self.n_memory = 10\n",
    "        self.noise_scale = 0.2\n",
    "        self.alpha = 0.7\n",
    "        self.beta = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model....\n",
      "finished building model!\n",
      "training....\n",
      "time: 2012-06-14 00:00:00\n",
      "portfolio: [-0.78848541 -0.22017193 -0.07807437  0.52182615  0.92611259 -0.65165442\n",
      " -0.96248692  0.43629789  0.36898693  0.80954117]\n",
      "reward: -2.33982004432\n",
      "value: -2.33982004432\n",
      "elapsed time 27.9639108181\n",
      "********************************************************************\n",
      "time: 2012-06-15 00:00:00\n",
      "portfolio: [-0.2043941  -0.79878378  0.85572428  0.34774041  0.97328931 -0.53153515\n",
      " -0.48382288 -0.32402045 -0.87829781  0.43954527]\n",
      "reward: -0.209494602793\n",
      "value: -2.54931464712\n",
      "elapsed time 54.0066330433\n",
      "********************************************************************\n",
      "time: 2012-06-18 00:00:00\n",
      "portfolio: [ 0.09572027 -0.71659136 -0.37864488 -0.28112313  0.99693447 -0.22951929\n",
      " -0.05818003 -0.69009864 -0.27890405  0.13469484]\n",
      "reward: 0.243291262273\n",
      "value: -2.30602338484\n",
      "elapsed time 81.6290798187\n",
      "********************************************************************\n",
      "time: 2012-06-19 00:00:00\n",
      "portfolio: [-0.32868016 -0.73855513 -0.93234462  0.11205547  0.98749399  0.45643964\n",
      "  0.27919954 -0.73020136  0.59129357  0.09440058]\n",
      "reward: -8.7853401112\n",
      "value: -11.091363496\n",
      "elapsed time 108.547554016\n",
      "********************************************************************\n",
      "time: 2012-06-20 00:00:00\n",
      "portfolio: [-0.89874291 -0.42431319 -0.94944501  0.78794634  0.93269068 -0.26861301\n",
      "  0.69650346  0.22093198 -0.13156076 -0.23503958]\n",
      "reward: -3.19829199486\n",
      "value: -14.2896554909\n",
      "elapsed time 138.039331913\n",
      "********************************************************************\n",
      "time: 2012-06-21 00:00:00\n",
      "portfolio: [-0.9215858  -0.43835586 -0.95789969  0.47764656  0.95346034 -0.1319208\n",
      "  0.31318742  0.32048926  0.13419282 -0.3191483 ]\n",
      "reward: 1.39976448958\n",
      "value: -12.8898910013\n",
      "elapsed time 167.112978935\n",
      "********************************************************************\n",
      "time: 2012-06-22 00:00:00\n",
      "portfolio: [-0.96684682 -0.59721768 -0.95499527  0.66555941  0.79712689  0.05393162\n",
      "  0.37621939  0.34077802  0.37667435 -0.37551028]\n",
      "reward: 2.34162552369\n",
      "value: -10.5482654776\n",
      "elapsed time 196.596163034\n",
      "********************************************************************\n",
      "time: 2012-06-25 00:00:00\n",
      "portfolio: [-0.9498719  -0.67449701 -0.945301    0.57689095  0.79975373 -0.09576134\n",
      "  0.23426527  0.23365952  0.29207557 -0.45025045]\n",
      "reward: 0.8829422723\n",
      "value: -9.66532320533\n",
      "elapsed time 222.986182928\n",
      "********************************************************************\n",
      "time: 2012-06-26 00:00:00\n",
      "portfolio: [-0.92855477 -0.6478793  -0.96516216  0.62985408  0.80046451 -0.03504555\n",
      "  0.28746918  0.16227776  0.35381475 -0.50369775]\n",
      "reward: 3.74270716661\n",
      "value: -5.92261603871\n",
      "elapsed time 249.019583941\n",
      "********************************************************************\n",
      "time: 2012-06-27 00:00:00\n",
      "portfolio: [-0.81240255 -0.87927556 -0.93940091  0.75053507  0.85296071 -0.15457784\n",
      "  0.31432191  0.20874056  0.11109623 -0.54296112]\n",
      "reward: -2.73470236741\n",
      "value: -8.65731840613\n",
      "elapsed time 275.130031824\n",
      "********************************************************************\n",
      "time: 2012-06-28 00:00:00\n",
      "portfolio: [-0.47425655 -0.97179747 -0.73549998  0.70283163  0.81410801 -0.54783112\n",
      "  0.09189127  0.11442984 -0.0237959  -0.05281654]\n",
      "reward: 2.72472901077\n",
      "value: -5.93258939536\n",
      "elapsed time 301.462669849\n",
      "********************************************************************\n",
      "time: 2012-06-29 00:00:00\n",
      "portfolio: [-0.62037271 -0.97086245 -0.73099303  0.46222082  0.8729012  -0.28303352\n",
      " -0.06154795  0.36477888  0.30258274 -0.31315872]\n",
      "reward: -6.38482330586\n",
      "value: -12.3174127012\n",
      "elapsed time 327.459424973\n",
      "********************************************************************\n",
      "time: 2012-07-02 00:00:00\n",
      "portfolio: [-0.81968796 -0.88942486 -0.47410074  0.23080063  0.95042664 -0.12521735\n",
      " -0.2835691   0.3888804   0.21752465 -0.64300334]\n",
      "reward: -7.40727700767\n",
      "value: -19.7246897089\n",
      "elapsed time 353.636293888\n",
      "********************************************************************\n",
      "time: 2012-07-03 00:00:00\n",
      "portfolio: [-0.89791173 -0.23109724 -0.28449622 -0.1904231   0.9727335  -0.18733305\n",
      " -0.08596047 -0.09266734  0.28677714 -0.83211553]\n",
      "reward: -8.80986011013\n",
      "value: -28.534549819\n",
      "elapsed time 379.953094006\n",
      "********************************************************************\n",
      "time: 2012-07-05 00:00:00\n",
      "portfolio: [-0.95427108 -0.0735633  -0.29036054 -0.1985445   0.95339823 -0.50893903\n",
      " -0.04194291 -0.53129262  0.6576184  -0.47888663]\n",
      "reward: -1.49477806796\n",
      "value: -30.029327887\n",
      "elapsed time 406.602730036\n",
      "********************************************************************\n",
      "time: 2012-07-06 00:00:00\n",
      "portfolio: [-0.94090152 -0.09066183 -0.38853049 -0.00320936  0.93113339 -0.71144342\n",
      "  0.19407555 -0.63731384  0.57864463 -0.48767534]\n",
      "reward: -0.147561673696\n",
      "value: -30.1768895607\n",
      "elapsed time 432.614348888\n",
      "********************************************************************\n",
      "time: 2012-07-09 00:00:00\n",
      "portfolio: [-0.63735485  0.19285855 -0.41659591 -0.04565438  0.96262711 -0.81786311\n",
      "  0.17854191 -0.82224053  0.28016004 -0.49819437]\n",
      "reward: 0.559292957563\n",
      "value: -29.6175966031\n",
      "elapsed time 458.673070908\n",
      "********************************************************************\n",
      "time: 2012-07-10 00:00:00\n",
      "portfolio: [-0.69934881  0.14896455 -0.45218799  0.05861422  0.96872181 -0.82850927\n",
      "  0.22415873 -0.72013378  0.14713757 -0.45790026]\n",
      "reward: 2.70056386064\n",
      "value: -26.9170327425\n",
      "elapsed time 485.049235821\n",
      "********************************************************************\n",
      "time: 2012-07-11 00:00:00\n",
      "portfolio: [-0.44294775  0.20693249 -0.41528067  0.06606563  0.96415347 -0.92154622\n",
      "  0.41047055 -0.66254365  0.05423371 -0.32523292]\n",
      "reward: -1.18296094864\n",
      "value: -28.0999936911\n",
      "elapsed time 511.495856047\n",
      "********************************************************************\n",
      "time: 2012-07-12 00:00:00\n",
      "portfolio: [-0.51042962  0.69214189 -0.32064638  0.11697614  0.88474876 -0.97249007\n",
      "  0.72357166 -0.47790691 -0.1198011   0.11934488]\n",
      "reward: -1.32870212545\n",
      "value: -29.4286958166\n",
      "elapsed time 537.522773027\n",
      "********************************************************************\n",
      "time: 2012-07-13 00:00:00\n",
      "portfolio: [-0.67673182  0.58538115 -0.27294618  0.11270244  0.8990615  -0.94838095\n",
      "  0.8853336  -0.56724793  0.13571954  0.32041177]\n",
      "reward: 1.63132175061\n",
      "value: -27.7973740659\n",
      "elapsed time 563.748402834\n",
      "********************************************************************\n",
      "time: 2012-07-16 00:00:00\n",
      "portfolio: [-0.2906321   0.53155077 -0.28616318  0.08868082  0.96427178 -0.9572221\n",
      "  0.78924799 -0.40792623  0.09041341  0.18282402]\n",
      "reward: 1.49712037833\n",
      "value: -26.3002536876\n",
      "elapsed time 590.008165836\n",
      "********************************************************************\n",
      "time: 2012-07-17 00:00:00\n",
      "portfolio: [-0.5661394   0.64263344 -0.01743633  0.13596499  0.97141904 -0.92786407\n",
      "  0.76210439 -0.44293299  0.22242628  0.05805957]\n",
      "reward: 2.96681081857\n",
      "value: -23.3334428691\n",
      "elapsed time 616.067477942\n",
      "********************************************************************\n",
      "time: 2012-07-18 00:00:00\n",
      "portfolio: [-0.40187943  0.60624307 -0.20463321  0.11765774  0.98707849 -0.91211343\n",
      "  0.63707864 -0.44106638  0.08705439  0.01019875]\n",
      "reward: -2.4491025016\n",
      "value: -25.7825453707\n",
      "elapsed time 642.191963911\n",
      "********************************************************************\n",
      "time: 2012-07-19 00:00:00\n",
      "portfolio: [-0.1882125   0.21745349 -0.33872804 -0.03046147  0.99341422 -0.88759345\n",
      "  0.50835013 -0.56257474  0.07507997  0.09220748]\n",
      "reward: 3.19756549697\n",
      "value: -22.5849798737\n",
      "elapsed time 668.336002827\n",
      "********************************************************************\n",
      "time: 2012-07-20 00:00:00\n",
      "portfolio: [-0.27765647  0.18345723 -0.24657945 -0.0184423   0.99132526 -0.94127327\n",
      "  0.49513564 -0.49167535  0.1855474   0.18351977]\n",
      "reward: 0.351583215453\n",
      "value: -22.2333966582\n",
      "elapsed time 694.669880867\n",
      "********************************************************************\n",
      "time: 2012-07-23 00:00:00\n",
      "portfolio: [-0.17994329  0.16699721 -0.26217744 -0.05053742  0.98714536 -0.9324851\n",
      "  0.72765088 -0.64115095  0.12530665  0.11157276]\n",
      "reward: -3.15021825676\n",
      "value: -25.383614915\n",
      "elapsed time 721.510489941\n",
      "********************************************************************\n",
      "time: 2012-07-24 00:00:00\n",
      "portfolio: [-0.68134993  0.28083062 -0.43809211  0.16997546  0.99397612 -0.92908305\n",
      "  0.33957821 -0.05414708  0.20544371 -0.10292908]\n",
      "reward: 2.57112158949\n",
      "value: -22.8124933255\n",
      "elapsed time 747.803905964\n",
      "********************************************************************\n",
      "time: 2012-07-25 00:00:00\n",
      "portfolio: [-0.74348581  0.25465125 -0.17518212 -0.06466845  0.99636543 -0.81852221\n",
      "  0.41259822 -0.24424021  0.15879883 -0.13145928]\n",
      "reward: -8.75378965048\n",
      "value: -31.566282976\n",
      "elapsed time 773.972618818\n",
      "********************************************************************\n",
      "time: 2012-07-26 00:00:00\n",
      "portfolio: [-0.5017215  -0.11368812  0.3321808  -0.3111724   0.99686927 -0.66141468\n",
      "  0.24439816 -0.63869143  0.39399293 -0.13992515]\n",
      "reward: 0.951418082263\n",
      "value: -30.6148648937\n",
      "elapsed time 800.241973877\n",
      "********************************************************************\n",
      "time: 2012-07-27 00:00:00\n",
      "portfolio: [-0.47930962 -0.26174396  0.50700212 -0.26311433  0.99400842 -0.75553411\n",
      "  0.31109342 -0.72733569  0.54017496 -0.07787861]\n",
      "reward: 0.667063837194\n",
      "value: -29.9478010565\n",
      "elapsed time 826.209485054\n",
      "********************************************************************\n",
      "time: 2012-07-30 00:00:00\n",
      "portfolio: [-0.43138    -0.06572837  0.61729944 -0.19698459  0.99130648 -0.77089089\n",
      "  0.29026896 -0.79832208  0.54134101 -0.03178874]\n",
      "reward: -4.36893979201\n",
      "value: -34.3167408485\n",
      "elapsed time 852.296247959\n",
      "********************************************************************\n",
      "time: 2012-07-31 00:00:00\n",
      "portfolio: [-0.54671717  0.76736951  0.81469977 -0.35094833  0.96015573 -0.76106882\n",
      "  0.30917561 -0.76980007  0.53443575 -0.05418308]\n",
      "reward: -0.555689397283\n",
      "value: -34.8724302458\n",
      "elapsed time 878.55366683\n",
      "********************************************************************\n",
      "time: 2012-08-01 00:00:00\n",
      "portfolio: [-0.56961805  0.70767444  0.80274278 -0.22749187  0.95144945 -0.88194501\n",
      "  0.31890175 -0.68972921  0.57377052  0.06830787]\n",
      "reward: 9.68094541474\n",
      "value: -25.1914848311\n",
      "elapsed time 904.506592989\n",
      "********************************************************************\n",
      "time: 2012-08-02 00:00:00\n",
      "portfolio: [-0.59256303  0.75420541  0.87656736 -0.13719516  0.95614702 -0.81976807\n",
      "  0.13238604 -0.73085606  0.64157444 -0.08170221]\n",
      "reward: -9.02268395005\n",
      "value: -34.2141687811\n",
      "elapsed time 930.698112011\n",
      "********************************************************************\n",
      "time: 2012-08-03 00:00:00\n",
      "portfolio: [-0.58380097  0.30796286  0.88498461 -0.15479021  0.99331701 -0.83198369\n",
      " -0.04081246 -0.11261436  0.61447912 -0.54192299]\n",
      "reward: 8.13267219231\n",
      "value: -26.0814965888\n",
      "elapsed time 956.738101959\n",
      "********************************************************************\n",
      "time: 2012-08-06 00:00:00\n",
      "portfolio: [-0.69568378  0.65449059  0.96203226 -0.28726426  0.96614659 -0.69952917\n",
      " -0.47681579 -0.42723683  0.73693913 -0.33896077]\n",
      "reward: 0.865013653906\n",
      "value: -25.2164829349\n",
      "elapsed time 983.147755861\n",
      "********************************************************************\n",
      "time: 2012-08-07 00:00:00\n",
      "portfolio: [-0.81181836  0.69334686  0.96149617 -0.32065144  0.98067236 -0.30912194\n",
      " -0.35477751 -0.48443899  0.63724512 -0.30929989]\n",
      "reward: 2.84151200472\n",
      "value: -22.3749709302\n",
      "elapsed time 1009.10844302\n",
      "********************************************************************\n",
      "time: 2012-08-08 00:00:00\n",
      "portfolio: [-0.82203174  0.65907919  0.9499746  -0.31032559  0.9801923  -0.26791114\n",
      " -0.38936594 -0.48859769  0.74305058 -0.13408478]\n",
      "reward: -3.01552646338\n",
      "value: -25.3904973936\n",
      "elapsed time 1034.87121987\n",
      "********************************************************************\n",
      "time: 2012-08-09 00:00:00\n",
      "portfolio: [-0.82042325  0.8664161   0.91777527 -0.22797984  0.92941564 -0.44859743\n",
      " -0.22314286 -0.69137919  0.796929   -0.06397025]\n",
      "reward: -1.29465090353\n",
      "value: -26.6851482971\n",
      "elapsed time 1060.97913599\n",
      "********************************************************************\n",
      "time: 2012-08-10 00:00:00\n",
      "portfolio: [-0.62588692  0.75784034  0.74339414 -0.30297428  0.9869312  -0.34474808\n",
      " -0.26472503 -0.7602371   0.87381089  0.0620479 ]\n",
      "reward: 0.920218007933\n",
      "value: -25.7649302892\n",
      "elapsed time 1087.00752783\n",
      "********************************************************************\n",
      "time: 2012-08-13 00:00:00\n",
      "portfolio: [-0.50798678  0.80434722  0.75356799 -0.40873668  0.99272704 -0.45994723\n",
      " -0.2100973  -0.75549799  0.67638433  0.2308014 ]\n",
      "reward: 3.26111624647\n",
      "value: -22.5038140427\n",
      "elapsed time 1113.14449382\n",
      "********************************************************************\n",
      "time: 2012-08-14 00:00:00\n",
      "portfolio: [-0.40258136  0.79743987  0.67612141 -0.38693526  0.99166381 -0.37894052\n",
      " -0.268282   -0.7917698   0.68371093  0.41826251]\n",
      "reward: 6.97275410409\n",
      "value: -15.5310599386\n",
      "elapsed time 1139.50615287\n",
      "********************************************************************\n",
      "time: 2012-08-15 00:00:00\n",
      "portfolio: [-0.51788688  0.77845442  0.71355116 -0.40934673  0.99374098 -0.37864295\n",
      " -0.23783663 -0.7712335   0.63801271  0.38980258]\n",
      "reward: 0.0932192315211\n",
      "value: -15.4378407071\n",
      "elapsed time 1165.89068484\n",
      "********************************************************************\n",
      "time: 2012-08-16 00:00:00\n",
      "portfolio: [-0.41522175  0.62461889  0.56290364 -0.42406365  0.99795055 -0.52811927\n",
      " -0.07737649 -0.65671474  0.64458263  0.27900055]\n",
      "reward: -0.842900225587\n",
      "value: -16.2807409327\n",
      "elapsed time 1192.5515759\n",
      "********************************************************************\n",
      "time: 2012-08-17 00:00:00\n",
      "portfolio: [-0.33928701  0.59347451  0.54087079 -0.20409612  0.99849141 -0.63264769\n",
      " -0.15656669 -0.66807425  0.62979943  0.17579223]\n",
      "reward: 5.19003463997\n",
      "value: -11.0907062927\n",
      "elapsed time 1218.69586492\n",
      "********************************************************************\n",
      "time: 2012-08-20 00:00:00\n",
      "portfolio: [-0.3606728   0.59960884  0.57012826 -0.36939439  0.99803269 -0.50479925\n",
      " -0.15086827 -0.72564137  0.689439    0.25307244]\n",
      "reward: 5.66482110963\n",
      "value: -5.42588518308\n",
      "elapsed time 1244.84070396\n",
      "********************************************************************\n",
      "time: 2012-08-21 00:00:00\n",
      "portfolio: [-0.30759931  0.63051438  0.50194609 -0.25673649  0.99813384 -0.69409037\n",
      " -0.11040542 -0.64148366  0.69652808  0.18602142]\n",
      "reward: 12.0943552562\n",
      "value: 6.66847007308\n",
      "elapsed time 1270.75366497\n",
      "********************************************************************\n",
      "time: 2012-08-22 00:00:00\n",
      "portfolio: [-0.24686177  0.58601689  0.60909307 -0.36553186  0.99801213 -0.49656621\n",
      " -0.24613361 -0.73200929  0.71248323  0.25318909]\n",
      "reward: -10.2725445084\n",
      "value: -3.60407443533\n",
      "elapsed time 1296.54136586\n",
      "********************************************************************\n",
      "time: 2012-08-23 00:00:00\n",
      "portfolio: [-0.40719298  0.44703332  0.67555577 -0.30477244  0.99878299 -0.49772462\n",
      " -0.24884717 -0.7066865   0.57983446  0.24716213]\n",
      "reward: 8.02400602414\n",
      "value: 4.41993158881\n",
      "elapsed time 1322.80815101\n",
      "********************************************************************\n",
      "time: 2012-08-24 00:00:00\n",
      "portfolio: [-0.25648797  0.52690929  0.66549689 -0.34499514  0.99836975 -0.53495729\n",
      " -0.24469806 -0.76015842  0.5719108   0.32360858]\n",
      "reward: -2.57284066436\n",
      "value: 1.84709092444\n",
      "elapsed time 1348.72308898\n",
      "********************************************************************\n",
      "time: 2012-08-27 00:00:00\n",
      "portfolio: [-0.25120667  0.41890892  0.65990198 -0.42060801  0.99844664 -0.49290797\n",
      " -0.30786163 -0.76116771  0.67329621  0.33128861]\n",
      "reward: 10.8551826348\n",
      "value: 12.7022735593\n",
      "elapsed time 1374.43118501\n",
      "********************************************************************\n",
      "time: 2012-08-28 00:00:00\n",
      "portfolio: [-0.1970017   0.45493838  0.67532134 -0.43812636  0.99861407 -0.63237369\n",
      " -0.24293806 -0.68198144  0.53820205  0.37243134]\n",
      "reward: -1.83866316577\n",
      "value: 10.8636103935\n",
      "elapsed time 1400.65528798\n",
      "********************************************************************\n",
      "time: 2012-08-29 00:00:00\n",
      "portfolio: [-0.0743324   0.43316925  0.68881452 -0.47208348  0.99871975 -0.63277143\n",
      " -0.40540415 -0.6062367   0.43913698  0.48758546]\n",
      "reward: 0.399785718085\n",
      "value: 11.2633961116\n",
      "elapsed time 1426.53597593\n",
      "********************************************************************\n",
      "time: 2012-08-30 00:00:00\n",
      "portfolio: [-0.11222734  0.53285813  0.70342124 -0.47605196  0.9981218  -0.6799745\n",
      " -0.43792358 -0.6296975   0.50931728  0.49300876]\n",
      "reward: -1.8308134416\n",
      "value: 9.43258266996\n",
      "elapsed time 1452.3794229\n",
      "********************************************************************\n",
      "time: 2012-08-31 00:00:00\n",
      "portfolio: [-0.22758153  0.48661664  0.65268743 -0.42594191  0.99866688 -0.76487553\n",
      " -0.51899511 -0.49183989  0.58339316  0.35565251]\n",
      "reward: -1.70647967896\n",
      "value: 7.726102991\n",
      "elapsed time 1478.22816801\n",
      "********************************************************************\n",
      "time: 2012-09-04 00:00:00\n",
      "portfolio: [-0.33996841  0.3763271   0.5171088  -0.37224165  0.99889284 -0.79890674\n",
      " -0.42552701 -0.66319168  0.64686304  0.25220254]\n",
      "reward: -0.983445944202\n",
      "value: 6.7426570468\n",
      "elapsed time 1503.97493696\n",
      "********************************************************************\n",
      "time: 2012-09-05 00:00:00\n",
      "portfolio: [-0.35166398  0.49995688  0.36919236 -0.29165512  0.99904126 -0.84321225\n",
      " -0.56047761 -0.6229803   0.52018189  0.23481071]\n",
      "reward: 4.05861057612\n",
      "value: 10.8012676229\n",
      "elapsed time 1529.74449682\n",
      "********************************************************************\n",
      "time: 2012-09-06 00:00:00\n",
      "portfolio: [-0.41097465  0.53996772  0.49382344 -0.34037787  0.99887687 -0.8222369\n",
      " -0.60232699 -0.64588588  0.49190605  0.26468736]\n",
      "reward: -1.17661988022\n",
      "value: 9.6246477427\n",
      "elapsed time 1555.93144703\n",
      "********************************************************************\n",
      "time: 2012-09-07 00:00:00\n",
      "portfolio: [-0.49152458  0.50437158  0.58481336 -0.36267501  0.99878502 -0.81459206\n",
      " -0.61908668 -0.64925849  0.46709216  0.31072453]\n",
      "reward: 2.77828008218\n",
      "value: 12.4029278249\n",
      "elapsed time 1582.45654702\n",
      "********************************************************************\n",
      "time: 2012-09-10 00:00:00\n",
      "portfolio: [-0.4785347   0.53719556  0.66508317 -0.38875633  0.99815226 -0.83926129\n",
      " -0.50912797 -0.72855818  0.49058083  0.35807425]\n",
      "reward: 1.39368751629\n",
      "value: 13.7966153412\n",
      "elapsed time 1608.29418683\n",
      "********************************************************************\n",
      "time: 2012-09-11 00:00:00\n",
      "portfolio: [-0.40139446  0.59961152  0.71764004 -0.42372203  0.99762601 -0.87707412\n",
      " -0.41807169 -0.71957552  0.48626059  0.32067862]\n",
      "reward: -7.54939787777\n",
      "value: 6.24721746341\n",
      "elapsed time 1637.07115197\n",
      "********************************************************************\n",
      "time: 2012-09-12 00:00:00\n",
      "portfolio: [-0.304764    0.6837582   0.74619901 -0.42911878  0.99692988 -0.81914115\n",
      " -0.3662591  -0.87285739  0.35041952  0.29492986]\n",
      "reward: 0.565855564036\n",
      "value: 6.81307302744\n",
      "elapsed time 1663.32730794\n",
      "********************************************************************\n",
      "time: 2012-09-13 00:00:00\n",
      "portfolio: [-0.29332644  0.72534311  0.77391303 -0.45226875  0.99460536 -0.73456347\n",
      " -0.31017384 -0.92402107  0.40051535  0.33998322]\n",
      "reward: 7.48313473645\n",
      "value: 14.2962077639\n",
      "elapsed time 1689.38200593\n",
      "********************************************************************\n",
      "time: 2012-09-14 00:00:00\n",
      "portfolio: [-0.32621899  0.64057958  0.71657598 -0.39009818  0.9963901  -0.79361713\n",
      " -0.27381778 -0.92700195  0.43851188  0.29705822]\n",
      "reward: 8.92794409117\n",
      "value: 23.2241518551\n",
      "elapsed time 1715.74117494\n",
      "********************************************************************\n",
      "time: 2012-09-17 00:00:00\n",
      "portfolio: [-0.34203082  0.70105171  0.78659123 -0.48067358  0.9951914  -0.75144476\n",
      " -0.22199917 -0.93389547  0.35915905  0.31293207]\n",
      "reward: 5.72478117846\n",
      "value: 28.9489330335\n",
      "elapsed time 1741.8630209\n",
      "********************************************************************\n",
      "time: 2012-09-18 00:00:00\n",
      "portfolio: [-0.3653754   0.73454785  0.82076043 -0.45542789  0.99125737 -0.78750461\n",
      " -0.25411889 -0.93618786  0.43658492  0.39175138]\n",
      "reward: 0.846445237278\n",
      "value: 29.7953782708\n",
      "elapsed time 1767.88200283\n",
      "********************************************************************\n",
      "time: 2012-09-19 00:00:00\n",
      "portfolio: [-0.29359749  0.74571753  0.82380974 -0.43500662  0.99038851 -0.77687734\n",
      " -0.30665022 -0.9467907   0.4236908   0.40120941]\n",
      "reward: 0.241442197203\n",
      "value: 30.036820468\n",
      "elapsed time 1793.77556205\n",
      "********************************************************************\n",
      "time: 2012-09-20 00:00:00\n",
      "portfolio: [-0.32789961  0.71924365  0.81337482 -0.40776646  0.99291003 -0.80070132\n",
      " -0.29728398 -0.94557321  0.41439715  0.28373402]\n",
      "reward: -0.0572551023673\n",
      "value: 29.9795653656\n",
      "elapsed time 1819.86648393\n",
      "********************************************************************\n",
      "time: 2012-09-21 00:00:00\n",
      "portfolio: [-0.33100334  0.67707092  0.8078239  -0.41041678  0.99394524 -0.78789711\n",
      " -0.36260185 -0.949489    0.4175854   0.2608307 ]\n",
      "reward: 2.41362285163\n",
      "value: 32.3931882173\n",
      "elapsed time 1845.86857605\n",
      "********************************************************************\n",
      "time: 2012-09-24 00:00:00\n",
      "portfolio: [-0.25434887  0.68578202  0.81453788 -0.38433346  0.99137264 -0.81058013\n",
      " -0.31311041 -0.95760876  0.45503479  0.31774005]\n",
      "reward: -9.88161334339\n",
      "value: 22.5115748739\n",
      "elapsed time 1871.94343495\n",
      "********************************************************************\n",
      "time: 2012-09-25 00:00:00\n",
      "portfolio: [-0.24660031  0.61499667  0.8531366  -0.48059371  0.99221599 -0.76590168\n",
      " -0.42963371 -0.95700014  0.55972958  0.1942481 ]\n",
      "reward: 1.3348120279\n",
      "value: 23.8463869018\n",
      "elapsed time 1897.75881791\n",
      "********************************************************************\n",
      "time: 2012-09-26 00:00:00\n",
      "portfolio: [-0.20189486  0.64432812  0.8521409  -0.526829    0.98758596 -0.76950169\n",
      " -0.38599253 -0.96384782  0.56518894  0.27618152]\n",
      "reward: -11.3095146056\n",
      "value: 12.5368722961\n",
      "elapsed time 1923.64713383\n",
      "********************************************************************\n",
      "time: 2012-09-27 00:00:00\n",
      "portfolio: [-0.31302726  0.71506655  0.86549503 -0.58441055  0.95193177 -0.56021476\n",
      " -0.27249661 -0.97555172  0.68632293  0.33434868]\n",
      "reward: -2.83775280209\n",
      "value: 9.69911949404\n",
      "elapsed time 1949.71017194\n",
      "********************************************************************\n",
      "time: 2012-09-28 00:00:00\n",
      "portfolio: [-0.50983465  0.78473723  0.85249901 -0.46073306  0.94960189 -0.54204315\n",
      " -0.27597797 -0.97229481  0.74088907  0.33197814]\n",
      "reward: 10.1657689753\n",
      "value: 19.8648884693\n",
      "elapsed time 1975.48058295\n",
      "********************************************************************\n",
      "time: 2012-10-01 00:00:00\n",
      "portfolio: [-0.53387201  0.83211339  0.92757142 -0.61350632  0.92140907 -0.3925828\n",
      " -0.29343185 -0.96277708  0.69623339  0.29580608]\n",
      "reward: -6.11409536273\n",
      "value: 13.7507931066\n",
      "elapsed time 2001.49966788\n",
      "********************************************************************\n",
      "time: 2012-10-02 00:00:00\n",
      "portfolio: [-0.49810678  0.7896387   0.95546186 -0.70420414  0.88094443 -0.51001775\n",
      " -0.27375543 -0.95446086  0.62629414  0.38071582]\n",
      "reward: -7.45067980024\n",
      "value: 6.30011330636\n",
      "elapsed time 2027.33548903\n",
      "********************************************************************\n",
      "time: 2012-10-03 00:00:00\n",
      "portfolio: [-0.39133441  0.69440222  0.95603454 -0.54855788  0.95005006 -0.85376942\n",
      " -0.21290462 -0.94354397  0.61225855  0.21396655]\n",
      "reward: 2.3373464919\n",
      "value: 8.63745979826\n",
      "elapsed time 2054.3366859\n",
      "********************************************************************\n",
      "time: 2012-10-04 00:00:00\n",
      "portfolio: [-0.48183328  0.65691996  0.96452463 -0.58775949  0.94544059 -0.78177321\n",
      " -0.2513752  -0.95978087  0.54792339  0.27167189]\n",
      "reward: 7.12925099419\n",
      "value: 15.7667107925\n",
      "elapsed time 2080.63974786\n",
      "********************************************************************\n",
      "time: 2012-10-05 00:00:00\n",
      "portfolio: [-0.44183093  0.61195332  0.968817   -0.65175569  0.9332394  -0.76016492\n",
      " -0.21623541 -0.96125889  0.58707374  0.22950318]\n",
      "reward: -4.31416732577\n",
      "value: 11.4525434667\n",
      "elapsed time 2106.46582103\n",
      "********************************************************************\n",
      "time: 2012-10-08 00:00:00\n",
      "portfolio: [-0.33839884  0.65366852  0.96592546 -0.69809055  0.92164069 -0.71753043\n",
      " -0.26598009 -0.96241343  0.68114305  0.16635273]\n",
      "reward: -10.4857722219\n",
      "value: 0.966771244817\n",
      "elapsed time 2132.36717486\n",
      "********************************************************************\n",
      "time: 2012-10-09 00:00:00\n",
      "portfolio: [-0.36009324  0.65493643  0.94619906 -0.49954283  0.94589347 -0.80461931\n",
      " -0.25344929 -0.9728815   0.62936997  0.20724747]\n",
      "reward: -5.10427079228\n",
      "value: -4.13749954746\n",
      "elapsed time 2158.15587401\n",
      "********************************************************************\n",
      "time: 2012-10-10 00:00:00\n",
      "portfolio: [-0.49432716  0.67143548  0.92908442 -0.37509549  0.95675886 -0.86431551\n",
      " -0.20625824 -0.96659511  0.59557122  0.17868729]\n",
      "reward: 0.919745129258\n",
      "value: -3.2177544182\n",
      "elapsed time 2184.05991888\n",
      "********************************************************************\n",
      "time: 2012-10-11 00:00:00\n",
      "portfolio: [-0.44303849  0.6882751   0.88698912 -0.34816211  0.95403409 -0.73918325\n",
      " -0.10715009 -0.98692173  0.4777118   0.2474259 ]\n",
      "reward: 4.65764476162\n",
      "value: 1.43989034342\n",
      "elapsed time 2210.22186995\n",
      "********************************************************************\n",
      "time: 2012-10-12 00:00:00\n",
      "portfolio: [-0.4326286   0.69389749  0.8241266  -0.37792581  0.95669109 -0.59280682\n",
      " -0.04319077 -0.99089158  0.37185889  0.25402269]\n",
      "reward: -11.3054425369\n",
      "value: -9.86555219344\n",
      "elapsed time 2236.30972695\n",
      "********************************************************************\n",
      "time: 2012-10-15 00:00:00\n",
      "portfolio: [-0.49863228  0.72603887  0.8782385  -0.45795572  0.94095337 -0.39866889\n",
      "  0.06237686 -0.99056184  0.39119479  0.11431557]\n",
      "reward: 1.36976990617\n",
      "value: -8.49578228727\n",
      "elapsed time 2262.15295696\n",
      "********************************************************************\n",
      "time: 2012-10-16 00:00:00\n",
      "portfolio: [-0.58300722  0.72994274  0.89262986 -0.20322555  0.95563143 -0.59748095\n",
      "  0.17610547 -0.98412257  0.4009684   0.02103154]\n",
      "reward: 2.47461987594\n",
      "value: -6.02116241133\n",
      "elapsed time 2287.88838291\n",
      "********************************************************************\n",
      "time: 2012-10-17 00:00:00\n",
      "portfolio: [-0.45431474  0.69049144  0.92961228 -0.19610953  0.96005726 -0.56859785\n",
      "  0.1166266  -0.98120886  0.4127855   0.02026313]\n",
      "reward: 9.86793608129\n",
      "value: 3.84677366996\n",
      "elapsed time 2314.56794405\n",
      "********************************************************************\n",
      "time: 2012-10-18 00:00:00\n",
      "portfolio: [-0.53463173  0.61810243  0.93865436 -0.2007158   0.96926701 -0.54521382\n",
      "  0.12267982 -0.97463274  0.3946203   0.03148908]\n",
      "reward: -6.52824069027\n",
      "value: -2.68146702032\n",
      "elapsed time 2341.40510488\n",
      "********************************************************************\n",
      "time: 2012-10-19 00:00:00\n",
      "portfolio: [-0.44187701  0.54858738  0.96662217 -0.21435961  0.96198881 -0.42286804\n",
      "  0.00454803 -0.96141016  0.45389202  0.01028687]\n",
      "reward: -5.35202244706\n",
      "value: -8.03348946738\n",
      "elapsed time 2367.92886901\n",
      "********************************************************************\n",
      "time: 2012-10-22 00:00:00\n",
      "portfolio: [-0.42300597  0.42829144  0.967493   -0.13464427  0.96979231 -0.60949242\n",
      "  0.00659162 -0.8519156   0.52765417 -0.00616903]\n",
      "reward: -10.6473348404\n",
      "value: -18.6808243077\n",
      "elapsed time 2394.64521885\n",
      "********************************************************************\n",
      "time: 2012-10-23 00:00:00\n",
      "portfolio: [-0.3581211   0.46822032  0.95765066 -0.27133498  0.96049649 -0.73983347\n",
      "  0.10365745 -0.79182839  0.55737257 -0.00224   ]\n",
      "reward: 7.33028381653\n",
      "value: -11.3505404912\n",
      "elapsed time 2420.99567294\n",
      "********************************************************************\n",
      "time: 2012-10-24 00:00:00\n",
      "portfolio: [-0.339268    0.50352126  0.9521082  -0.28448722  0.95037305 -0.77999914\n",
      "  0.12542485 -0.78449184  0.57708669 -0.01618053]\n",
      "reward: -4.36126382479\n",
      "value: -15.711804316\n",
      "elapsed time 2446.73713684\n",
      "********************************************************************\n",
      "time: 2012-10-25 00:00:00\n",
      "portfolio: [-0.48957595  0.61794126  0.95466232 -0.22645454  0.94228423 -0.72982824\n",
      "  0.08452615 -0.72992778  0.57609606 -0.04220944]\n",
      "reward: 0.323317438007\n",
      "value: -15.388486878\n",
      "elapsed time 2472.48573804\n",
      "********************************************************************\n",
      "time: 2012-10-26 00:00:00\n",
      "portfolio: [-0.51425165  0.69191444  0.95977002 -0.13470979  0.92272192 -0.71859467\n",
      "  0.0328838  -0.59828758  0.56549537 -0.00846403]\n",
      "reward: -6.46755197729\n",
      "value: -21.8560388553\n",
      "elapsed time 2498.74209595\n",
      "********************************************************************\n",
      "time: 2012-10-31 00:00:00\n",
      "portfolio: [-0.57356721  0.60720968  0.9654119  -0.08899239  0.93343514 -0.73515379\n",
      "  0.06711987 -0.54488397  0.51517403 -0.01373272]\n",
      "reward: -9.83467695767\n",
      "value: -31.6907158129\n",
      "elapsed time 2524.73866105\n",
      "********************************************************************\n",
      "time: 2012-11-01 00:00:00\n",
      "portfolio: [-0.56954783  0.50287843  0.97504824 -0.07583485  0.958381   -0.68062127\n",
      "  0.02985652 -0.51697409  0.47407004 -0.03956499]\n",
      "reward: 2.03111571978\n",
      "value: -29.6596000932\n",
      "elapsed time 2550.60667896\n",
      "********************************************************************\n",
      "time: 2012-11-02 00:00:00\n",
      "portfolio: [-0.51594073  0.6545763   0.97780293 -0.09075248  0.94868404 -0.61703086\n",
      "  0.02643777 -0.55004263  0.37605467 -0.03340329]\n",
      "reward: -1.41722731836\n",
      "value: -31.0768274115\n",
      "elapsed time 2576.34305787\n",
      "********************************************************************\n",
      "time: 2012-11-05 00:00:00\n",
      "portfolio: [-0.50903875  0.63370889  0.97812271 -0.13217448  0.93841112 -0.6605916\n",
      "  0.05273093 -0.49880755  0.406073   -0.01397911]\n",
      "reward: -8.23486717302\n",
      "value: -39.3116945846\n",
      "elapsed time 2602.16318297\n",
      "********************************************************************\n",
      "time: 2012-11-06 00:00:00\n",
      "portfolio: [-0.55085135  0.56164366  0.97697765 -0.05253109  0.93675154 -0.69845843\n",
      "  0.13119668 -0.50639302  0.35807022 -0.04068881]\n",
      "reward: 4.51498164457\n",
      "value: -34.79671294\n",
      "elapsed time 2628.27985597\n",
      "********************************************************************\n",
      "time: 2012-11-07 00:00:00\n",
      "portfolio: [-0.51697683  0.55400217  0.97569633 -0.03664815  0.91055024 -0.7595861\n",
      "  0.12239569 -0.48659936  0.39264587 -0.03154938]\n",
      "reward: -9.54150265579\n",
      "value: -44.3382155958\n",
      "elapsed time 2654.06854105\n",
      "********************************************************************\n",
      "time: 2012-11-08 00:00:00\n",
      "portfolio: [-0.44589016  0.57003784  0.9776358  -0.07689288  0.83379346 -0.804142\n",
      "  0.09092374 -0.49159837  0.46477053 -0.00566576]\n",
      "reward: -7.34636983671\n",
      "value: -51.6845854325\n",
      "elapsed time 2679.94966292\n",
      "********************************************************************\n",
      "time: 2012-11-09 00:00:00\n",
      "portfolio: [-0.378847    0.50809324  0.97967547 -0.0891435   0.74933267 -0.83359355\n",
      "  0.07432519 -0.53427845  0.4909825   0.03654788]\n",
      "reward: -11.7124212162\n",
      "value: -63.3970066487\n",
      "elapsed time 2705.96954703\n",
      "********************************************************************\n",
      "time: 2012-11-12 00:00:00\n",
      "portfolio: [-0.36753431  0.48722252  0.97612715 -0.04673962  0.72831184 -0.79682761\n",
      "  0.10967845 -0.6340363   0.52819312  0.0303591 ]\n",
      "reward: 7.36543366525\n",
      "value: -56.0315729834\n",
      "elapsed time 2731.79195499\n",
      "********************************************************************\n",
      "time: 2012-11-13 00:00:00\n",
      "portfolio: [-0.37808406  0.47735068  0.97067273 -0.01828883  0.72561753 -0.81852192\n",
      "  0.15204242 -0.61507893  0.55888867  0.01100428]\n",
      "reward: -7.59947771926\n",
      "value: -63.6310507027\n",
      "elapsed time 2757.71310186\n",
      "********************************************************************\n",
      "time: 2012-11-14 00:00:00\n",
      "portfolio: [-0.3778564   0.45624161  0.97964627 -0.05252549  0.69126105 -0.77197713\n",
      "  0.13552587 -0.60497916  0.5448972  -0.00848355]\n",
      "reward: 2.35268085239\n",
      "value: -61.2783698503\n",
      "elapsed time 2783.59126186\n",
      "********************************************************************\n",
      "time: 2012-11-15 00:00:00\n",
      "portfolio: [-0.45001471  0.48331887  0.98032671 -0.08625039  0.70880961 -0.74826247\n",
      "  0.10773771 -0.60956645  0.52522695  0.00489894]\n",
      "reward: -4.59359952758\n",
      "value: -65.8719693779\n",
      "elapsed time 2809.45961499\n",
      "********************************************************************\n",
      "time: 2012-11-16 00:00:00\n",
      "portfolio: [-0.46618828  0.50878674  0.97198379 -0.06807645  0.7069242  -0.80081224\n",
      "  0.14636615 -0.63640559  0.52318633  0.00986349]\n",
      "reward: -5.91946270273\n",
      "value: -71.7914320806\n",
      "elapsed time 2835.27580595\n",
      "********************************************************************\n",
      "time: 2012-11-19 00:00:00\n",
      "portfolio: [-0.48718092  0.44324785  0.95808065 -0.03576837  0.68679923 -0.76518553\n",
      "  0.14915763 -0.67623162  0.65991426 -0.02728136]\n",
      "reward: 8.11778373232\n",
      "value: -63.6736483483\n",
      "elapsed time 2861.34682894\n",
      "********************************************************************\n",
      "time: 2012-11-20 00:00:00\n",
      "portfolio: [-0.6048187   0.52718472  0.94060308 -0.01896491  0.61493421 -0.78920287\n",
      "  0.1293886  -0.6523993   0.67853093 -0.03802747]\n",
      "reward: 15.0922673976\n",
      "value: -48.5813809507\n",
      "elapsed time 2888.37562799\n",
      "********************************************************************\n",
      "time: 2012-11-21 00:00:00\n",
      "portfolio: [-0.60632843  0.54488128  0.89199632 -0.05645242  0.62156177 -0.75632131\n",
      "  0.14065453 -0.68192482  0.76567394 -0.04663441]\n",
      "reward: -4.08488861129\n",
      "value: -52.6662695619\n",
      "elapsed time 2914.33484483\n",
      "********************************************************************\n",
      "time: 2012-11-23 00:00:00\n",
      "portfolio: [-0.61807084  0.52736968  0.82999063  0.01371782  0.48953232 -0.76337135\n",
      "  0.18766098 -0.64463979  0.81289709 -0.03928738]\n",
      "reward: 1.25443758821\n",
      "value: -51.4118319737\n",
      "elapsed time 2940.32083488\n",
      "********************************************************************\n",
      "time: 2012-11-26 00:00:00\n",
      "portfolio: [-0.61218107  0.54024673  0.83615845  0.09687536  0.47296834 -0.73445547\n",
      "  0.063712   -0.66380084  0.80777037 -0.02271057]\n",
      "reward: 4.28588963575\n",
      "value: -47.125942338\n",
      "elapsed time 2966.37583399\n",
      "********************************************************************\n",
      "time: 2012-11-27 00:00:00\n",
      "portfolio: [-0.56782532  0.521456    0.84579927  0.09004724  0.61339927 -0.71687907\n",
      "  0.06056319 -0.72967708  0.76165855 -0.03742702]\n",
      "reward: 7.10913603751\n",
      "value: -40.0168063005\n",
      "elapsed time 2992.42789483\n",
      "********************************************************************\n",
      "time: 2012-11-28 00:00:00\n",
      "portfolio: [-0.58507293  0.57456946  0.82262373  0.05823365  0.60986245 -0.73370469\n",
      "  0.09671651 -0.73317814  0.76372844 -0.00938599]\n",
      "reward: -6.27011083074\n",
      "value: -46.2869171312\n",
      "elapsed time 3018.41566396\n",
      "********************************************************************\n",
      "time: 2012-11-29 00:00:00\n",
      "portfolio: [-0.49521714  0.64581871  0.84128237 -0.00134665  0.62570858 -0.72074723\n",
      "  0.06195815 -0.7323631   0.76809818 -0.00096078]\n",
      "reward: 7.8516639597\n",
      "value: -38.4352531715\n",
      "elapsed time 3044.15444493\n",
      "********************************************************************\n",
      "time: 2012-11-30 00:00:00\n",
      "portfolio: [-0.50561547  0.64396363  0.83836102 -0.03688751  0.60337198 -0.7157079\n",
      "  0.07330077 -0.77401441  0.77340442  0.02852963]\n",
      "reward: -2.14932929106\n",
      "value: -40.5845824626\n",
      "elapsed time 3069.97424483\n",
      "********************************************************************\n",
      "time: 2012-12-03 00:00:00\n",
      "portfolio: [ -6.08429253e-01   7.29118228e-01   7.93519795e-01  -1.90195460e-02\n",
      "   6.14733338e-01  -7.32145429e-01   6.79997280e-02  -6.96351469e-01\n",
      "   8.13478947e-01   4.90268867e-04]\n",
      "reward: 4.35245663558\n",
      "value: -36.232125827\n",
      "elapsed time 3095.70061898\n",
      "********************************************************************\n",
      "time: 2012-12-04 00:00:00\n",
      "portfolio: [-0.60576355  0.74020088  0.80462468 -0.0425896   0.56791091 -0.68242365\n",
      "  0.08593914 -0.7455951   0.82497674  0.01532339]\n",
      "reward: -8.83691209912\n",
      "value: -45.0690379261\n",
      "elapsed time 3121.49612689\n",
      "********************************************************************\n",
      "time: 2012-12-05 00:00:00\n",
      "portfolio: [-0.52104199  0.71459627  0.8879807  -0.11896792  0.49270877 -0.65484726\n",
      "  0.01571757 -0.70442939  0.86817348  0.04938868]\n",
      "reward: -9.98303656902\n",
      "value: -55.0520744951\n",
      "elapsed time 3147.35966182\n",
      "********************************************************************\n",
      "time: 2012-12-06 00:00:00\n",
      "portfolio: [-0.45510983  0.721425    0.88859439 -0.14309771  0.45809117 -0.57216239\n",
      " -0.03822555 -0.75872099  0.87616163  0.08682674]\n",
      "reward: -28.6231808934\n",
      "value: -83.6752553885\n",
      "elapsed time 3173.20155382\n",
      "********************************************************************\n",
      "time: 2012-12-07 00:00:00\n",
      "portfolio: [-0.44543314  0.7301017   0.87828356 -0.17001279  0.52804178 -0.55827504\n",
      " -0.01788682 -0.77872837  0.86500943  0.09838932]\n",
      "reward: 17.6214084222\n",
      "value: -66.0538469663\n",
      "elapsed time 3199.23046184\n",
      "********************************************************************\n",
      "time: 2012-12-10 00:00:00\n",
      "portfolio: [-0.39994526  0.69650662  0.87357128 -0.1090567   0.50304866 -0.55475926\n",
      "  0.00836178 -0.77498585  0.88440931  0.15494062]\n",
      "reward: -20.5517855509\n",
      "value: -86.6056325172\n",
      "elapsed time 3225.07528305\n",
      "********************************************************************\n",
      "time: 2012-12-11 00:00:00\n",
      "portfolio: [-0.44145596  0.76436365  0.83689815 -0.13218541  0.61673498 -0.63648248\n",
      " -0.01237522 -0.7204603   0.88567233  0.15974683]\n",
      "reward: 9.82183278385\n",
      "value: -76.7837997333\n",
      "elapsed time 3250.85475302\n",
      "********************************************************************\n",
      "time: 2012-12-12 00:00:00\n",
      "portfolio: [-0.49507537  0.77135402  0.84057194 -0.1592382   0.56521076 -0.66616654\n",
      "  0.02879292 -0.72913569  0.87572849  0.14467828]\n",
      "reward: 6.24794383382\n",
      "value: -70.5358558995\n",
      "elapsed time 3276.64437103\n",
      "********************************************************************\n",
      "time: 2012-12-13 00:00:00\n",
      "portfolio: [-0.54124129  0.72224605  0.86021543 -0.07381408  0.65041161 -0.62601268\n",
      "  0.07310205 -0.73359537  0.85368621  0.11346702]\n",
      "reward: -12.953883918\n",
      "value: -83.4897398175\n",
      "elapsed time 3302.40229702\n",
      "********************************************************************\n",
      "time: 2012-12-14 00:00:00\n",
      "portfolio: [-0.38517481  0.68689466  0.90669656 -0.17526002  0.51040161 -0.62229896\n",
      "  0.04702852 -0.70919251  0.89031267  0.15649052]\n",
      "reward: -12.209984355\n",
      "value: -95.6997241725\n",
      "elapsed time 3328.1969409\n",
      "********************************************************************\n",
      "time: 2012-12-17 00:00:00\n",
      "portfolio: [-0.44815052  0.6972785   0.90626168 -0.14433892  0.50057799 -0.51984251\n",
      "  0.06161645 -0.74287903  0.89456761  0.13473259]\n",
      "reward: -4.23243303268\n",
      "value: -99.9321572052\n",
      "elapsed time 3353.95179892\n",
      "********************************************************************\n",
      "time: 2012-12-18 00:00:00\n",
      "portfolio: [-0.34681204  0.70323944  0.90670997 -0.16951394  0.5283612  -0.60114664\n",
      "  0.11720943 -0.72460341  0.88335806  0.10866631]\n",
      "reward: 11.6117000318\n",
      "value: -88.3204571734\n",
      "elapsed time 3379.73441696\n",
      "********************************************************************\n",
      "time: 2012-12-19 00:00:00\n",
      "portfolio: [-0.28521463  0.67550129  0.91421318 -0.21393794  0.53484988 -0.58856046\n",
      "  0.10646746 -0.69282967  0.89330393  0.16831143]\n",
      "reward: 4.20634466403\n",
      "value: -84.1141125093\n",
      "elapsed time 3405.54297185\n",
      "********************************************************************\n",
      "time: 2012-12-20 00:00:00\n",
      "portfolio: [-0.30955693  0.66269654  0.91924971 -0.09598459  0.60309833 -0.57942486\n",
      "  0.06042576 -0.74009597  0.86170918  0.11183324]\n",
      "reward: -1.55808538344\n",
      "value: -85.6721978928\n",
      "elapsed time 3431.36068702\n",
      "********************************************************************\n",
      "time: 2012-12-21 00:00:00\n",
      "portfolio: [-0.29879719  0.64894843  0.92046517 -0.04727002  0.51217663 -0.70059246\n",
      "  0.05056443 -0.67907178  0.86577123  0.14181568]\n",
      "reward: -11.5294946222\n",
      "value: -97.201692515\n",
      "elapsed time 3457.02643895\n",
      "********************************************************************\n",
      "time: 2012-12-24 00:00:00\n",
      "portfolio: [-0.21073873  0.60250169  0.95242864  0.01393843  0.57441056 -0.70933408\n",
      "  0.00676864 -0.6799345   0.80555809  0.10873797]\n",
      "reward: 4.78470703826\n",
      "value: -92.4169854767\n",
      "elapsed time 3482.77175689\n",
      "********************************************************************\n",
      "time: 2012-12-26 00:00:00\n",
      "portfolio: [-0.24757814  0.47828144  0.95757836  0.05521005  0.64886624 -0.73309183\n",
      "  0.01285922 -0.62345123  0.77672249  0.15678518]\n",
      "reward: -0.245497898422\n",
      "value: -92.6624833752\n",
      "elapsed time 3508.68036389\n",
      "********************************************************************\n",
      "time: 2012-12-27 00:00:00\n",
      "portfolio: [-0.28433678  0.5565936   0.95962149 -0.02671135  0.62813795 -0.69521248\n",
      "  0.10229531 -0.68626046  0.69829679  0.1564327 ]\n",
      "reward: -2.39929407765\n",
      "value: -95.0617774528\n",
      "elapsed time 3534.60450101\n",
      "********************************************************************\n",
      "time: 2012-12-28 00:00:00\n",
      "portfolio: [-0.09254994  0.4964515   0.97265309 -0.08442707  0.69189763 -0.51388323\n",
      "  0.05268081 -0.72968924  0.64911699  0.12101461]\n",
      "reward: -1.91564577471\n",
      "value: -96.9774232275\n",
      "elapsed time 3560.4466629\n",
      "********************************************************************\n",
      "time: 2012-12-31 00:00:00\n",
      "portfolio: [ 0.00261191  0.38286805  0.97660029 -0.0470712   0.73780245 -0.59940672\n",
      " -0.02740102 -0.67245376  0.61808169  0.08656682]\n",
      "reward: 0.214392661385\n",
      "value: -96.7630305661\n",
      "elapsed time 3586.25499105\n",
      "********************************************************************\n",
      "time: 2013-01-02 00:00:00\n",
      "portfolio: [ 0.05902338  0.25823525  0.98291641  0.01000689  0.6070652  -0.62702\n",
      " -0.01628737 -0.64553922  0.65845817  0.04735058]\n",
      "reward: 17.3059839737\n",
      "value: -79.4570465925\n",
      "elapsed time 3612.03242302\n",
      "********************************************************************\n",
      "time: 2013-01-03 00:00:00\n",
      "portfolio: [ 0.10923902  0.27040473  0.98151058  0.02817191  0.7196371  -0.64524537\n",
      " -0.07150857 -0.64662969  0.56135726  0.03926511]\n",
      "reward: -1.66849042825\n",
      "value: -81.1255370207\n",
      "elapsed time 3637.956141\n",
      "********************************************************************\n",
      "time: 2013-01-04 00:00:00\n",
      "portfolio: [ 0.13908191  0.34695378  0.98029739  0.04887816  0.65224594 -0.56447506\n",
      "  0.02386497 -0.68009061  0.56127071  0.04527324]\n",
      "reward: -3.14501415568\n",
      "value: -84.2705511764\n",
      "elapsed time 3663.84498501\n",
      "********************************************************************\n",
      "time: 2013-01-07 00:00:00\n",
      "portfolio: [ 0.13242333  0.37964725  0.97916687  0.05117705  0.67239416 -0.50979549\n",
      "  0.0092945  -0.67966831  0.58122647  0.07194497]\n",
      "reward: -5.13540875677\n",
      "value: -89.4059599332\n",
      "elapsed time 3689.95363283\n",
      "********************************************************************\n",
      "time: 2013-01-08 00:00:00\n",
      "portfolio: [ 0.10046677  0.35298541  0.98137492  0.04734477  0.63239801 -0.47381032\n",
      "  0.0580405  -0.66352731  0.58148474  0.09083918]\n",
      "reward: 2.70107191868\n",
      "value: -86.7048880145\n",
      "elapsed time 3715.66113305\n",
      "********************************************************************\n",
      "time: 2013-01-09 00:00:00\n",
      "portfolio: [ 0.06268657  0.32836732  0.9816252   0.04868976  0.66716278 -0.44900641\n",
      "  0.06338993 -0.64923733  0.54256475  0.12079302]\n",
      "reward: -2.59738417291\n",
      "value: -89.3022721874\n",
      "elapsed time 3741.32516289\n",
      "********************************************************************\n",
      "time: 2013-01-10 00:00:00\n",
      "portfolio: [ 0.03990797  0.35332632  0.97772396  0.03083171  0.74567521 -0.42244402\n",
      "  0.08064473 -0.65721214  0.51182342  0.14427917]\n",
      "reward: 2.13486922176\n",
      "value: -87.1674029656\n",
      "elapsed time 3767.30981803\n",
      "********************************************************************\n",
      "time: 2013-01-11 00:00:00\n",
      "portfolio: [-0.03654607  0.37511563  0.97878617  0.0336157   0.7701875  -0.37801045\n",
      "  0.09342066 -0.57486606  0.54905617  0.12974283]\n",
      "reward: -2.52800058526\n",
      "value: -89.6954035509\n",
      "elapsed time 3793.22500086\n",
      "********************************************************************\n",
      "time: 2013-01-14 00:00:00\n",
      "portfolio: [-0.02862526  0.32110742  0.98566765  0.00501211  0.75621867 -0.30538005\n",
      "  0.09047565 -0.49065626  0.48622495  0.15887384]\n",
      "reward: -6.99099416572\n",
      "value: -96.6863977166\n",
      "elapsed time 3818.98397684\n",
      "********************************************************************\n",
      "time: 2013-01-15 00:00:00\n",
      "portfolio: [-0.03481904  0.39076373  0.98922002 -0.00145829  0.71286201 -0.29495686\n",
      "  0.08894896 -0.51557291  0.39383444  0.14304516]\n",
      "reward: -1.89716057889\n",
      "value: -98.5835582955\n",
      "elapsed time 3844.96076488\n",
      "********************************************************************\n",
      "time: 2013-01-16 00:00:00\n",
      "portfolio: [-0.06790625  0.41050777  0.99315381 -0.02186913  0.62182975 -0.24175118\n",
      "  0.03943888 -0.47492686  0.39228413  0.13642737]\n",
      "reward: -0.996724005983\n",
      "value: -99.5802823015\n",
      "elapsed time 3870.89943886\n",
      "********************************************************************\n",
      "time: 2013-01-17 00:00:00\n",
      "portfolio: [-0.14956695  0.48598516  0.9942534  -0.12375189  0.55338061 -0.4165059\n",
      "  0.07338628 -0.48588121  0.29922765  0.0998246 ]\n",
      "reward: 6.3378064944\n",
      "value: -93.2424758071\n",
      "elapsed time 3897.423908\n",
      "********************************************************************\n",
      "time: 2013-01-18 00:00:00\n",
      "portfolio: [-0.19959007  0.52918863  0.99382919 -0.2488147   0.60118264 -0.44610766\n",
      "  0.12820952 -0.47501329  0.22445546  0.10643762]\n",
      "reward: -4.96540931734\n",
      "value: -98.2078851244\n",
      "elapsed time 3924.09543896\n",
      "********************************************************************\n",
      "time: 2013-01-22 00:00:00\n",
      "portfolio: [-0.20562842  0.50989151  0.99422985 -0.08533546  0.63021266 -0.49348095\n",
      "  0.04658176 -0.35756111  0.18886776  0.09659873]\n",
      "reward: 3.1741048977\n",
      "value: -95.0337802267\n",
      "elapsed time 3950.64254093\n",
      "********************************************************************\n",
      "time: 2013-01-23 00:00:00\n",
      "portfolio: [-0.1894943   0.48601589  0.99350756 -0.11368996  0.65786827 -0.484308\n",
      "  0.09910866 -0.40949661  0.21887612  0.10740089]\n",
      "reward: 1.85913222966\n",
      "value: -93.1746479971\n",
      "elapsed time 3976.54515004\n",
      "********************************************************************\n",
      "time: 2013-01-24 00:00:00\n",
      "portfolio: [-0.1636578   0.45968017  0.99339533 -0.12287851  0.61590272 -0.49145201\n",
      "  0.0985963  -0.43415517  0.33228809  0.09910186]\n",
      "reward: -23.7044578404\n",
      "value: -116.879105838\n",
      "elapsed time 4002.54720402\n",
      "********************************************************************\n",
      "time: 2013-01-25 00:00:00\n",
      "portfolio: [-0.21102421  0.49827284  0.9925341  -0.0775467   0.61334497 -0.46910864\n",
      "  0.1145814  -0.3944554   0.37420604  0.09929938]\n",
      "reward: -3.6519979876\n",
      "value: -120.531103825\n",
      "elapsed time 4028.37056494\n",
      "********************************************************************\n",
      "time: 2013-01-28 00:00:00\n",
      "portfolio: [-0.19835453  0.5165379   0.99109274 -0.0180818   0.58985162 -0.48052916\n",
      "  0.13249603 -0.38119122  0.44419229  0.11122563]\n",
      "reward: -6.96145095717\n",
      "value: -127.492554782\n",
      "elapsed time 4054.29461098\n",
      "********************************************************************\n",
      "time: 2013-01-29 00:00:00\n",
      "portfolio: [-0.18553485  0.53011858  0.99233633 -0.11492781  0.50901121 -0.40598875\n",
      "  0.07738272 -0.39245704  0.45031387  0.12720555]\n",
      "reward: 10.914148577\n",
      "value: -116.578406205\n",
      "elapsed time 4080.21124101\n",
      "********************************************************************\n",
      "time: 2013-01-30 00:00:00\n",
      "portfolio: [-0.21011989  0.53341401  0.99241698 -0.12349799  0.51056278 -0.3340919\n",
      "  0.0935239  -0.38765773  0.42820567  0.13137606]\n",
      "reward: -0.638283628073\n",
      "value: -117.216689833\n",
      "elapsed time 4106.15950084\n",
      "********************************************************************\n",
      "time: 2013-01-31 00:00:00\n",
      "portfolio: [-0.10366498  0.48903018  0.99363983 -0.12475121  0.44962892 -0.32706246\n",
      "  0.09654121 -0.37869555  0.37231815  0.11475514]\n",
      "reward: -0.23970512373\n",
      "value: -117.456394957\n",
      "elapsed time 4132.03088999\n",
      "********************************************************************\n",
      "time: 2013-02-01 00:00:00\n",
      "portfolio: [-0.13574924  0.53584325  0.99396944 -0.18181893  0.46113968 -0.20923609\n",
      "  0.03382284 -0.31232056  0.4019689   0.12378328]\n",
      "reward: 1.27809025762\n",
      "value: -116.1783047\n",
      "elapsed time 4157.92601299\n",
      "********************************************************************\n",
      "time: 2013-02-04 00:00:00\n",
      "portfolio: [-0.15864371  0.53877592  0.99390322 -0.20014983  0.49968439 -0.2914739\n",
      "  0.03037958 -0.29680765  0.33382645  0.14770433]\n",
      "reward: -2.91851649228\n",
      "value: -119.096821192\n",
      "elapsed time 4183.85564303\n",
      "********************************************************************\n",
      "time: 2013-02-05 00:00:00\n",
      "portfolio: [-0.21015444  0.55950952  0.99347931 -0.09897075  0.50397539 -0.2732653\n",
      "  0.08549736 -0.29329157  0.29115304  0.1521534 ]\n",
      "reward: -5.15608735964\n",
      "value: -124.252908551\n",
      "elapsed time 4209.64399695\n",
      "********************************************************************\n",
      "time: 2013-02-06 00:00:00\n",
      "portfolio: [-0.15749124  0.55694759  0.99265772 -0.19062023  0.51702875 -0.3099826\n",
      "  0.08917727 -0.31178993  0.39790627  0.15885945]\n",
      "reward: 6.72954266059\n",
      "value: -117.523365891\n",
      "elapsed time 4235.60579491\n",
      "********************************************************************\n",
      "time: 2013-02-07 00:00:00\n",
      "portfolio: [-0.19739813  0.59625602  0.99305779 -0.20508951  0.52407289 -0.27281284\n",
      "  0.0627372  -0.28034228  0.39907402  0.13521574]\n",
      "reward: 3.89848183942\n",
      "value: -113.624884051\n",
      "elapsed time 4261.65421796\n",
      "********************************************************************\n",
      "time: 2013-02-08 00:00:00\n",
      "portfolio: [-0.10809883  0.62672943  0.9941867  -0.20110732  0.38790929 -0.20192894\n",
      "  0.06373879 -0.35314944  0.3343994   0.14727332]\n",
      "reward: 6.23275951222\n",
      "value: -107.392124539\n",
      "elapsed time 4287.50444698\n",
      "********************************************************************\n",
      "time: 2013-02-11 00:00:00\n",
      "portfolio: [-0.12788512  0.65482807  0.9945448  -0.27721503  0.35918069 -0.12300248\n",
      "  0.10964165 -0.3551774   0.28102103  0.14751008]\n",
      "reward: 1.31617640852\n",
      "value: -106.075948131\n",
      "elapsed time 4313.5006249\n",
      "********************************************************************\n",
      "time: 2013-02-12 00:00:00\n",
      "portfolio: [-0.10634745  0.62217909  0.99485862 -0.22132297  0.35469824 -0.21309133\n",
      "  0.11961028 -0.28387967  0.24317087  0.14618573]\n",
      "reward: 2.00235482919\n",
      "value: -104.073593301\n",
      "elapsed time 4339.51439095\n",
      "********************************************************************\n",
      "time: 2013-02-13 00:00:00\n",
      "portfolio: [-0.14862481  0.56957763  0.99517953 -0.21657018  0.38486519 -0.16677517\n",
      "  0.13360174 -0.2013766   0.25839099  0.12481974]\n",
      "reward: -7.10975460722\n",
      "value: -111.183347909\n",
      "elapsed time 4365.42386603\n",
      "********************************************************************\n",
      "time: 2013-02-14 00:00:00\n",
      "portfolio: [-0.15992185  0.60273385  0.99360108 -0.33092198  0.5547111  -0.19592638\n",
      "  0.05860612 -0.2736598   0.29533041  0.1302038 ]\n",
      "reward: -1.40854236015\n",
      "value: -112.591890269\n",
      "elapsed time 4391.40499783\n",
      "********************************************************************\n",
      "time: 2013-02-15 00:00:00\n",
      "portfolio: [-0.24025618  0.73459017  0.99153745 -0.387027    0.58528399 -0.18237229\n",
      "  0.06514822 -0.34360528  0.29945564  0.14357997]\n",
      "reward: 2.92735640449\n",
      "value: -109.664533864\n",
      "elapsed time 4417.32638597\n",
      "********************************************************************\n",
      "time: 2013-02-19 00:00:00\n",
      "portfolio: [-0.12941808  0.74543494  0.99274677 -0.28755465  0.46921465 -0.23148112\n",
      "  0.0233768  -0.42005917  0.25802195  0.16963618]\n",
      "reward: -5.60511963348\n",
      "value: -115.269653498\n",
      "elapsed time 4443.13779783\n",
      "********************************************************************\n",
      "time: 2013-02-20 00:00:00\n",
      "portfolio: [-0.16938819  0.78964996  0.99160528 -0.31008795  0.47128192 -0.17320226\n",
      "  0.10708346 -0.41266668  0.23635897  0.18218771]\n",
      "reward: -2.44343499195\n",
      "value: -117.71308849\n",
      "elapsed time 4469.07824492\n",
      "********************************************************************\n",
      "time: 2013-02-21 00:00:00\n",
      "portfolio: [-0.27023524  0.80332667  0.99110627 -0.30520648  0.46411303 -0.16232361\n",
      "  0.10994139 -0.3595674   0.19076745  0.22016484]\n",
      "reward: -9.67902535206\n",
      "value: -127.392113842\n",
      "elapsed time 4494.97321296\n",
      "********************************************************************\n",
      "time: 2013-02-22 00:00:00\n",
      "portfolio: [-0.18139611  0.77903557  0.98861074 -0.3206667   0.47510096 -0.20583905\n",
      "  0.13892695 -0.31960124  0.2443939   0.23506363]\n",
      "reward: 2.20341347172\n",
      "value: -125.18870037\n",
      "elapsed time 4520.75718904\n",
      "********************************************************************\n",
      "time: 2013-02-25 00:00:00\n",
      "portfolio: [-0.19404277  0.78099048  0.98123825 -0.35788971  0.53903902 -0.20031607\n",
      "  0.15759213 -0.33668518  0.21259497  0.24406587]\n",
      "reward: 3.3797889925\n",
      "value: -121.808911378\n",
      "elapsed time 4546.819417\n",
      "********************************************************************\n",
      "time: 2013-02-26 00:00:00\n",
      "portfolio: [-0.2771664   0.80212486  0.97739011 -0.37702358  0.55166018 -0.2516731\n",
      "  0.08665478 -0.24117874  0.13583839  0.26346785]\n",
      "reward: -8.20114584746\n",
      "value: -130.010057225\n",
      "elapsed time 4572.84209085\n",
      "********************************************************************\n",
      "time: 2013-02-27 00:00:00\n",
      "portfolio: [-0.31549579  0.80059141  0.9510451  -0.3586663   0.57088435 -0.2335494\n",
      "  0.1022106  -0.227446    0.17069085  0.26283455]\n",
      "reward: 3.6126976032\n",
      "value: -126.397359622\n",
      "elapsed time 4598.67391396\n",
      "********************************************************************\n",
      "time: 2013-02-28 00:00:00\n",
      "portfolio: [-0.30624279  0.79176986  0.90288478 -0.36474049  0.53217125 -0.20411223\n",
      "  0.09577851 -0.31845716  0.17084929  0.29523924]\n",
      "reward: -3.00839315839\n",
      "value: -129.40575278\n",
      "elapsed time 4624.44382191\n",
      "********************************************************************\n",
      "time: 2013-03-01 00:00:00\n",
      "portfolio: [-0.335758    0.8354876   0.82111526 -0.37616634  0.55878782 -0.18804683\n",
      "  0.09589678 -0.27757075  0.24871349  0.26471093]\n",
      "reward: -5.20208733318\n",
      "value: -134.607840113\n",
      "elapsed time 4650.318578\n",
      "********************************************************************\n",
      "time: 2013-03-04 00:00:00\n",
      "portfolio: [-0.34912261  0.80897522  0.81105036 -0.35644427  0.56871653 -0.21323676\n",
      "  0.11455366 -0.33961993  0.20038411  0.32139024]\n",
      "reward: -8.4842172376\n",
      "value: -143.092057351\n",
      "elapsed time 4677.10548997\n",
      "********************************************************************\n",
      "time: 2013-03-05 00:00:00\n",
      "portfolio: [-0.36912537  0.81556058  0.80477732 -0.36619058  0.58736676 -0.19024001\n",
      "  0.10173409 -0.33193958  0.22260049  0.31508711]\n",
      "reward: -4.74426693418\n",
      "value: -147.836324285\n",
      "elapsed time 4704.01610589\n",
      "********************************************************************\n",
      "time: 2013-03-06 00:00:00\n",
      "portfolio: [-0.4776026   0.81107169  0.81095248 -0.25540444  0.62799203 -0.16932417\n",
      "  0.12202284 -0.31883666  0.21931319  0.2771863 ]\n",
      "reward: 10.8717191365\n",
      "value: -136.964605149\n",
      "elapsed time 4730.19461894\n",
      "********************************************************************\n",
      "time: 2013-03-07 00:00:00\n",
      "portfolio: [-0.44036454  0.79369783  0.79583216 -0.31057519  0.61623728 -0.16787912\n",
      "  0.13423146 -0.38895941  0.22963423  0.30087489]\n",
      "reward: -8.51949169911\n",
      "value: -145.484096848\n",
      "elapsed time 4756.45600486\n",
      "********************************************************************\n",
      "time: 2013-03-08 00:00:00\n",
      "portfolio: [-0.48711264  0.81389129  0.76294482 -0.35858297  0.60842568 -0.17575583\n",
      "  0.13002098 -0.35623667  0.27478832  0.29017377]\n",
      "reward: 4.17511436162\n",
      "value: -141.308982486\n",
      "elapsed time 4782.22211695\n",
      "********************************************************************\n",
      "time: 2013-03-11 00:00:00\n",
      "portfolio: [-0.49990582  0.81941473  0.77408588 -0.38300937  0.63095349 -0.06554791\n",
      "  0.10169197 -0.43472108  0.25832346  0.32178929]\n",
      "reward: 0.180858517247\n",
      "value: -141.128123969\n",
      "elapsed time 4807.95873594\n",
      "********************************************************************\n",
      "time: 2013-03-12 00:00:00\n",
      "portfolio: [-0.60790199  0.83730769  0.7568422  -0.37565938  0.60464966 -0.09000241\n",
      "  0.10015067 -0.38748828  0.28800407  0.33054739]\n",
      "reward: 5.00888169698\n",
      "value: -136.119242272\n",
      "elapsed time 4833.82724094\n",
      "********************************************************************\n",
      "time: 2013-03-13 00:00:00\n",
      "portfolio: [-0.59382713  0.83348739  0.7697041  -0.40210748  0.60629523  0.0110302\n",
      "  0.10831922 -0.45175716  0.29435036  0.3236874 ]\n",
      "reward: -6.30595324751\n",
      "value: -142.42519552\n",
      "elapsed time 4859.69243789\n",
      "********************************************************************\n",
      "time: 2013-03-14 00:00:00\n",
      "portfolio: [-0.59779894  0.80440658  0.81189638 -0.39984086  0.65121436 -0.073277\n",
      "  0.1140353  -0.40939403  0.33378735  0.35070461]\n",
      "reward: 3.83888045159\n",
      "value: -138.586315068\n",
      "elapsed time 4885.29316688\n",
      "********************************************************************\n",
      "time: 2013-03-15 00:00:00\n",
      "portfolio: [-0.63022041  0.81662434  0.78889728 -0.40594181  0.64482135 -0.08552554\n",
      "  0.12678331 -0.39074203  0.35018253  0.36702505]\n",
      "reward: 3.39188816875\n",
      "value: -135.194426899\n",
      "elapsed time 4911.61931992\n",
      "********************************************************************\n",
      "time: 2013-03-18 00:00:00\n",
      "portfolio: [-0.65940195  0.82863969  0.73554742 -0.406441    0.67794228 -0.0951511\n",
      "  0.09098173 -0.44331583  0.33259749  0.34624127]\n",
      "reward: 2.30764300549\n",
      "value: -132.886783894\n",
      "elapsed time 4937.79871297\n",
      "********************************************************************\n",
      "time: 2013-03-19 00:00:00\n",
      "portfolio: [-0.69175017  0.83768189  0.71557379 -0.33965448  0.66992813 -0.12683032\n",
      "  0.08038431 -0.42666486  0.3166036   0.32755336]\n",
      "reward: 14.6521974302\n",
      "value: -118.234586464\n",
      "elapsed time 4963.90832496\n",
      "********************************************************************\n",
      "time: 2013-03-20 00:00:00\n",
      "portfolio: [-0.66105795  0.8210628   0.71438682 -0.34406957  0.72884905 -0.08271424\n",
      "  0.0919023  -0.50573063  0.28028142  0.33020356]\n",
      "reward: -1.62340471488\n",
      "value: -119.857991178\n",
      "elapsed time 4991.46727395\n",
      "********************************************************************\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-885ee1fcef1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDDPGConfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_stock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mddpg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDDPG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mddpg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-45-560879611a9b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;31m# select transition from pool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m                 \u001b[1;31m# update prioritizing paramter untill it goes over 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                 \u001b[1;31m# self.beta  += db\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-560879611a9b>\u001b[0m in \u001b[0;36mupdate_weight\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    215\u001b[0m         weights = [self.update_rate * new_w + (1 - self.update_rate) * old_w\n\u001b[0;32m    216\u001b[0m                    for new_w, old_w in zip(new_weights, old_weights)]\n\u001b[1;32m--> 217\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcritic_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mset_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m    493\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflattened_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[0mnb_param\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 495\u001b[1;33m             \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnb_param\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    496\u001b[0m             \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnb_param\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mset_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m    889\u001b[0m                                 'provided weight shape ' + str(w.shape))\n\u001b[0;32m    890\u001b[0m             \u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m         \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 995\u001b[1;33m         \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    996\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 766\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 964\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    965\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1014\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1015\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1022\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1003\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/contextlib.pyc\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.pyc\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_NewStatus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32myield\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetCode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m       raise _make_specific_exception(\n\u001b[0;32m    467\u001b[0m           \u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_stock = input_data.shape[-1]\n",
    "\n",
    "config = DDPGConfig(n_stock)\n",
    "ddpg = DDPG(config)\n",
    "values = ddpg.train(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-48ab06a8724d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "len(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tomoaki/work/github/jjakimoto.github.io/content\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
