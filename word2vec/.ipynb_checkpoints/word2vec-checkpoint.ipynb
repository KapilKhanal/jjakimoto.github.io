{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fetch data from http://ai.stanford.edu/~amaas/data/sentiment/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from six.moves import xrange, zip, map, filter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def review2wordlist(review, remove_stopwords=False):\n",
    "    review_text = BeautifulSoup(review, 'lxml').get_text()\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    words = review_text.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re \n",
    "from six.moves import xrange\n",
    "import os\n",
    "\n",
    "def get_data(file_dirs, remove_stopwords=False):\n",
    "    label = []\n",
    "    txt = []\n",
    "    comp_re = re.compile('(\\d+)_(\\d+).txt')\n",
    "    for file_dir in file_dirs:\n",
    "        name_list = [x for x in os.listdir(file_dir) if '.txt' in x]\n",
    "        for x in iter(name_list):\n",
    "            f = open(os.path.join(file_dir, x), 'r')\n",
    "            # word_list = review_to_wordlist(f.read(),  remove_stopwords)\n",
    "            review_text = BeautifulSoup(f.read(), 'lxml').get_text()\n",
    "            review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "            txt.append(review_text)\n",
    "            # txt.append(word_list)\n",
    "            f.close()\n",
    "            obj = comp_re.search(x)\n",
    "            star = float(obj.group(2))\n",
    "            if star > 5:\n",
    "                label.append(1)\n",
    "            else:\n",
    "                label.append(0)\n",
    "    return [txt, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.7 s, sys: 364 ms, total: 16.1 s\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_unlabeled = get_data(['./aclImdb/train/unsup'], remove_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.79 s, sys: 120 ms, total: 7.91 s\n",
      "Wall time: 7.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_labeled = get_data(['./aclImdb/train/pos', './aclImdb/train/neg'], remove_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Most reviews say that this is the weakest point in Hamilton s short movie career  This movie is a bit different from the rest  and considering it the best or the worst depends on what you expect from a movie  and what you expect from Hamilton Knowing Hamilton as a photographer  you can be slightly surprised  While Bilitis looks like his books in a movement with all those young girls discovering themselves and relations with each other on the edge of lesbian  with a plot connecting these scenes  Laura concentrates on few characters what enables developing relations among them  male female  artist model  but though we see beautiful photos  many of them better than his average  their number is reduced for the sake of the plot  Tendres cousines is different from both  it is only Hamilton s movie that looks more like a film than like a collection of moving photos  Because of that it can be acceptable to wider audience than Hamilton s fans  looking like an erotic comedy  but not German soft core type    Schulm dchen report  fans would be very disappointed   You won t laugh a lot  but you can smile  and that s something you don t often get from Hamilton   Unlike all other Hamilton s movies the age of female varies  Unlike other movies main character is a boy  Unlike his usual works this one isn t put out of place and out of time  We have characters that live their life  have their destiny and don t lead us only from one photo to another  from one nude girl to another Unfortunately  Hamilton  again  gets lost with a script in his hands  Girls on beaches  under shower  in low light rooms  in gardens  under tents  in front of mirrors  regardless of the amount of clothes   this is his territory  he can shoot minutes and hours  and whatever he does you ll always feel the artist s eye and hand behind it  But when he has to present us average everyday life he stops being Hamilton and becomes average director who just follows the script  Hamilton is best known for his nudes  but they are just a part of his work  And in Tendres cousines we have a reverse situation  his girls are not in the best shots  Nature  garden  house remind us on Hamilton s work  often neglected part of it   while girls  even when nude  don t have anything special in the way he presents us  Maybe Hamilton was confused having a boy in front of camera  maybe he was thinking about a line that censorship would accept  maybe he was really trying to make something new  and no one dared to tell him he shouldn t   but he neglected what he was mostly praised for '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labeled[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", \n",
    "                             tokenizer = None,    \n",
    "                             preprocessor = None, \n",
    "                             stop_words = None,   \n",
    "                             max_features = 5000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def get_bow(vectorizer, data):\n",
    "    bow = vectorizer.transform(data)\n",
    "    bow = normalize(bow, norm='l2', axis=1)\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.85 s, sys: 44 ms, total: 3.9 s\n",
      "Wall time: 3.82 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vectorizer.fit(train_labeled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bow = get_bow(vectorizer, train_labeled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.1 s, sys: 168 ms, total: 51.3 s\n",
      "Wall time: 50.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "forest.fit(bow, train_labeled[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.96 s, sys: 176 ms, total: 8.14 s\n",
      "Wall time: 8.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_data = get_data(['./aclImdb/test/pos', './aclImdb/test/neg'], remove_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_input, test_label = test_data\n",
    "# vectorizer.fit([' '.join(x)  for x in labeled_data[0]])\n",
    "test_bow = get_bow(vectorizer, test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = forest.predict(test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy(prediction, target):\n",
    "    return 1 - np.mean(np.abs(prediction - target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84328000000000003"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(output, test_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentences2wordlist(sentences):\n",
    "    return list(map(review2wordlist, sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.22 s, sys: 76 ms, total: 6.29 s\n",
      "Wall time: 6.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "labeled_reviews = sentences2wordlist(train_labeled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.7 s, sys: 188 ms, total: 12.8 s\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "unlabeled_reviews = sentences2wordlist(train_unlabeled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.48 s, sys: 96 ms, total: 6.58 s\n",
      "Wall time: 6.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_reviews = sentences2wordlist(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomoaki/anaconda2/lib/python2.7/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 29s, sys: 684 ms, total: 3min 30s\n",
      "Wall time: 58.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "model = Word2Vec(unlabeled_reviews + labeled_reviews, size=300, \n",
    "                 window=5, min_count=5, workers=4, max_vocab_size=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_average_vector(word2vec, wordlist):\n",
    "    wordlist = filter(lambda x: x in word2vec.vocab.keys(), wordlist)\n",
    "    vectors = np.array(list(map(lambda x: word2vec[x], wordlist)))\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "def sentences2avgvec(word2vec, sentences):\n",
    "    return np.array(list(map(lambda x: get_average_vector(word2vec, x), sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 58min 30s, sys: 1.74 s, total: 1h 58min 32s\n",
      "Wall time: 1h 58min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_average_vec = sentences2avgvec(model, labeled_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 1min 37s, sys: 2.57 s, total: 2h 1min 39s\n",
      "Wall time: 2h 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_average_vec = sentences2avgvec(model, test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomoaki/anaconda2/lib/python2.7/site-packages/keras/engine/topology.py:1656: UserWarning: Model inputs must come from a Keras Input layer, they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"sequential_3_model\" was not an Input tensor, it was generated by layer lambda_3.\n",
      "Note that input tensors are instantiated via `tensor = Input(shape)`.\n",
      "The tensor that caused the issue was: lambda_input_3:0\n",
      "  str(x.name))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D \n",
    "from keras.layers.core import Flatten, Lambda\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers import SpatialDropout2D\n",
    "from keras.layers import Dropout, Reshape\n",
    "from keras.layers import Embedding\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x, input_shape=[300]))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(50, name='hidden'))\n",
    "# model.add(BatchNormalization(mode=1))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(50))\n",
    "# model.add(BatchNormalization(mode=1))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid', name='output'))\n",
    "\n",
    "opt = Adam(lr=1e-3)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "0s - loss: 0.3284 - acc: 0.8636\n",
      "Epoch 2/100\n",
      "0s - loss: 0.3283 - acc: 0.8632\n",
      "Epoch 3/100\n",
      "0s - loss: 0.3279 - acc: 0.8637\n",
      "Epoch 4/100\n",
      "0s - loss: 0.3278 - acc: 0.8648\n",
      "Epoch 5/100\n",
      "0s - loss: 0.3278 - acc: 0.8640\n",
      "Epoch 6/100\n",
      "0s - loss: 0.3278 - acc: 0.8641\n",
      "Epoch 7/100\n",
      "0s - loss: 0.3275 - acc: 0.8643\n",
      "Epoch 8/100\n",
      "0s - loss: 0.3274 - acc: 0.8645\n",
      "Epoch 9/100\n",
      "0s - loss: 0.3273 - acc: 0.8650\n",
      "Epoch 10/100\n",
      "0s - loss: 0.3272 - acc: 0.8645\n",
      "Epoch 11/100\n",
      "0s - loss: 0.3271 - acc: 0.8642\n",
      "Epoch 12/100\n",
      "0s - loss: 0.3271 - acc: 0.8646\n",
      "Epoch 13/100\n",
      "0s - loss: 0.3269 - acc: 0.8642\n",
      "Epoch 14/100\n",
      "0s - loss: 0.3268 - acc: 0.8650\n",
      "Epoch 15/100\n",
      "0s - loss: 0.3267 - acc: 0.8653\n",
      "Epoch 16/100\n",
      "0s - loss: 0.3267 - acc: 0.8639\n",
      "Epoch 17/100\n",
      "0s - loss: 0.3267 - acc: 0.8646\n",
      "Epoch 18/100\n",
      "0s - loss: 0.3266 - acc: 0.8653\n",
      "Epoch 19/100\n",
      "0s - loss: 0.3264 - acc: 0.8650\n",
      "Epoch 20/100\n",
      "0s - loss: 0.3264 - acc: 0.8650\n",
      "Epoch 21/100\n",
      "0s - loss: 0.3264 - acc: 0.8647\n",
      "Epoch 22/100\n",
      "0s - loss: 0.3262 - acc: 0.8644\n",
      "Epoch 23/100\n",
      "0s - loss: 0.3264 - acc: 0.8643\n",
      "Epoch 24/100\n",
      "0s - loss: 0.3261 - acc: 0.8648\n",
      "Epoch 25/100\n",
      "0s - loss: 0.3259 - acc: 0.8653\n",
      "Epoch 26/100\n",
      "0s - loss: 0.3259 - acc: 0.8652\n",
      "Epoch 27/100\n",
      "0s - loss: 0.3258 - acc: 0.8653\n",
      "Epoch 28/100\n",
      "0s - loss: 0.3257 - acc: 0.8650\n",
      "Epoch 29/100\n",
      "0s - loss: 0.3258 - acc: 0.8651\n",
      "Epoch 30/100\n",
      "0s - loss: 0.3256 - acc: 0.8654\n",
      "Epoch 31/100\n",
      "0s - loss: 0.3255 - acc: 0.8657\n",
      "Epoch 32/100\n",
      "0s - loss: 0.3255 - acc: 0.8651\n",
      "Epoch 33/100\n",
      "0s - loss: 0.3255 - acc: 0.8658\n",
      "Epoch 34/100\n",
      "0s - loss: 0.3254 - acc: 0.8652\n",
      "Epoch 35/100\n",
      "0s - loss: 0.3254 - acc: 0.8655\n",
      "Epoch 36/100\n",
      "0s - loss: 0.3252 - acc: 0.8657\n",
      "Epoch 37/100\n",
      "0s - loss: 0.3253 - acc: 0.8656\n",
      "Epoch 38/100\n",
      "0s - loss: 0.3251 - acc: 0.8652\n",
      "Epoch 39/100\n",
      "0s - loss: 0.3250 - acc: 0.8652\n",
      "Epoch 40/100\n",
      "0s - loss: 0.3249 - acc: 0.8658\n",
      "Epoch 41/100\n",
      "0s - loss: 0.3249 - acc: 0.8649\n",
      "Epoch 42/100\n",
      "0s - loss: 0.3248 - acc: 0.8653\n",
      "Epoch 43/100\n",
      "0s - loss: 0.3248 - acc: 0.8654\n",
      "Epoch 44/100\n",
      "0s - loss: 0.3248 - acc: 0.8650\n",
      "Epoch 45/100\n",
      "0s - loss: 0.3249 - acc: 0.8652\n",
      "Epoch 46/100\n",
      "0s - loss: 0.3246 - acc: 0.8657\n",
      "Epoch 47/100\n",
      "0s - loss: 0.3247 - acc: 0.8648\n",
      "Epoch 48/100\n",
      "0s - loss: 0.3244 - acc: 0.8657\n",
      "Epoch 49/100\n",
      "0s - loss: 0.3244 - acc: 0.8652\n",
      "Epoch 50/100\n",
      "0s - loss: 0.3245 - acc: 0.8655\n",
      "Epoch 51/100\n",
      "0s - loss: 0.3243 - acc: 0.8653\n",
      "Epoch 52/100\n",
      "0s - loss: 0.3242 - acc: 0.8656\n",
      "Epoch 53/100\n",
      "0s - loss: 0.3242 - acc: 0.8655\n",
      "Epoch 54/100\n",
      "0s - loss: 0.3241 - acc: 0.8650\n",
      "Epoch 55/100\n",
      "0s - loss: 0.3241 - acc: 0.8654\n",
      "Epoch 56/100\n",
      "0s - loss: 0.3240 - acc: 0.8658\n",
      "Epoch 57/100\n",
      "0s - loss: 0.3240 - acc: 0.8661\n",
      "Epoch 58/100\n",
      "0s - loss: 0.3239 - acc: 0.8659\n",
      "Epoch 59/100\n",
      "0s - loss: 0.3239 - acc: 0.8656\n",
      "Epoch 60/100\n",
      "0s - loss: 0.3240 - acc: 0.8658\n",
      "Epoch 61/100\n",
      "0s - loss: 0.3237 - acc: 0.8650\n",
      "Epoch 62/100\n",
      "0s - loss: 0.3238 - acc: 0.8652\n",
      "Epoch 63/100\n",
      "0s - loss: 0.3238 - acc: 0.8652\n",
      "Epoch 64/100\n",
      "0s - loss: 0.3236 - acc: 0.8654\n",
      "Epoch 65/100\n",
      "0s - loss: 0.3235 - acc: 0.8658\n",
      "Epoch 66/100\n",
      "0s - loss: 0.3233 - acc: 0.8651\n",
      "Epoch 67/100\n",
      "0s - loss: 0.3235 - acc: 0.8655\n",
      "Epoch 68/100\n",
      "0s - loss: 0.3235 - acc: 0.8658\n",
      "Epoch 69/100\n",
      "0s - loss: 0.3233 - acc: 0.8656\n",
      "Epoch 70/100\n",
      "0s - loss: 0.3235 - acc: 0.8648\n",
      "Epoch 71/100\n",
      "0s - loss: 0.3231 - acc: 0.8660\n",
      "Epoch 72/100\n",
      "0s - loss: 0.3231 - acc: 0.8658\n",
      "Epoch 73/100\n",
      "0s - loss: 0.3231 - acc: 0.8655\n",
      "Epoch 74/100\n",
      "0s - loss: 0.3231 - acc: 0.8658\n",
      "Epoch 75/100\n",
      "0s - loss: 0.3229 - acc: 0.8655\n",
      "Epoch 76/100\n",
      "0s - loss: 0.3230 - acc: 0.8654\n",
      "Epoch 77/100\n",
      "0s - loss: 0.3229 - acc: 0.8656\n",
      "Epoch 78/100\n",
      "0s - loss: 0.3229 - acc: 0.8658\n",
      "Epoch 79/100\n",
      "0s - loss: 0.3227 - acc: 0.8661\n",
      "Epoch 80/100\n",
      "0s - loss: 0.3228 - acc: 0.8661\n",
      "Epoch 81/100\n",
      "0s - loss: 0.3229 - acc: 0.8657\n",
      "Epoch 82/100\n",
      "0s - loss: 0.3226 - acc: 0.8657\n",
      "Epoch 83/100\n",
      "0s - loss: 0.3227 - acc: 0.8655\n",
      "Epoch 84/100\n",
      "0s - loss: 0.3226 - acc: 0.8663\n",
      "Epoch 85/100\n",
      "0s - loss: 0.3227 - acc: 0.8662\n",
      "Epoch 86/100\n",
      "0s - loss: 0.3224 - acc: 0.8659\n",
      "Epoch 87/100\n",
      "0s - loss: 0.3224 - acc: 0.8664\n",
      "Epoch 88/100\n",
      "0s - loss: 0.3223 - acc: 0.8658\n",
      "Epoch 89/100\n",
      "0s - loss: 0.3224 - acc: 0.8658\n",
      "Epoch 90/100\n",
      "0s - loss: 0.3223 - acc: 0.8664\n",
      "Epoch 91/100\n",
      "0s - loss: 0.3223 - acc: 0.8670\n",
      "Epoch 92/100\n",
      "0s - loss: 0.3223 - acc: 0.8664\n",
      "Epoch 93/100\n",
      "0s - loss: 0.3222 - acc: 0.8667\n",
      "Epoch 94/100\n",
      "0s - loss: 0.3220 - acc: 0.8660\n",
      "Epoch 95/100\n",
      "0s - loss: 0.3221 - acc: 0.8657\n",
      "Epoch 96/100\n",
      "0s - loss: 0.3221 - acc: 0.8660\n",
      "Epoch 97/100\n",
      "0s - loss: 0.3221 - acc: 0.8661\n",
      "Epoch 98/100\n",
      "0s - loss: 0.3220 - acc: 0.8662\n",
      "Epoch 99/100\n",
      "0s - loss: 0.3219 - acc: 0.8659\n",
      "Epoch 100/100\n",
      "0s - loss: 0.3219 - acc: 0.8658\n",
      "CPU times: user 8.58 s, sys: 620 ms, total: 9.2 s\n",
      "Wall time: 5.27 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f055854fe50>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(train_average_vec, train_labeled[1], nb_epoch=100, batch_size=1000, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24864/25000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "output = model.predict_classes(test_average_vec)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy(prediction, target):\n",
    "    return 1 - np.mean(np.abs(prediction - target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86308000000000007"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(output, test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.4 s, sys: 72 ms, total: 29.5 s\n",
      "Wall time: 29.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "forest.fit(train_average_vec, train_labeled[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = forest.predict(test_average_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80496000000000001"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(output, test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re \n",
    "from six.moves import xrange\n",
    "import os\n",
    "\n",
    "def get_data(file_dirs, remove_stopwords=False):\n",
    "    label = []\n",
    "    txt = []\n",
    "    comp_re = re.compile('(\\d+)_(\\d+).txt')\n",
    "    for file_dir in file_dirs:\n",
    "        name_list = [x for x in os.listdir(file_dir) if '.txt' in x]\n",
    "        for x in iter(name_list):\n",
    "            f = open(os.path.join(file_dir, x), 'r')\n",
    "            # word_list = review_to_wordlist(f.read(),  remove_stopwords)\n",
    "            # review_text = BeautifulSoup(f.read(), 'lxml').get_text()\n",
    "            # review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "            # txt.append(review_text)\n",
    "            # txt.append(word_list)\n",
    "            txt.append(f.read())\n",
    "            f.close()\n",
    "            obj = comp_re.search(x)\n",
    "            star = float(obj.group(2))\n",
    "            if star > 5:\n",
    "                label.append(1)\n",
    "            else:\n",
    "                label.append(0)\n",
    "    return [txt, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "def review_to_sentences(review, remove_stopwords=False):\n",
    "    review = BeautifulSoup(review, 'lxml').get_text()\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentences) == 0:\n",
    "            continue\n",
    "        sentences.append(review_to_wordlist(raw_sentence, remove_stopwords))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 312 ms, sys: 268 ms, total: 580 ms\n",
      "Wall time: 577 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_unlabeled = get_data(['./aclImdb/train/unsup'], remove_stopwords=False)\n",
    "train_labeled = get_data(['./aclImdb/train/pos', './aclImdb/train/neg'], remove_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sentnces(data):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    ids = []\n",
    "    for idx, x in enumerate(data[0]):\n",
    "        _sentences = review_to_sentences(x)\n",
    "        if len(_sentences) == 0:\n",
    "            continue\n",
    "        sentences += _sentences\n",
    "        labels += [data[1][idx]] * len(_sentences)\n",
    "        ids += [idx]*len(_sentences)\n",
    "    return sentences, labels, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 47s, sys: 888 ms, total: 1min 48s\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "unlabeled_sentences, _, unlabeled_ids = get_sentnces(train_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(539897, 539897, 539897)\n"
     ]
    }
   ],
   "source": [
    "print(len(unlabeled_ids), len(unlabeled_sentences), len(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.2 s, sys: 616 ms, total: 54.9 s\n",
      "Wall time: 54.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "labeled_sentences, labeled_labels, labeled_ids = get_sentnces(train_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = [len(x) for x in labeled_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.774692175294586"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2b0c767c90>]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEACAYAAABPiSrXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2c1c2f82d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sorted(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 10s, sys: 1.66 s, total: 2min 11s\n",
      "Wall time: 44.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "model = Word2Vec(unlabeled_sentences + labeled_sentences, size=100, \n",
    "                 window=5, min_count=5, workers=4, max_vocab_size=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'girl', 0.8241639137268066),\n",
       " (u'lady', 0.7883622646331787),\n",
       " (u'man', 0.775084376335144),\n",
       " (u'prostitute', 0.7727598547935486),\n",
       " (u'widow', 0.7150318622589111),\n",
       " (u'nun', 0.7095363736152649),\n",
       " (u'lad', 0.7027652263641357),\n",
       " (u'person', 0.6869978308677673),\n",
       " (u'housewife', 0.6725583076477051),\n",
       " (u'boy', 0.6619994044303894)]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29494, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = dict([(k, v.index) for k, v in model.vocab.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_list = []\n",
    "for x in labeled_sentences:\n",
    "    word_list += x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 µs, sys: 1 µs, total: 10 µs\n",
      "Wall time: 39.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def word2index(word):\n",
    "    try:\n",
    "        return vocab[word]\n",
    "    except:\n",
    "        return None\n",
    "index = map(word2index, word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x187fefba8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = model.syn0\n",
    "np.save(open(\"embbeding.npy\", 'wb'), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, Input\n",
    "\n",
    "def w2v_embedding_layer(embeddings_path):\n",
    "    weights = np.load(open(embeddings_path, 'rb'))\n",
    "    layer = Embedding(input_dim=weights.shape[0], \n",
    "                      output_dim=weights.shape[1], \n",
    "                      weights=[weights])\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D \n",
    "from keras.layers.core import Flatten, Lambda\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers import SpatialDropout2D\n",
    "from keras.layers import Dropout, Reshape\n",
    "from keras.layers import Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "class CNN(object):\n",
    "    def __init__(self, conf, sentences):\n",
    "        self.model_config = conf.model_config\n",
    "        self.n_emb = conf.n_emb\n",
    "        self.min_word_count = conf.min_word_count\n",
    "        self.n_context = conf.n_context\n",
    "        self.n_workers = 4\n",
    "        self.algo = conf.algo\n",
    "        self.n_epoch = conf.n_epoch\n",
    "        self.batch_size = conf.batch_size\n",
    "        self.maxlen = conf.maxlen\n",
    "        self.learning_rate = conf.learning_rate\n",
    "        \n",
    "        print(\"build word2vec ...\")\n",
    "        self.word2vec = Word2Vec(sentences, workers=self.n_workers, \n",
    "            size=self.n_emb, min_count = self.min_word_count, \n",
    "            window = self.n_context, sg=self.algo)\n",
    "        print(\"finished!\")\n",
    "        \n",
    "        self.vocab = dict([(k, v.index) for k, v in self.word2vec.vocab.items()])\n",
    "        self.n_vocab = len(self.vocab)\n",
    "        index = self.word2indexes(sentences)\n",
    "        \n",
    "        # avoid creating _LEARNING_PHASE outside the network\n",
    "        tf.reset_default_graph()\n",
    "        K.clear_session()\n",
    "        self.sess = tf.Session()\n",
    "        print(\"buiild model ...\")\n",
    "        self.build_model()\n",
    "        print(\"finished\")\n",
    "        \n",
    "    def train(self, input_data, target_data):\n",
    "        print(\"start training\")\n",
    "        index_data = self.word2indexes(input_data)\n",
    "        self.model.fit(index_data, target_data, nb_epoch=self.n_epoch, batch_size=self.batch_size)\n",
    "        print(\"finished\")\n",
    "        \n",
    "    def predict(self, input_data):\n",
    "        index_data = self.word2index(input_data)\n",
    "        return self.model.predict(index_data)\n",
    "    \n",
    "    def word2index(self, sentence):\n",
    "        def w2i(x):\n",
    "            try:\n",
    "                return self.vocab[x]\n",
    "            except:\n",
    "                return None\n",
    "        index = map(w2i, sentence)\n",
    "        index = filter(lambda x: x is not None, index)\n",
    "        return list(index)\n",
    "    \n",
    "    def word2indexes(self, sentences):\n",
    "        index = map(self.word2index, sentences)\n",
    "        return pad_sequences(list(index), maxlen=self.maxlen)\n",
    "    \n",
    "    def build_model(self):\n",
    "        self.input = tf.placeholder(tf.int32, [None, self.maxlen], name=\"input\")\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(input_dim=self.n_vocab, output_dim=self.n_emb, \n",
    "                            input_length=self.maxlen, name=\"embedding\", weights=[self.word2vec.syn0]))\n",
    "        model.add(Reshape([self.maxlen, self.n_emb, 1]))\n",
    "        self.model = self.build_network(self.model_config, model=model)\n",
    "        \n",
    "        self.output = self.model(self.input)\n",
    "        opt = Adam(lr=self.learning_rate)\n",
    "        self.model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['acc'])\n",
    "    \n",
    "    def build_network(self, conf, model=None, input_shape=None, is_conv=True):\n",
    "        \"\"\"Build network\"\"\"\n",
    "        _model = model\n",
    "        model = Sequential()\n",
    "        if _model is None:\n",
    "            model.add(Lambda(lambda x: x,  input_shape=input_shape))\n",
    "        else:\n",
    "            model.add(_model)\n",
    "            \n",
    "        for x in conf:\n",
    "            if x['is_drop']:\n",
    "                model.add(Dropout(x['drop_rate']))\n",
    "                \n",
    "            if x['type'] is 'full':\n",
    "                if is_conv:\n",
    "                    model.add(Flatten())\n",
    "                    is_conv = False\n",
    "                model.add(Dense(x['n_feature']))\n",
    "            elif x['type'] is 'conv':\n",
    "                model.add(Convolution2D(nb_filter=x['n_feature'], \n",
    "                                        nb_row=x['kw'], \n",
    "                                        nb_col=1, \n",
    "                                        border_mode='same'))  \n",
    "                is_conv=True\n",
    "                \n",
    "            if x['is_batch']:\n",
    "                if x['type'] is 'full':\n",
    "                    model.add(BatchNormalization(mode=1, axis=-1))\n",
    "                if x['type'] is 'conv':\n",
    "                    model.add(BatchNormalization(mode=2, axis=-1))\n",
    "            \n",
    "            if x['activation'] is None:\n",
    "                pass\n",
    "            if x['activation'] is 'prelu':\n",
    "                model.add(PReLU())\n",
    "            else:\n",
    "                model.add(Activation(x['activation']))\n",
    "            \n",
    "            if type(x['n_pool']) is int:\n",
    "                model.add(MaxPooling2D(pool_size=(x['n_pool'], 1), border_mode='same'))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    device = '/gpu:0'\n",
    "    save_path = '/home/tomoaki/work/github/jjakimoto.github.io/content'\n",
    "    is_load = False\n",
    "    n_batch = 32\n",
    "    n_epoch = 10\n",
    "    learning_rate = 1e-4\n",
    "    n_emb = 100\n",
    "    min_word_count = 5\n",
    "    n_context = 10\n",
    "    n_worker = 4\n",
    "    algo = 1\n",
    "    batch_size = 256\n",
    "    maxlen = 20\n",
    "    \n",
    "    model_config = [{'type':'conv', 'n_feature': 32, 'kw': 5,\n",
    "                    'activation': 'prelu', 'is_batch': True, 'is_drop': False,\n",
    "                    'n_pool': None},\n",
    "                    {'type':'conv', 'n_feature': 64, 'kw': 5,\n",
    "                    'activation': 'prelu', 'is_batch': True, 'is_drop': False,\n",
    "                    'n_pool': 2},\n",
    "                    {'type':'conv', 'n_feature': 64, 'kw': 5,\n",
    "                     'activation': 'prelu', 'is_batch': True, 'is_drop': False,\n",
    "                    'n_pool': 2},\n",
    "                    {'type':'full', 'n_feature': 32, 'kw': 4,\n",
    "                    'activation': 'prelu', 'is_batch': True, 'is_drop': False,\n",
    "                    'n_pool': None},\n",
    "                    {'type':'full', 'n_feature': 1, 'kw': 4,\n",
    "                     'activation': 'sigmoid', 'is_batch': False, 'is_drop': False,\n",
    "                    'n_pool': None}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build word2vec ...\n",
      "finished!\n",
      "buiild model ...\n",
      "finished\n",
      "start training\n",
      "Epoch 1/10\n",
      "271908/271908 [==============================] - 249s - loss: 0.6145 - acc: 0.6544   \n",
      "Epoch 2/10\n",
      "271908/271908 [==============================] - 249s - loss: 0.5692 - acc: 0.6984   \n",
      "Epoch 3/10\n",
      "271908/271908 [==============================] - 253s - loss: 0.5451 - acc: 0.7179   \n",
      "Epoch 4/10\n",
      "271908/271908 [==============================] - 249s - loss: 0.5216 - acc: 0.7353   \n",
      "Epoch 5/10\n",
      "271908/271908 [==============================] - 251s - loss: 0.4956 - acc: 0.7553   \n",
      "Epoch 6/10\n",
      "271908/271908 [==============================] - 251s - loss: 0.4663 - acc: 0.7751   \n",
      "Epoch 7/10\n",
      "271908/271908 [==============================] - 251s - loss: 0.4335 - acc: 0.7957   \n",
      "Epoch 8/10\n",
      "113408/271908 [===========>..................] - ETA: 145s - loss: 0.3923 - acc: 0.8202"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-189-3718071fec2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# cnn = CNN(conf, labeled_sentences + unlabeled_sentences)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabeled_sentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabeled_sentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabeled_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-175-d03ba3ee1884>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_data, target_data)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"start training\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mindex_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2indexes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"finished\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    619\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m                               sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m   1117\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1118\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1119\u001b[1;33m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[0;32m   1120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[0;32m    835\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 837\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    838\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[0mupdated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 766\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 964\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    965\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1014\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1015\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1022\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1003\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "conf = Config()\n",
    "# cnn = CNN(conf, labeled_sentences + unlabeled_sentences)\n",
    "cnn = CNN(conf, labeled_sentences)\n",
    "cnn.train(labeled_sentences, labeled_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/Users/admin/pokemon/PokemonGo-Bot/src/pgoapi',\n",
       " '/Users/admin/anaconda/lib/python35.zip',\n",
       " '/Users/admin/anaconda/lib/python3.5',\n",
       " '/Users/admin/anaconda/lib/python3.5/plat-darwin',\n",
       " '/Users/admin/anaconda/lib/python3.5/lib-dynload',\n",
       " '/Users/admin/anaconda/lib/python3.5/site-packages',\n",
       " '/Users/admin/anaconda/lib/python3.5/site-packages/Sphinx-1.3.5-py3.5.egg',\n",
       " '/Users/admin/anaconda/lib/python3.5/site-packages/aeosa',\n",
       " '/Users/admin/anaconda/lib/python3.5/site-packages/IPython/extensions',\n",
       " '/Users/admin/.ipython']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PYTHONPATH'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f357497d4da7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PYTHONPATH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpathsep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/admin/anaconda/lib/python3.5/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PYTHONPATH'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTHONPATH'].split(os.pathsep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4], [2, 4, 5, 6]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def f(x):\n",
    "    if x == 2:\n",
    "        return None\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "index = map(f, [[1, 2, 3, 4], [2, 4, 5, 6]])\n",
    "print(list(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = filter(lambda x: x is not None, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [2, 4, 5, 6]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = dict([(k, v.index) for k, v in model.vocab.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4964"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['fury']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = labeled_sentences[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = map(lambda x: vocab[x], sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def w2v(word):\n",
    "    try:\n",
    "        return vocab[word]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = map(w2v, sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 299, 5, 2, 1073, 200]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29494"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.3 s, sys: 7.16 s, total: 35.5 s\n",
      "Wall time: 36.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y = [t**2 for t in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.47 s, sys: 3.68 s, total: 5.14 s\n",
      "Wall time: 5.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y = map(lambda t: t**2, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
