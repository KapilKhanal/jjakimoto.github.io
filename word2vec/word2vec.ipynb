{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fetch data from http://ai.stanford.edu/~amaas/data/sentiment/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from six.moves import xrange, zip\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def review_to_wordlist(review, remove_stopwords=False):\n",
    "    review_text = BeautifulSoup(review, 'lxml').get_text()\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    words = review_text.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re \n",
    "from six.moves import xrange\n",
    "import os\n",
    "\n",
    "def get_data(file_dirs, remove_stopwords=False):\n",
    "    label = []\n",
    "    txt = []\n",
    "    comp_re = re.compile('(\\d+)_(\\d+).txt')\n",
    "    for file_dir in file_dirs:\n",
    "        name_list = [x for x in os.listdir(file_dir) if '.txt' in x]\n",
    "        for x in iter(name_list):\n",
    "            f = open(os.path.join(file_dir, x), 'r')\n",
    "            # word_list = review_to_wordlist(f.read(),  remove_stopwords)\n",
    "            txt.append(f.read())\n",
    "            f.close()\n",
    "            obj = comp_re.search(x)\n",
    "            star = float(obj.group(2))\n",
    "            if star > 5:\n",
    "                label.append(1)\n",
    "            else:\n",
    "                label.append(0)\n",
    "    return [txt, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.9 s, sys: 680 ms, total: 22.6 s\n",
      "Wall time: 22.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_unlabeled = get_data(['./aclImdb/train/unsup'], remove_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.3 s, sys: 284 ms, total: 11.6 s\n",
      "Wall time: 11.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_labeled = get_data(['./aclImdb/train/pos', './aclImdb/train/neg'], remove_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", \n",
    "                             tokenizer = None,    \n",
    "                             preprocessor = None, \n",
    "                             stop_words = None,   \n",
    "                             max_features = 5000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_data(data):\n",
    "    new_data = []\n",
    "    for x in data:\n",
    "        new_data.append(' '.join(x))\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def get_bow(vectorizer, data):\n",
    "    data = convert_data(data)\n",
    "    bow = vectorizer.transform(data)\n",
    "    bow = normalize(bow, norm='l2', axis=1)\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.49 s, sys: 20 ms, total: 2.51 s\n",
      "Wall time: 2.43 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vectorizer.fit(convert_data(train_labeled[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomoaki/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the normalize function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "bow = get_bow(vectorizer, train_labeled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomoaki/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the normalize function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "bow = normalize(bow, norm='l2', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86692144686301076"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2c6e33afd0>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2bfe53d110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(bow.toarray()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 1s, sys: 76 ms, total: 7min 1s\n",
      "Wall time: 7min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 1000) \n",
    "forest.fit(bow, train_labeled[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2c16f9d490>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/T+sbztbo7ki8QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2c75dc32d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(forest.predict(bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.1 s, sys: 368 ms, total: 11.4 s\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_data = get_data(['./aclImdb/test/pos', './aclImdb/test/neg'], remove_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomoaki/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by the normalize function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "test_input, test_label = test_data\n",
    "# vectorizer.fit([' '.join(x)  for x in labeled_data[0]])\n",
    "test_bow = get_bow(vectorizer, test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = forest.predict(test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy(prediction, target):\n",
    "    return 1 - np.mean(np.abs(prediction - target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "def review_to_sentences(review, remove_stopwords=False):\n",
    "    review = BeautifulSoup(review, 'lxml').get_text()\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentences) == 0:\n",
    "            continue\n",
    "        sentences.append(review_to_wordlist(raw_sentence, remove_stopwords))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 392 ms, sys: 244 ms, total: 636 ms\n",
      "Wall time: 639 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_unlabeled = get_data(['./aclImdb/train/unsup'], remove_stopwords=False)\n",
    "train_labeled = get_data(['./aclImdb/train/pos', './aclImdb/train/neg'], remove_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sentnces(data):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    ids = []\n",
    "    for idx, x in enumerate(data[0]):\n",
    "        _sentences = review_to_sentences(x)\n",
    "        if len(_sentences) == 0:\n",
    "            continue\n",
    "        sentences += _sentences\n",
    "        labels += [data[1][idx]] * len(_sentences)\n",
    "        ids += [idx]*len(_sentences)\n",
    "    return sentences, labels, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 45s, sys: 704 ms, total: 1min 46s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "unlabeled_sentences, _, unlabeled_ids = get_sentnces(train_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(539897, 539897, 539897)\n"
     ]
    }
   ],
   "source": [
    "print(len(unlabeled_ids), len(unlabeled_sentences), len(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.4 s, sys: 260 ms, total: 52.6 s\n",
      "Wall time: 52.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "labeled_sentences, labeled_labels, labeled_ids = get_sentnces(train_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 8s, sys: 1.4 s, total: 2min 9s\n",
      "Wall time: 44.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "model = Word2Vec(unlabeled_sentences + labeled_sentences, size=100, \n",
    "                 window=5, min_count=5, workers=4, max_vocab_size=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'girl', 0.8187841176986694),\n",
       " (u'lady', 0.7666571736335754),\n",
       " (u'man', 0.7453933358192444),\n",
       " (u'widow', 0.723605215549469),\n",
       " (u'prostitute', 0.7163055539131165),\n",
       " (u'person', 0.6789537668228149),\n",
       " (u'monk', 0.6728273630142212),\n",
       " (u'lad', 0.6556423306465149),\n",
       " (u'teenager', 0.6553688049316406),\n",
       " (u'nun', 0.6540654301643372)]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47167, 100)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = dict([(k, v.index) for k, v in model.vocab.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_list = []\n",
    "for x in labeled_sentences:\n",
    "    word_list += x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.17 s, sys: 28 ms, total: 1.2 s\n",
      "Wall time: 1.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def word2index(word):\n",
    "    try:\n",
    "        return vocab[word]\n",
    "    except:\n",
    "        return None\n",
    "index = map(word2index, word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[87,\n",
       " 823,\n",
       " 135,\n",
       " 10,\n",
       " 9,\n",
       " 5,\n",
       " 0,\n",
       " 4436,\n",
       " 218,\n",
       " 7,\n",
       " 4515,\n",
       " 11,\n",
       " 348,\n",
       " 16,\n",
       " 585,\n",
       " 9,\n",
       " 16,\n",
       " 5,\n",
       " 2,\n",
       " 220,\n",
       " 260,\n",
       " 35,\n",
       " 0,\n",
       " 366,\n",
       " 1,\n",
       " 1064,\n",
       " 6,\n",
       " 0,\n",
       " 116,\n",
       " 40,\n",
       " 0,\n",
       " 247,\n",
       " 5963,\n",
       " 21,\n",
       " 46,\n",
       " 19,\n",
       " 508,\n",
       " 35,\n",
       " 2,\n",
       " 16,\n",
       " 1,\n",
       " 46,\n",
       " 19,\n",
       " 508,\n",
       " 35,\n",
       " 4515,\n",
       " 1216,\n",
       " 4515,\n",
       " 13,\n",
       " 2,\n",
       " 4006,\n",
       " 19,\n",
       " 49,\n",
       " 27,\n",
       " 1046,\n",
       " 764,\n",
       " 132,\n",
       " 0,\n",
       " 277,\n",
       " 37,\n",
       " 25,\n",
       " 1148,\n",
       " 7,\n",
       " 2,\n",
       " 2449,\n",
       " 14,\n",
       " 29,\n",
       " 145,\n",
       " 184,\n",
       " 528,\n",
       " 4881,\n",
       " 499,\n",
       " 1,\n",
       " 4902,\n",
       " 14,\n",
       " 251,\n",
       " 81,\n",
       " 21,\n",
       " 0,\n",
       " 1314,\n",
       " 3,\n",
       " 2270,\n",
       " 14,\n",
       " 2,\n",
       " 108,\n",
       " 9592,\n",
       " 130,\n",
       " 134,\n",
       " 2403,\n",
       " 9849,\n",
       " 21,\n",
       " 170,\n",
       " 100,\n",
       " 46,\n",
       " 14371,\n",
       " 3956,\n",
       " 4902,\n",
       " 766,\n",
       " 89,\n",
       " 878,\n",
       " 620,\n",
       " 1682,\n",
       " 2113,\n",
       " 17,\n",
       " 151,\n",
       " 69,\n",
       " 65,\n",
       " 318,\n",
       " 4687,\n",
       " 107,\n",
       " 3,\n",
       " 89,\n",
       " 125,\n",
       " 71,\n",
       " 25,\n",
       " 814,\n",
       " 61,\n",
       " 631,\n",
       " 5,\n",
       " 3688,\n",
       " 15,\n",
       " 0,\n",
       " 2143,\n",
       " 3,\n",
       " 0,\n",
       " 108,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 260,\n",
       " 35,\n",
       " 193,\n",
       " 6,\n",
       " 5,\n",
       " 63,\n",
       " 4515,\n",
       " 11,\n",
       " 16,\n",
       " 10,\n",
       " 277,\n",
       " 50,\n",
       " 37,\n",
       " 2,\n",
       " 18,\n",
       " 71,\n",
       " 37,\n",
       " 2,\n",
       " 1548,\n",
       " 3,\n",
       " 765,\n",
       " 4687,\n",
       " 84,\n",
       " 3,\n",
       " 10,\n",
       " 6,\n",
       " 49,\n",
       " 27,\n",
       " 3292,\n",
       " 4,\n",
       " 6426,\n",
       " 306,\n",
       " 71,\n",
       " 4515,\n",
       " 11,\n",
       " 432,\n",
       " 258,\n",
       " 37,\n",
       " 34,\n",
       " 2430,\n",
       " 200,\n",
       " 17,\n",
       " 22,\n",
       " 1048,\n",
       " 1849,\n",
       " 1946,\n",
       " 523,\n",
       " 0,\n",
       " 0,\n",
       " 3727,\n",
       " 432,\n",
       " 58,\n",
       " 27,\n",
       " 52,\n",
       " 662,\n",
       " 19,\n",
       " 381,\n",
       " 20,\n",
       " 442,\n",
       " 2,\n",
       " 169,\n",
       " 17,\n",
       " 19,\n",
       " 49,\n",
       " 1764,\n",
       " 1,\n",
       " 10,\n",
       " 11,\n",
       " 136,\n",
       " 19,\n",
       " 88,\n",
       " 20,\n",
       " 399,\n",
       " 74,\n",
       " 35,\n",
       " 4515,\n",
       " 991,\n",
       " 29,\n",
       " 81,\n",
       " 4515,\n",
       " 11,\n",
       " 97,\n",
       " 0,\n",
       " 566,\n",
       " 3,\n",
       " 620,\n",
       " 13507,\n",
       " 991,\n",
       " 81,\n",
       " 97,\n",
       " 285,\n",
       " 101,\n",
       " 5,\n",
       " 2,\n",
       " 391,\n",
       " 991,\n",
       " 25,\n",
       " 640,\n",
       " 507,\n",
       " 9,\n",
       " 28,\n",
       " 212,\n",
       " 20,\n",
       " 276,\n",
       " 43,\n",
       " 3,\n",
       " 262,\n",
       " 1,\n",
       " 43,\n",
       " 3,\n",
       " 56,\n",
       " 69,\n",
       " 26,\n",
       " 100,\n",
       " 10,\n",
       " 403,\n",
       " 61,\n",
       " 113,\n",
       " 26,\n",
       " 61,\n",
       " 5054,\n",
       " 1,\n",
       " 88,\n",
       " 20,\n",
       " 449,\n",
       " 176,\n",
       " 63,\n",
       " 35,\n",
       " 28,\n",
       " 4296,\n",
       " 4,\n",
       " 158,\n",
       " 35,\n",
       " 28,\n",
       " 2388,\n",
       " 232,\n",
       " 4,\n",
       " 158,\n",
       " 463,\n",
       " 4515,\n",
       " 173,\n",
       " 216,\n",
       " 400,\n",
       " 14,\n",
       " 2,\n",
       " 221,\n",
       " 7,\n",
       " 25,\n",
       " 919,\n",
       " 528,\n",
       " 21,\n",
       " 12374,\n",
       " 439,\n",
       " 3257,\n",
       " 7,\n",
       " 350,\n",
       " 609,\n",
       " 4289,\n",
       " 7,\n",
       " 12621,\n",
       " 439,\n",
       " 21013,\n",
       " 7,\n",
       " 959,\n",
       " 3,\n",
       " 7330,\n",
       " 2932,\n",
       " 3,\n",
       " 0,\n",
       " 1131,\n",
       " 3,\n",
       " 1694,\n",
       " 9,\n",
       " 5,\n",
       " 25,\n",
       " 3210,\n",
       " 23,\n",
       " 49,\n",
       " 1173,\n",
       " 225,\n",
       " 1,\n",
       " 584,\n",
       " 1,\n",
       " 821,\n",
       " 23,\n",
       " 123,\n",
       " 19,\n",
       " 231,\n",
       " 211,\n",
       " 228,\n",
       " 0,\n",
       " 1682,\n",
       " 11,\n",
       " 745,\n",
       " 1,\n",
       " 488,\n",
       " 505,\n",
       " 6,\n",
       " 17,\n",
       " 51,\n",
       " 23,\n",
       " 44,\n",
       " 4,\n",
       " 933,\n",
       " 176,\n",
       " 814,\n",
       " 2839,\n",
       " 113,\n",
       " 23,\n",
       " 2795,\n",
       " 106,\n",
       " 4515,\n",
       " 1,\n",
       " 461,\n",
       " 814,\n",
       " 152,\n",
       " 33,\n",
       " 41,\n",
       " 1104,\n",
       " 0,\n",
       " 221,\n",
       " 4515,\n",
       " 5,\n",
       " 116,\n",
       " 537,\n",
       " 15,\n",
       " 25,\n",
       " 0,\n",
       " 17,\n",
       " 31,\n",
       " 24,\n",
       " 41,\n",
       " 2,\n",
       " 171,\n",
       " 3,\n",
       " 25,\n",
       " 162,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 69,\n",
       " 26,\n",
       " 2,\n",
       " 7089,\n",
       " 870,\n",
       " 25,\n",
       " 528,\n",
       " 24,\n",
       " 22,\n",
       " 7,\n",
       " 0,\n",
       " 116,\n",
       " 671,\n",
       " 918,\n",
       " 3168,\n",
       " 320,\n",
       " 2972,\n",
       " 176,\n",
       " 21,\n",
       " 4515,\n",
       " 11,\n",
       " 162,\n",
       " 399,\n",
       " 6435,\n",
       " 171,\n",
       " 3,\n",
       " 6,\n",
       " 132,\n",
       " 528,\n",
       " 57,\n",
       " 51,\n",
       " 2388,\n",
       " 88,\n",
       " 20,\n",
       " 26,\n",
       " 235,\n",
       " 301,\n",
       " 7,\n",
       " 0,\n",
       " 94,\n",
       " 23,\n",
       " 2350,\n",
       " 176,\n",
       " 269,\n",
       " 4515,\n",
       " 12,\n",
       " 1448,\n",
       " 254,\n",
       " 2,\n",
       " 391,\n",
       " 7,\n",
       " 959,\n",
       " 3,\n",
       " 355,\n",
       " 269,\n",
       " 23,\n",
       " 12,\n",
       " 526,\n",
       " 42,\n",
       " 2,\n",
       " 340,\n",
       " 10,\n",
       " 7696,\n",
       " 58,\n",
       " 1757,\n",
       " 269,\n",
       " 23,\n",
       " 12,\n",
       " 64,\n",
       " 256,\n",
       " 4,\n",
       " 92,\n",
       " 136,\n",
       " 159,\n",
       " 1,\n",
       " 55,\n",
       " 28,\n",
       " 9835,\n",
       " 4,\n",
       " 375,\n",
       " 85,\n",
       " 23,\n",
       " 1504,\n",
       " 20,\n",
       " 17,\n",
       " 23,\n",
       " 6435,\n",
       " 46,\n",
       " 23,\n",
       " 12,\n",
       " 645,\n",
       " 6007,\n",
       " 15,\n",
       " 8,\n",
       " 211,\n",
       " 805,\n",
       " 0,\n",
       " 0,\n",
       " 36,\n",
       " 51,\n",
       " 59,\n",
       " 558,\n",
       " 1271,\n",
       " 1184,\n",
       " 11,\n",
       " 1235,\n",
       " 4,\n",
       " 0,\n",
       " 274,\n",
       " 339,\n",
       " 8,\n",
       " 415,\n",
       " 20,\n",
       " 860,\n",
       " 4,\n",
       " 105,\n",
       " 6,\n",
       " 3,\n",
       " 263,\n",
       " 69,\n",
       " 199,\n",
       " 109,\n",
       " 0,\n",
       " 3724,\n",
       " 3,\n",
       " 0,\n",
       " 1235,\n",
       " 51,\n",
       " 0,\n",
       " 842,\n",
       " 1235,\n",
       " 12,\n",
       " 21,\n",
       " 17,\n",
       " 10,\n",
       " 110,\n",
       " 398,\n",
       " 0,\n",
       " 926,\n",
       " 1,\n",
       " 3470,\n",
       " 5303,\n",
       " 45,\n",
       " 19,\n",
       " 305,\n",
       " 192,\n",
       " 94,\n",
       " 2072,\n",
       " 93,\n",
       " 19,\n",
       " 381,\n",
       " 20,\n",
       " 27,\n",
       " 764,\n",
       " 32,\n",
       " 0,\n",
       " 1070,\n",
       " 60,\n",
       " 1908,\n",
       " 8,\n",
       " 167,\n",
       " 50,\n",
       " 1102,\n",
       " 71,\n",
       " 2378,\n",
       " 8,\n",
       " 102,\n",
       " 0,\n",
       " 63,\n",
       " 150,\n",
       " 10,\n",
       " 3556,\n",
       " 70,\n",
       " 42,\n",
       " 0,\n",
       " 274,\n",
       " 12,\n",
       " 1184,\n",
       " 11,\n",
       " 1097,\n",
       " 17,\n",
       " 23,\n",
       " 66,\n",
       " 6,\n",
       " 9907,\n",
       " 165,\n",
       " 0,\n",
       " 36,\n",
       " 59,\n",
       " 7562,\n",
       " 360,\n",
       " 15,\n",
       " 0,\n",
       " 12,\n",
       " 0,\n",
       " 7621,\n",
       " 8,\n",
       " 95,\n",
       " 26,\n",
       " 1385,\n",
       " 206,\n",
       " 0,\n",
       " 6871,\n",
       " 25307,\n",
       " 3786,\n",
       " 13,\n",
       " 14,\n",
       " 0,\n",
       " 0,\n",
       " 9898,\n",
       " 12,\n",
       " 172,\n",
       " 220,\n",
       " 13,\n",
       " 208,\n",
       " 13,\n",
       " 0,\n",
       " 1235,\n",
       " 390,\n",
       " 8,\n",
       " 784,\n",
       " 3973,\n",
       " 51,\n",
       " 1184,\n",
       " 3023,\n",
       " 25,\n",
       " 488,\n",
       " 1,\n",
       " 27088,\n",
       " 30,\n",
       " 172,\n",
       " 0,\n",
       " 23,\n",
       " 10738,\n",
       " 132,\n",
       " 2639,\n",
       " 1,\n",
       " 3,\n",
       " 263,\n",
       " 0,\n",
       " 315,\n",
       " 3,\n",
       " 1988,\n",
       " 0,\n",
       " 10,\n",
       " 12,\n",
       " 34,\n",
       " 3844,\n",
       " 1621,\n",
       " 17,\n",
       " 93,\n",
       " 172,\n",
       " 288,\n",
       " 38,\n",
       " 11,\n",
       " 136,\n",
       " 8753,\n",
       " 3151,\n",
       " 70,\n",
       " 4744,\n",
       " 261,\n",
       " 25,\n",
       " 2061,\n",
       " 44,\n",
       " 4121,\n",
       " 2,\n",
       " 3173,\n",
       " 210,\n",
       " 35,\n",
       " 0,\n",
       " 26165,\n",
       " 15072,\n",
       " 23,\n",
       " 12,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 11,\n",
       " 80,\n",
       " 4,\n",
       " 65,\n",
       " 85,\n",
       " 74,\n",
       " 344,\n",
       " 36,\n",
       " 68,\n",
       " 146,\n",
       " 14,\n",
       " 1184,\n",
       " 46,\n",
       " 8,\n",
       " 1924,\n",
       " 35,\n",
       " 9,\n",
       " 7442,\n",
       " 12,\n",
       " 110,\n",
       " 282,\n",
       " 10364,\n",
       " 5071,\n",
       " 126,\n",
       " 2164,\n",
       " 15,\n",
       " 235,\n",
       " 31,\n",
       " 66,\n",
       " 1781,\n",
       " 4,\n",
       " 5071,\n",
       " 0,\n",
       " 1475,\n",
       " 1,\n",
       " 131,\n",
       " 0,\n",
       " 246,\n",
       " 165,\n",
       " 0,\n",
       " 733,\n",
       " 314,\n",
       " 15,\n",
       " 0,\n",
       " 10364,\n",
       " 66,\n",
       " 63,\n",
       " 223,\n",
       " 312,\n",
       " 3,\n",
       " 177,\n",
       " 10,\n",
       " 916,\n",
       " 4,\n",
       " 27,\n",
       " 223,\n",
       " 1,\n",
       " 0,\n",
       " 2164,\n",
       " 12,\n",
       " 2,\n",
       " 1509,\n",
       " 464,\n",
       " 0,\n",
       " 215,\n",
       " 1235,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 360,\n",
       " 4,\n",
       " 276,\n",
       " 2,\n",
       " 169,\n",
       " 50,\n",
       " 162,\n",
       " 78,\n",
       " 61,\n",
       " 5363,\n",
       " 2104,\n",
       " 0,\n",
       " 1269,\n",
       " 1164,\n",
       " 2137,\n",
       " 1,\n",
       " 3517,\n",
       " 2,\n",
       " 1025,\n",
       " 631,\n",
       " 3,\n",
       " 81,\n",
       " 8497,\n",
       " 8971,\n",
       " 43,\n",
       " 4,\n",
       " 2271,\n",
       " 0,\n",
       " 94,\n",
       " 31,\n",
       " 117,\n",
       " 12,\n",
       " 160,\n",
       " 348,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1184,\n",
       " 44,\n",
       " 34,\n",
       " 3699,\n",
       " 5030,\n",
       " 15,\n",
       " 2511,\n",
       " 1,\n",
       " 1146,\n",
       " 1107,\n",
       " 17,\n",
       " 774,\n",
       " 4,\n",
       " 0,\n",
       " 54,\n",
       " 2,\n",
       " 169,\n",
       " 4,\n",
       " 64,\n",
       " 2916,\n",
       " 13,\n",
       " 23,\n",
       " 199,\n",
       " 37,\n",
       " 1,\n",
       " 427,\n",
       " 1184,\n",
       " 1,\n",
       " 11355,\n",
       " 24,\n",
       " 3528,\n",
       " 158,\n",
       " 3,\n",
       " 130,\n",
       " 0,\n",
       " 443,\n",
       " 0,\n",
       " 192,\n",
       " 94,\n",
       " 182,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 49,\n",
       " 20,\n",
       " 860,\n",
       " 4,\n",
       " 74,\n",
       " 59,\n",
       " 919,\n",
       " 21,\n",
       " 6,\n",
       " 199,\n",
       " 45,\n",
       " 19,\n",
       " 112,\n",
       " 15124,\n",
       " 1,\n",
       " 40,\n",
       " 2106,\n",
       " 333,\n",
       " 17014,\n",
       " 254,\n",
       " 2,\n",
       " 137,\n",
       " 19,\n",
       " 26,\n",
       " 4,\n",
       " 105,\n",
       " 9,\n",
       " 8,\n",
       " 4928,\n",
       " 19,\n",
       " 112,\n",
       " 6,\n",
       " 6,\n",
       " 11,\n",
       " 52,\n",
       " 409,\n",
       " 7,\n",
       " 1157,\n",
       " 4,\n",
       " 2167,\n",
       " 0,\n",
       " 19,\n",
       " 2722,\n",
       " 24,\n",
       " 2,\n",
       " 542,\n",
       " 8,\n",
       " 12,\n",
       " 36,\n",
       " 1505,\n",
       " 32,\n",
       " 0,\n",
       " 126,\n",
       " 1718,\n",
       " 0,\n",
       " 1406,\n",
       " 1,\n",
       " 0,\n",
       " 187,\n",
       " 10,\n",
       " 19,\n",
       " 163,\n",
       " 1746,\n",
       " 41,\n",
       " 1111,\n",
       " 1064,\n",
       " 46,\n",
       " 34,\n",
       " 21791,\n",
       " 861,\n",
       " 1235,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1184,\n",
       " 2137,\n",
       " 1,\n",
       " 0,\n",
       " 366,\n",
       " 3,\n",
       " 0,\n",
       " 733,\n",
       " 363,\n",
       " 3721,\n",
       " 15,\n",
       " 3889,\n",
       " 6,\n",
       " 119,\n",
       " 4,\n",
       " 102,\n",
       " 10,\n",
       " 2,\n",
       " 2321,\n",
       " 1372,\n",
       " 733,\n",
       " 95,\n",
       " 26,\n",
       " 3456,\n",
       " 36,\n",
       " 72,\n",
       " 5,\n",
       " 367,\n",
       " 5284,\n",
       " 19,\n",
       " 147,\n",
       " 29,\n",
       " 392,\n",
       " 174,\n",
       " 11,\n",
       " 2010,\n",
       " 5,\n",
       " 34,\n",
       " 947,\n",
       " 1088,\n",
       " 6,\n",
       " 11,\n",
       " 2,\n",
       " 1582,\n",
       " 15,\n",
       " 2,\n",
       " 2248,\n",
       " 1735,\n",
       " 20667,\n",
       " 16,\n",
       " 10,\n",
       " 149,\n",
       " 20,\n",
       " 3011,\n",
       " 1,\n",
       " 82,\n",
       " 77,\n",
       " 110,\n",
       " 3011,\n",
       " 30,\n",
       " 217,\n",
       " 22,\n",
       " 7,\n",
       " 9,\n",
       " 810,\n",
       " 14,\n",
       " 130,\n",
       " 100,\n",
       " 154,\n",
       " 1,\n",
       " 108,\n",
       " 340,\n",
       " 559,\n",
       " 36,\n",
       " 0,\n",
       " 16,\n",
       " 5,\n",
       " 28,\n",
       " 195,\n",
       " 9265,\n",
       " 57,\n",
       " 50,\n",
       " 71,\n",
       " 1644,\n",
       " 2839,\n",
       " 144,\n",
       " 16,\n",
       " 4020,\n",
       " 0,\n",
       " 1582,\n",
       " 82,\n",
       " 3425,\n",
       " 19,\n",
       " 29,\n",
       " 54,\n",
       " 15,\n",
       " 160,\n",
       " 7,\n",
       " 10,\n",
       " 3091,\n",
       " 8,\n",
       " 64,\n",
       " 157,\n",
       " 20,\n",
       " 419,\n",
       " 9,\n",
       " 348,\n",
       " 1088,\n",
       " 51,\n",
       " 148,\n",
       " 9,\n",
       " 1582,\n",
       " 6,\n",
       " 161,\n",
       " 19,\n",
       " 5021,\n",
       " 1,\n",
       " 2294,\n",
       " 15,\n",
       " 50,\n",
       " 1,\n",
       " 30,\n",
       " 0,\n",
       " 168,\n",
       " 56,\n",
       " 610,\n",
       " 1,\n",
       " 368,\n",
       " 19,\n",
       " ...]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = model.syn0\n",
    "np.save(open(\"embbeding.npy\", 'wb'), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, Input\n",
    "\n",
    "def w2v_embedding_layer(embeddings_path):\n",
    "    weights = np.load(open(embeddings_path, 'rb'))\n",
    "    layer = Embedding(input_dim=weights.shape[0], \n",
    "                      output_dim=weights.shape[1], \n",
    "                      weights=[weights])\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D \n",
    "from keras.layers.core import Flatten, Lambda\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers import SpatialDropout2D\n",
    "from keras.layers import Dropout, Reshape\n",
    "from keras.layers import Embedding\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "class CNN(object):\n",
    "    def __init__(self, conf, sentences):\n",
    "        self.model_config = conf.model_config\n",
    "        self.n_emb = conf.n_emb\n",
    "        self.min_word_count = conf.min_word_count\n",
    "        self.n_context = conf.n_context\n",
    "        self.n_workers = 4\n",
    "        self.algo = conf.algo\n",
    "        self.n_epoch = conf.n_epoch\n",
    "        self.batch_size = conf.batch_size\n",
    "        \n",
    "        print(\"build word2vec ...\")\n",
    "        self.word2vec = Word2Vec(sentences, workers=self.n_workers, \n",
    "            size=self.n_emb, min_count = self.min_word_count, \n",
    "            window = self.n_context, sg=self.algo)\n",
    "        print(\"finished!\")\n",
    "        \n",
    "        self.vocab = dict([(k, v.index) for k, v in self.word2vec.vocab.items()])\n",
    "        self.n_vocab = len(self.vocab)\n",
    "        self.maxlen = None\n",
    "        index = self.word2index(sentences)\n",
    "        self.maxlen = len(index[0])\n",
    "        \n",
    "        # avoid creating _LEARNING_PHASE outside the network\n",
    "        tf.reset_default_graph()\n",
    "        K.clear_session()\n",
    "        self.sess = tf.Session()\n",
    "        print(\"buiild model ...\")\n",
    "        self.build_model()\n",
    "        print(\"finished\")\n",
    "        \n",
    "    def train(self, input_data, target_data):\n",
    "        print(\"start training\")\n",
    "        index_data = self.word2index(input_data)\n",
    "        self.model.fit(index_data, target_data, nb_epoch=self.n_epoch, batch_size=self.batch_size)\n",
    "        print(\"finished\")\n",
    "        \n",
    "    def predict(self, input_data):\n",
    "        index_data = self.word2index(input_data)\n",
    "        return self.model.predict(index_data)\n",
    "        \n",
    "    def word2index(self, sentences):\n",
    "        index = []\n",
    "        for sentence in iter(sentences):\n",
    "            index.append([self.vocab[w] for w in sentence if w in self.vocab.keys()])\n",
    "        return pad_sequences(index, maxlen=self.maxlen)\n",
    "    \n",
    "    def build_model(self):\n",
    "        self.input = tf.placeholder(tf.int32, [None, self.maxlen], name=\"input\")\n",
    "        self.model = self.build_cnn()\n",
    "        self.output = self.model(self.input)\n",
    "        self.model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "    \n",
    "    def build_cnn(self):\n",
    "        \"\"\"Build network\"\"\"\n",
    "        model = Sequential()\n",
    "        # embedding\n",
    "        model.add(Embedding(input_dim=self.n_vocab, output_dim=self.n_emb, \n",
    "                            input_length=self.maxlen, name=\"embedding\", weights=[self.word2vec.syn0]))\n",
    "        model.add(Reshape([self.maxlen, self.n_emb, 1]))\n",
    "        # layer 1\n",
    "        nf = self.n_feature\n",
    "        model.add(Convolution2D(nb_filter=nf, nb_row=self.k_w, nb_col=1, \n",
    "                                border_mode='same', name=\"layer1\"))\n",
    "        model.add(BatchNormalization(mode=2, axis=-1))\n",
    "        model.add(PReLU())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 1), strides=None))\n",
    "        # layer2\n",
    "        nf = nf * 2\n",
    "        model.add(Convolution2D(nb_filter=nf, nb_row=self.k_w, nb_col=1, \n",
    "                                border_mode='same', name=\"layer2\"))\n",
    "        model.add(BatchNormalization(mode=2, axis=-1))\n",
    "        model.add(PReLU())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 1), strides=None))\n",
    "        model.add(Flatten())\n",
    "        # layer3\n",
    "        model.add(Dense(self.n_output, activation=\"sigmoid\",\n",
    "                       name=\"output_layer\"))\n",
    "        # model.add(BatchNormalization(mode=1, axis=-1))\n",
    "        return model\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    device = '/gpu:0'\n",
    "    save_path = '/home/tomoaki/work/github/jjakimoto.github.io/content'\n",
    "    is_load = False\n",
    "    n_batch = 32\n",
    "    n_epoch = 10\n",
    "    learning_rate = 1e-2\n",
    "    n_emb = 100\n",
    "    min_word_count = 10\n",
    "    n_context = 10\n",
    "    n_worker = 4\n",
    "    algo = 1\n",
    "    n_epoch=1\n",
    "    batch_size = 64\n",
    "    \n",
    "    model_config = [{'type':'conv', 'n_feature': 32, 'kw': 4,\n",
    "                    'activation': PReLU(), 'is_batch': True, 'is_drop': False,\n",
    "                    'n_pool': 2},\n",
    "                    {'type':'conv', 'n_feature': 64, 'kw': 4,\n",
    "                    'activation': PReLU(), 'is_batch': True, 'is_drop': False,\n",
    "                    'n_pool': 2},\n",
    "                    {'type':'conv', 'n_feature': 32, 'kw': 4,\n",
    "                     'activation': PReLU(), 'is_batch': True, 'is_drop': False,\n",
    "                    'n_pool': 2},\n",
    "                    {'type':'full', 'n_feature': 32, 'kw': 4,\n",
    "                    'activation': PReLU(), 'is_batch': True, 'is_drop': False,\n",
    "                    'n_pool': None},\n",
    "                    {'type':'full', 'n_feature': 1, 'kw': 4,\n",
    "                     'activation': Activation('sigmoid'), 'is_batch': False, 'is_drop': False,\n",
    "                    'n_pool': None}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build word2vec ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-2aa424a1ed83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtarget_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentiment\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-70-f645a9fdd46e>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, conf, sentences)\u001b[0m\n\u001b[1;32m     34\u001b[0m         self.word2vec = model = Word2Vec(sentences, workers=self.n_workers, \n\u001b[1;32m     35\u001b[0m             \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_word_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             window = self.n_context, sg=self.algo)\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"finished!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/admin/anaconda/lib/python3.5/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab, batch_words)\u001b[0m\n\u001b[1;32m    471\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You can't pass a generator as the sentences argument. Try an iterator.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_cum_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m31\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/admin/anaconda/lib/python3.5/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, total_words, word_count, total_examples, queue_factor, report_delay)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocks if workers too slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# a thread reporting that it finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/admin/anaconda/lib/python3.5/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/admin/anaconda/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "target_data = train[\"sentiment\"]\n",
    "cnn = CNN(conf, sentences)\n",
    "cnn.train(sentences, target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/Users/admin/pokemon/PokemonGo-Bot/src/pgoapi',\n",
       " '/Users/admin/anaconda/lib/python35.zip',\n",
       " '/Users/admin/anaconda/lib/python3.5',\n",
       " '/Users/admin/anaconda/lib/python3.5/plat-darwin',\n",
       " '/Users/admin/anaconda/lib/python3.5/lib-dynload',\n",
       " '/Users/admin/anaconda/lib/python3.5/site-packages',\n",
       " '/Users/admin/anaconda/lib/python3.5/site-packages/Sphinx-1.3.5-py3.5.egg',\n",
       " '/Users/admin/anaconda/lib/python3.5/site-packages/aeosa',\n",
       " '/Users/admin/anaconda/lib/python3.5/site-packages/IPython/extensions',\n",
       " '/Users/admin/.ipython']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PYTHONPATH'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f357497d4da7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PYTHONPATH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpathsep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/admin/anaconda/lib/python3.5/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PYTHONPATH'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTHONPATH'].split(os.pathsep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
