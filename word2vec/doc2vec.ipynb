{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fetch data from http://ai.stanford.edu/~amaas/data/sentiment/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from six.moves import xrange, zip, map, filter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def review2wordlist(review, remove_stopwords=False):\n",
    "    review_text = BeautifulSoup(review, 'lxml').get_text()\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    words = review_text.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re \n",
    "from six.moves import xrange\n",
    "import os\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "def get_document(file_dirs):\n",
    "    documents = []\n",
    "    label=[]\n",
    "    comp_re = re.compile('(\\d+)_(\\d+).txt')\n",
    "    for file_dir in file_dirs:\n",
    "        name_list = [x for x in os.listdir(file_dir) if '.txt' in x]\n",
    "        for x in iter(name_list):\n",
    "            obj = comp_re.search(x)\n",
    "            f = open(os.path.join(file_dir, x), 'r')\n",
    "            # word_list = review_to_wordlist(f.read(),  remove_stopwords)\n",
    "            review_text = BeautifulSoup(f.read(), 'lxml').get_text()\n",
    "            review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "            wordlist = review_text.lower().split()\n",
    "            documents.append(TaggedDocument(words=wordlist, tags=[int(obj.group(1))]))\n",
    "            f.close()\n",
    "            star = float(obj.group(2))\n",
    "            if star > 5:\n",
    "                label.append(1)\n",
    "            else:\n",
    "                label.append(0)\n",
    "    return [documents, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.5 s, sys: 560 ms, total: 22 s\n",
      "Wall time: 22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_unlabeled = get_document(['./aclImdb/train/unsup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 s, sys: 216 ms, total: 10.2 s\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_labeled = get_document(['./aclImdb/train/pos', './aclImdb/train/neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.doc2vec.TaggedDocument"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_labeled[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 s, sys: 200 ms, total: 10.7 s\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_data = get_document(['./aclImdb/test/pos', './aclImdb/test/neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy(prediction, target):\n",
    "    return 1 - np.mean(np.abs(prediction - target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "x = TaggedDocument(words=labeled_reviews, tags=len(labeled_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 8s, sys: 2.62 s, total: 6min 11s\n",
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "model = Doc2Vec(train_labeled[0] + train_unlabeled[0], size=300, dm=1,\n",
    "                 window=5, min_count=5, workers=4, max_vocab_size=50000, iter=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(w2v, wordlist):\n",
    "    return list(filter(lambda x: x in w2v.vocab.keys(), wordlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 3.83 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.17229879,  0.0175097 , -0.10541873,  0.10327891, -0.01094715,\n",
       "       -0.11901031,  0.05238745,  0.03845617,  0.21301316,  0.05182881,\n",
       "       -0.13010938, -0.08308098, -0.0496176 ,  0.07736664, -0.17075467,\n",
       "        0.17832054,  0.13833727,  0.11140529,  0.06371908, -0.08114829,\n",
       "       -0.06618007,  0.07798573,  0.10603686,  0.1772197 , -0.07093286,\n",
       "        0.10257882, -0.0547631 ,  0.00838977, -0.08903383, -0.18608266,\n",
       "       -0.0112441 , -0.01345374, -0.10663204, -0.16266789, -0.06547717,\n",
       "       -0.01873604, -0.07731603, -0.00793496,  0.05035963, -0.12249844,\n",
       "        0.03971871, -0.10869493, -0.10660531, -0.02105713,  0.01019378,\n",
       "       -0.22608733, -0.00145685, -0.18536724, -0.01317812, -0.01969652,\n",
       "        0.12821956,  0.08013025, -0.1327641 ,  0.06315907, -0.03426347,\n",
       "        0.0205448 ,  0.15984285,  0.04619165, -0.16732842, -0.09575068,\n",
       "       -0.01013592,  0.02931355,  0.06131265, -0.15663613,  0.00650703,\n",
       "        0.22494796, -0.10240985, -0.0072034 , -0.01210339,  0.16137753,\n",
       "        0.08028596, -0.01211029, -0.1097761 , -0.02800397,  0.03728414,\n",
       "        0.12376186, -0.00242142, -0.06669613, -0.09544029, -0.10351692,\n",
       "       -0.01942455, -0.13071243,  0.23351005, -0.08239113,  0.09352272,\n",
       "       -0.01499522,  0.15098952,  0.07129199, -0.00113329, -0.01791005,\n",
       "       -0.07599711,  0.17178817, -0.06420337, -0.00555038,  0.11037968,\n",
       "        0.06455699,  0.03696882, -0.02189688,  0.07456243, -0.08894791,\n",
       "        0.04006839, -0.1760159 , -0.05269261,  0.0368457 ,  0.06178533,\n",
       "        0.05330347, -0.03772894, -0.11312515,  0.06904776,  0.01461531,\n",
       "        0.09761809,  0.07085472,  0.24246345, -0.13418515, -0.10749424,\n",
       "       -0.21658452, -0.02642964, -0.08868569, -0.0171662 , -0.04673383,\n",
       "        0.17349792, -0.15683758,  0.17357041,  0.01906417, -0.07279488,\n",
       "        0.08611108, -0.05665196, -0.05013881, -0.07404733,  0.0798922 ,\n",
       "        0.04676744,  0.03288302, -0.13860001,  0.02547027, -0.00759526,\n",
       "       -0.14830218, -0.15311977,  0.01363995, -0.00998387,  0.06121543,\n",
       "       -0.05209222, -0.02786537,  0.01342612, -0.0013716 , -0.00916369,\n",
       "       -0.02153292,  0.14264683, -0.03244111,  0.01288122,  0.01099398,\n",
       "        0.11215909, -0.09702282,  0.00306506,  0.09485751,  0.07355551,\n",
       "       -0.03351246,  0.01687809, -0.00094526, -0.01640301,  0.01900788,\n",
       "        0.00728329, -0.11601394, -0.11329352, -0.02239992,  0.01951276,\n",
       "       -0.03130225, -0.0645276 ,  0.00389348, -0.09936631,  0.10509597,\n",
       "       -0.0324541 , -0.01075494, -0.04238125, -0.022905  , -0.02992393,\n",
       "        0.09897466, -0.04005127,  0.0320973 ,  0.02799059, -0.03381205,\n",
       "        0.0739205 ,  0.03849012, -0.25737211, -0.07495777, -0.16337338,\n",
       "       -0.07937466,  0.08867875, -0.01827599, -0.05614578,  0.06450618,\n",
       "        0.10460477, -0.10752171, -0.00582227,  0.05966133, -0.19962499,\n",
       "        0.01721567,  0.00391427, -0.01536716,  0.0003962 ,  0.16481368,\n",
       "       -0.00125448,  0.00952576, -0.10728656,  0.00934801,  0.14795245,\n",
       "        0.18126418,  0.08574691, -0.0237142 ,  0.07811796, -0.14713673,\n",
       "       -0.08117256, -0.12081598,  0.00832574,  0.07550766,  0.20058234,\n",
       "       -0.1799414 , -0.09682491,  0.01140684,  0.03490572, -0.05745652,\n",
       "        0.04378524,  0.1533418 ,  0.06730125,  0.00779946,  0.00556477,\n",
       "        0.04832645, -0.08794137, -0.0276164 ,  0.05725087,  0.06972783,\n",
       "       -0.23135197,  0.12718299, -0.068926  , -0.03491251, -0.10326527,\n",
       "       -0.23499481, -0.04762619, -0.03950942, -0.05858084,  0.11054828,\n",
       "        0.04453299, -0.00417559,  0.10373617, -0.07376007,  0.05519772,\n",
       "       -0.10832325,  0.07193395, -0.07689636, -0.10631607,  0.08991507,\n",
       "        0.00884567, -0.02260907,  0.1786776 ,  0.07458013,  0.02011618,\n",
       "        0.03702257,  0.02976329, -0.02072032,  0.01307339,  0.04495371,\n",
       "        0.06771277, -0.06136185,  0.09256645,  0.02891213,  0.01019516,\n",
       "       -0.0285296 , -0.08266929,  0.09885012, -0.09551749, -0.02295644,\n",
       "       -0.0565562 , -0.00504312,  0.08589807, -0.04424159,  0.00933788,\n",
       "        0.16574369,  0.05788449,  0.00646562,  0.09009425,  0.11050357,\n",
       "        0.04055998,  0.0346383 , -0.05240594, -0.17649397, -0.01103095,\n",
       "       -0.05361283, -0.07842377, -0.09347375, -0.05198399, -0.00961643,\n",
       "        0.15677659, -0.01459409,  0.01211875,  0.02431539, -0.00648905,\n",
       "       -0.01123809, -0.07078172,  0.03509117,  0.23001513, -0.04885151], dtype=float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# model.infer_vector(preprocess(model, train_labeled[0][0].words))\n",
    "model.infer_vector(doc_wrods=test_data[0][0].words, alpha=0.1, min_alpha=0.0001, steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_vectors(doc2vec, sentences):\n",
    "    return np.array(list(map(lambda x: doc2vec.infer_vector(x.words), sentences)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min, sys: 0 ns, total: 1min\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_vectors = get_vectors(model, train_labeled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58 s, sys: 8 ms, total: 58 s\n",
      "Wall time: 58.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_vectors = get_vectors(model, test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.5 s, sys: 0 ns, total: 29.5 s\n",
      "Wall time: 29.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "forest.fit(train_vectors, train_labeled[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = forest.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy(prediction, target):\n",
    "    return 1 - np.mean(np.abs(prediction - target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy(prediction, target):\n",
    "    return 1 - np.mean(np.abs(prediction - target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73184000000000005"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(output, test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re \n",
    "from six.moves import xrange\n",
    "import os\n",
    "\n",
    "def get_data(file_dirs, remove_stopwords=False):\n",
    "    label = []\n",
    "    txt = []\n",
    "    comp_re = re.compile('(\\d+)_(\\d+).txt')\n",
    "    for file_dir in file_dirs:\n",
    "        name_list = [x for x in os.listdir(file_dir) if '.txt' in x]\n",
    "        for x in iter(name_list):\n",
    "            f = open(os.path.join(file_dir, x), 'r')\n",
    "            # word_list = review_to_wordlist(f.read(),  remove_stopwords)\n",
    "            # review_text = BeautifulSoup(f.read(), 'lxml').get_text()\n",
    "            # review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "            # txt.append(review_text)\n",
    "            # txt.append(word_list)\n",
    "            txt.append(f.read())\n",
    "            f.close()\n",
    "            obj = comp_re.search(x)\n",
    "            star = float(obj.group(2))\n",
    "            if star > 5:\n",
    "                label.append(1)\n",
    "            else:\n",
    "                label.append(0)\n",
    "    return [txt, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "def review_to_sentences(review, remove_stopwords=False):\n",
    "    review = BeautifulSoup(review, 'lxml').get_text()\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentences) == 0:\n",
    "            continue\n",
    "        sentences.append(review_to_wordlist(raw_sentence, remove_stopwords))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 312 ms, sys: 268 ms, total: 580 ms\n",
      "Wall time: 577 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_unlabeled = get_data(['./aclImdb/train/unsup'], remove_stopwords=False)\n",
    "train_labeled = get_data(['./aclImdb/train/pos', './aclImdb/train/neg'], remove_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sentnces(data):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    ids = []\n",
    "    for idx, x in enumerate(data[0]):\n",
    "        _sentences = review_to_sentences(x)\n",
    "        if len(_sentences) == 0:\n",
    "            continue\n",
    "        sentences += _sentences\n",
    "        labels += [data[1][idx]] * len(_sentences)\n",
    "        ids += [idx]*len(_sentences)\n",
    "    return sentences, labels, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 47s, sys: 888 ms, total: 1min 48s\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "unlabeled_sentences, _, unlabeled_ids = get_sentnces(train_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(539897, 539897, 539897)\n"
     ]
    }
   ],
   "source": [
    "print(len(unlabeled_ids), len(unlabeled_sentences), len(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.2 s, sys: 616 ms, total: 54.9 s\n",
      "Wall time: 54.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "labeled_sentences, labeled_labels, labeled_ids = get_sentnces(train_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = [len(x) for x in labeled_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.774692175294586"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2b0c767c90>]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEACAYAAABPiSrXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2c1c2f82d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sorted(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 10s, sys: 1.66 s, total: 2min 11s\n",
      "Wall time: 44.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "model = Word2Vec(unlabeled_sentences + labeled_sentences, size=100, \n",
    "                 window=5, min_count=5, workers=4, max_vocab_size=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'girl', 0.8241639137268066),\n",
       " (u'lady', 0.7883622646331787),\n",
       " (u'man', 0.775084376335144),\n",
       " (u'prostitute', 0.7727598547935486),\n",
       " (u'widow', 0.7150318622589111),\n",
       " (u'nun', 0.7095363736152649),\n",
       " (u'lad', 0.7027652263641357),\n",
       " (u'person', 0.6869978308677673),\n",
       " (u'housewife', 0.6725583076477051),\n",
       " (u'boy', 0.6619994044303894)]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29494, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = dict([(k, v.index) for k, v in model.vocab.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_list = []\n",
    "for x in labeled_sentences:\n",
    "    word_list += x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 µs, sys: 1 µs, total: 10 µs\n",
      "Wall time: 39.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def word2index(word):\n",
    "    try:\n",
    "        return vocab[word]\n",
    "    except:\n",
    "        return None\n",
    "index = map(word2index, word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x187fefba8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = model.syn0\n",
    "np.save(open(\"embbeding.npy\", 'wb'), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, Input\n",
    "\n",
    "def w2v_embedding_layer(embeddings_path):\n",
    "    weights = np.load(open(embeddings_path, 'rb'))\n",
    "    layer = Embedding(input_dim=weights.shape[0], \n",
    "                      output_dim=weights.shape[1], \n",
    "                      weights=[weights])\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D \n",
    "from keras.layers.core import Flatten, Lambda\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers import SpatialDropout2D\n",
    "from keras.layers import Dropout, Reshape\n",
    "from keras.layers import Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "class CNN(object):\n",
    "    def __init__(self, conf, sentences):\n",
    "        self.model_config = conf.model_config\n",
    "        self.n_emb = conf.n_emb\n",
    "        self.min_word_count = conf.min_word_count\n",
    "        self.n_context = conf.n_context\n",
    "        self.n_workers = 4\n",
    "        self.algo = conf.algo\n",
    "        self.n_epoch = conf.n_epoch\n",
    "        self.batch_size = conf.batch_size\n",
    "        self.maxlen = conf.maxlen\n",
    "        self.learning_rate = conf.learning_rate\n",
    "        \n",
    "        print(\"build word2vec ...\")\n",
    "        self.word2vec = Word2Vec(sentences, workers=self.n_workers, \n",
    "            size=self.n_emb, min_count = self.min_word_count, \n",
    "            window = self.n_context, sg=self.algo)\n",
    "        print(\"finished!\")\n",
    "        \n",
    "        self.vocab = dict([(k, v.index) for k, v in self.word2vec.vocab.items()])\n",
    "        self.n_vocab = len(self.vocab)\n",
    "        index = self.word2indexes(sentences)\n",
    "        \n",
    "        # avoid creating _LEARNING_PHASE outside the network\n",
    "        tf.reset_default_graph()\n",
    "        K.clear_session()\n",
    "        self.sess = tf.Session()\n",
    "        print(\"buiild model ...\")\n",
    "        self.build_model()\n",
    "        print(\"finished\")\n",
    "        \n",
    "    def train(self, input_data, target_data):\n",
    "        print(\"start training\")\n",
    "        index_data = self.word2indexes(input_data)\n",
    "        self.model.fit(index_data, target_data, nb_epoch=self.n_epoch, batch_size=self.batch_size)\n",
    "        print(\"finished\")\n",
    "        \n",
    "    def predict(self, input_data):\n",
    "        index_data = self.word2index(input_data)\n",
    "        return self.model.predict(index_data)\n",
    "    \n",
    "    def word2index(self, sentence):\n",
    "        def w2i(x):\n",
    "            try:\n",
    "                return self.vocab[x]\n",
    "            except:\n",
    "                return None\n",
    "        index = map(w2i, sentence)\n",
    "        index = filter(lambda x: x is not None, index)\n",
    "        return list(index)\n",
    "    \n",
    "    def word2indexes(self, sentences):\n",
    "        index = map(self.word2index, sentences)\n",
    "        return pad_sequences(list(index), maxlen=self.maxlen)\n",
    "    \n",
    "    def build_model(self):\n",
    "        self.input = tf.placeholder(tf.int32, [None, self.maxlen], name=\"input\")\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(input_dim=self.n_vocab, output_dim=self.n_emb, \n",
    "                            input_length=self.maxlen, name=\"embedding\", weights=[self.word2vec.syn0]))\n",
    "        model.add(Reshape([self.maxlen, self.n_emb, 1]))\n",
    "        self.model = self.build_network(self.model_config, model=model)\n",
    "        \n",
    "        self.output = self.model(self.input)\n",
    "        opt = Adam(lr=self.learning_rate)\n",
    "        self.model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['acc'])\n",
    "    \n",
    "    def build_network(self, conf, model=None, input_shape=None, is_conv=True):\n",
    "        \"\"\"Build network\"\"\"\n",
    "        _model = model\n",
    "        model = Sequential()\n",
    "        if _model is None:\n",
    "            model.add(Lambda(lambda x: x,  input_shape=input_shape))\n",
    "        else:\n",
    "            model.add(_model)\n",
    "            \n",
    "        for x in conf:\n",
    "            if x['is_drop']:\n",
    "                model.add(Dropout(x['drop_rate']))\n",
    "                \n",
    "            if x['type'] is 'full':\n",
    "                if is_conv:\n",
    "                    model.add(Flatten())\n",
    "                    is_conv = False\n",
    "                model.add(Dense(x['n_feature']))\n",
    "            elif x['type'] is 'conv':\n",
    "                model.add(Convolution2D(nb_filter=x['n_feature'], \n",
    "                                        nb_row=x['kw'], \n",
    "                                        nb_col=1, \n",
    "                                        border_mode='same'))  \n",
    "                is_conv=True\n",
    "                \n",
    "            if x['is_batch']:\n",
    "                if x['type'] is 'full':\n",
    "                    model.add(BatchNormalization(mode=1, axis=-1))\n",
    "                if x['type'] is 'conv':\n",
    "                    model.add(BatchNormalization(mode=2, axis=-1))\n",
    "            \n",
    "            if x['activation'] is None:\n",
    "                pass\n",
    "            if x['activation'] is 'prelu':\n",
    "                model.add(PReLU())\n",
    "            else:\n",
    "                model.add(Activation(x['activation']))\n",
    "            \n",
    "            if type(x['n_pool']) is int:\n",
    "                model.add(MaxPooling2D(pool_size=(x['n_pool'], 1), border_mode='same'))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    device = '/gpu:0'\n",
    "    save_path = '/home/tomoaki/work/github/jjakimoto.github.io/content'\n",
    "    is_load = False\n",
    "    n_batch = 32\n",
    "    n_epoch = 10\n",
    "    learning_rate = 1e-4\n",
    "    n_emb = 100\n",
    "    min_word_count = 5\n",
    "    n_context = 10\n",
    "    n_worker = 4\n",
    "    algo = 1\n",
    "    batch_size = 256\n",
    "    maxlen = 20\n",
    "    \n",
    "    model_config = [{'type':'conv', 'n_feature': 32, 'kw': 5,\n",
    "                    'activation': 'prelu', 'is_batch': True, 'is_drop': False,\n",
    "                    'n_pool': None},\n",
    "                    {'type':'conv', 'n_feature': 64, 'kw': 5,\n",
    "                    'activation': 'prelu', 'is_batch': True, 'is_drop': False,\n",
    "                    'n_pool': 2},\n",
    "                    {'type':'conv', 'n_feature': 64, 'kw': 5,\n",
    "                     'activation': 'prelu', 'is_batch': True, 'is_drop': False,\n",
    "                    'n_pool': 2},\n",
    "                    {'type':'full', 'n_feature': 32, 'kw': 4,\n",
    "                    'activation': 'prelu', 'is_batch': True, 'is_drop': False,\n",
    "                    'n_pool': None},\n",
    "                    {'type':'full', 'n_feature': 1, 'kw': 4,\n",
    "                     'activation': 'sigmoid', 'is_batch': False, 'is_drop': False,\n",
    "                    'n_pool': None}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build word2vec ...\n",
      "finished!\n",
      "buiild model ...\n",
      "finished\n",
      "start training\n",
      "Epoch 1/10\n",
      "271908/271908 [==============================] - 249s - loss: 0.6145 - acc: 0.6544   \n",
      "Epoch 2/10\n",
      "271908/271908 [==============================] - 249s - loss: 0.5692 - acc: 0.6984   \n",
      "Epoch 3/10\n",
      "271908/271908 [==============================] - 253s - loss: 0.5451 - acc: 0.7179   \n",
      "Epoch 4/10\n",
      "271908/271908 [==============================] - 249s - loss: 0.5216 - acc: 0.7353   \n",
      "Epoch 5/10\n",
      "271908/271908 [==============================] - 251s - loss: 0.4956 - acc: 0.7553   \n",
      "Epoch 6/10\n",
      "271908/271908 [==============================] - 251s - loss: 0.4663 - acc: 0.7751   \n",
      "Epoch 7/10\n",
      "271908/271908 [==============================] - 251s - loss: 0.4335 - acc: 0.7957   \n",
      "Epoch 8/10\n",
      "113408/271908 [===========>..................] - ETA: 145s - loss: 0.3923 - acc: 0.8202"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-189-3718071fec2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# cnn = CNN(conf, labeled_sentences + unlabeled_sentences)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabeled_sentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabeled_sentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabeled_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-175-d03ba3ee1884>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_data, target_data)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"start training\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mindex_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2indexes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"finished\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    619\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m                               sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m   1117\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1118\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1119\u001b[1;33m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[0;32m   1120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[0;32m    835\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 837\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    838\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[0mupdated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 766\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 964\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    965\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1014\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1015\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1022\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1003\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "conf = Config()\n",
    "# cnn = CNN(conf, labeled_sentences + unlabeled_sentences)\n",
    "cnn = CNN(conf, labeled_sentences)\n",
    "cnn.train(labeled_sentences, labeled_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/Users/admin/pokemon/PokemonGo-Bot/src/pgoapi',\n",
       " '/Users/admin/anaconda/lib/python35.zip',\n",
       " '/Users/admin/anaconda/lib/python3.5',\n",
       " '/Users/admin/anaconda/lib/python3.5/plat-darwin',\n",
       " '/Users/admin/anaconda/lib/python3.5/lib-dynload',\n",
       " '/Users/admin/anaconda/lib/python3.5/site-packages',\n",
       " '/Users/admin/anaconda/lib/python3.5/site-packages/Sphinx-1.3.5-py3.5.egg',\n",
       " '/Users/admin/anaconda/lib/python3.5/site-packages/aeosa',\n",
       " '/Users/admin/anaconda/lib/python3.5/site-packages/IPython/extensions',\n",
       " '/Users/admin/.ipython']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PYTHONPATH'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f357497d4da7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PYTHONPATH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpathsep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/admin/anaconda/lib/python3.5/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PYTHONPATH'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTHONPATH'].split(os.pathsep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4], [2, 4, 5, 6]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def f(x):\n",
    "    if x == 2:\n",
    "        return None\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "index = map(f, [[1, 2, 3, 4], [2, 4, 5, 6]])\n",
    "print(list(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = filter(lambda x: x is not None, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [2, 4, 5, 6]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = dict([(k, v.index) for k, v in model.vocab.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4964"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['fury']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = labeled_sentences[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = map(lambda x: vocab[x], sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def w2v(word):\n",
    "    try:\n",
    "        return vocab[word]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = map(w2v, sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 299, 5, 2, 1073, 200]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29494"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.3 s, sys: 7.16 s, total: 35.5 s\n",
      "Wall time: 36.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y = [t**2 for t in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.47 s, sys: 3.68 s, total: 5.14 s\n",
      "Wall time: 5.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y = map(lambda t: t**2, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
