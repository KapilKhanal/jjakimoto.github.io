{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fetch data from http://ai.stanford.edu/~amaas/data/sentiment/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from six.moves import xrange, zip, map, filter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def review2wordlist(review, remove_stopwords=False):\n",
    "    review_text = BeautifulSoup(review, 'lxml').get_text()\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    words = review_text.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re \n",
    "from six.moves import xrange\n",
    "import os\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "def get_document(file_dirs):\n",
    "    documents = []\n",
    "    label=[]\n",
    "    comp_re = re.compile('(\\d+)_(\\d+).txt')\n",
    "    for file_dir in file_dirs:\n",
    "        name_list = [x for x in os.listdir(file_dir) if '.txt' in x]\n",
    "        for x in iter(name_list):\n",
    "            obj = comp_re.search(x)\n",
    "            f = open(os.path.join(file_dir, x), 'r')\n",
    "            # word_list = review_to_wordlist(f.read(),  remove_stopwords)\n",
    "            review_text = BeautifulSoup(f.read(), 'lxml').get_text()\n",
    "            review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "            wordlist = review_text.lower().split()\n",
    "            documents.append(TaggedDocument(words=wordlist, tags=[int(obj.group(1))]))\n",
    "            f.close()\n",
    "            star = float(obj.group(2))\n",
    "            if star > 5:\n",
    "                label.append(1)\n",
    "            else:\n",
    "                label.append(0)\n",
    "    return [documents, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.5 s, sys: 560 ms, total: 22 s\n",
      "Wall time: 22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_unlabeled = get_document(['./aclImdb/train/unsup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 s, sys: 216 ms, total: 10.2 s\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_labeled = get_document(['./aclImdb/train/pos', './aclImdb/train/neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.doc2vec.TaggedDocument"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_labeled[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 s, sys: 200 ms, total: 10.7 s\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_data = get_document(['./aclImdb/test/pos', './aclImdb/test/neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy(prediction, target):\n",
    "    return 1 - np.mean(np.abs(prediction - target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "x = TaggedDocument(words=labeled_reviews, tags=len(labeled_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 8s, sys: 2.62 s, total: 6min 11s\n",
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "model = Doc2Vec(train_labeled[0] + train_unlabeled[0], size=300, dm=1,\n",
    "                 window=5, min_count=5, workers=4, max_vocab_size=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(w2v, wordlist):\n",
    "    return list(filter(lambda x: x in w2v.vocab.keys(), wordlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.17 s, sys: 8 ms, total: 1.18 s\n",
      "Wall time: 1.16 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(u'cum', 0.5036293268203735),\n",
       " (u'whose', 0.4968193769454956),\n",
       " (u'sans', 0.4900319576263428),\n",
       " (u'by', 0.4839792251586914),\n",
       " (u'eg', 0.47736790776252747),\n",
       " (u'ala', 0.47309911251068115),\n",
       " (u'including', 0.44890832901000977),\n",
       " (u'astutely', 0.4465252757072449),\n",
       " (u'esque', 0.44400548934936523),\n",
       " (u'esquire', 0.44280943274497986)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.most_similar(preprocess(model, train_labeled[0][0].words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07071121,  0.13487346, -0.19217843, ..., -0.10901735,\n",
       "        -0.16984639,  0.06387426],\n",
       "       [ 0.04407932,  0.15717666,  0.09058554, ..., -0.05591015,\n",
       "         0.16616131,  0.02360181],\n",
       "       [ 0.17854936,  0.00079916,  0.32049215, ..., -0.04356373,\n",
       "         0.13961183,  0.08961002],\n",
       "       ..., \n",
       "       [-0.12189644, -0.09973729, -0.0278647 , ..., -0.09487402,\n",
       "         0.11301638,  0.08958962],\n",
       "       [ 0.0434482 ,  0.00253062,  0.01874633, ...,  0.04999549,\n",
       "         0.00129158, -0.04417289],\n",
       "       [-0.05025821,  0.1218873 , -0.22856046, ...,  0.06213769,\n",
       "        -0.18127625,  0.02562766]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[preprocess(model, train_labeled[0][0].words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'king', 0.853341281414032),\n",
       " (u'dorff', 0.4814228415489197),\n",
       " (u'rea', 0.4666828215122223),\n",
       " (u'furst', 0.45371681451797485),\n",
       " (u'mcnally', 0.4354397654533386),\n",
       " (u'hawking', 0.4324524402618408),\n",
       " (u'sondheim', 0.4172976613044739),\n",
       " (u'darko', 0.40212035179138184),\n",
       " (u'fry', 0.39135587215423584),\n",
       " (u'depp', 0.3913366198539734)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similar_by_vector(model['king'] - model['man'] + model['woman'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sentence2vec(doc2vec, sentence):\n",
    "    return doc2vec[sentence.word]\n",
    "\n",
    "def get_vectors(doc2vec, sentences):\n",
    "    sentences = map(lambda x: preprocess(doc2vec, x), sentences)\n",
    "    return list(map(lambda x: doc2vec[x.words], sentences))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "u'alecky'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-ed6a1b9e2ba4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu'vectors = get_vectors(model, test_data[0])'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2118\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2119\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2120\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2121\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m             \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-110-838be4752740>\u001b[0m in \u001b[0;36mget_vectors\u001b[1;34m(doc2vec, sentences)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_vectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc2vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# sentences = map(lambda x: preprocess(doc2vec, x), sentences)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdoc2vec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-110-838be4752740>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_vectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc2vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# sentences = map(lambda x: preprocess(doc2vec, x), sentences)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdoc2vec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, words)\u001b[0m\n\u001b[0;32m   1578\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1580\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1582\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: u'alecky'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectors = get_vectors(model, test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'though',\n",
       " u'i',\n",
       " u'saw',\n",
       " u'this',\n",
       " u'movie',\n",
       " u'about',\n",
       " u'years',\n",
       " u'ago',\n",
       " u'long',\n",
       " u'before',\n",
       " u'i',\n",
       " u'started',\n",
       " u'commenting',\n",
       " u'on',\n",
       " u'imdb',\n",
       " u'i',\n",
       " u'decided',\n",
       " u'to',\n",
       " u'review',\n",
       " u'it',\n",
       " u'now',\n",
       " u'which',\n",
       " u'is',\n",
       " u'unusual',\n",
       " u'for',\n",
       " u'me',\n",
       " u'since',\n",
       " u'before',\n",
       " u'now',\n",
       " u'i',\n",
       " u'often',\n",
       " u'reviewed',\n",
       " u'something',\n",
       " u'just',\n",
       " u'after',\n",
       " u'seeing',\n",
       " u'it',\n",
       " u'what',\n",
       " u'can',\n",
       " u'i',\n",
       " u'say',\n",
       " u'well',\n",
       " u'the',\n",
       " u'best',\n",
       " u'performance',\n",
       " u'is',\n",
       " u'that',\n",
       " u'of',\n",
       " u'the',\n",
       " u'late',\n",
       " u'peter',\n",
       " u'boyle',\n",
       " u'as',\n",
       " u'the',\n",
       " u'title',\n",
       " u'character',\n",
       " u'who',\n",
       " u'after',\n",
       " u'finding',\n",
       " u'out',\n",
       " u'about',\n",
       " u'a',\n",
       " u'man',\n",
       " u's',\n",
       " u'killing',\n",
       " u'the',\n",
       " u'drug',\n",
       " u'dealing',\n",
       " u'boyfriend',\n",
       " u'of',\n",
       " u'his',\n",
       " u'daughter',\n",
       " u'wants',\n",
       " u'to',\n",
       " u'bond',\n",
       " u'with',\n",
       " u'him',\n",
       " u'even',\n",
       " u'though',\n",
       " u'he',\n",
       " u's',\n",
       " u'a',\n",
       " u'madison',\n",
       " u'avenue',\n",
       " u'executive',\n",
       " u'who',\n",
       " u'has',\n",
       " u'nothing',\n",
       " u'in',\n",
       " u'common',\n",
       " u'with',\n",
       " u'the',\n",
       " u'very',\n",
       " u'lower',\n",
       " u'class',\n",
       " u'conservative',\n",
       " u'joe',\n",
       " u'in',\n",
       " u'fact',\n",
       " u'there',\n",
       " u'are',\n",
       " u'plenty',\n",
       " u'of',\n",
       " u'funny',\n",
       " u'scenes',\n",
       " u'of',\n",
       " u'joe',\n",
       " u'at',\n",
       " u'this',\n",
       " u'guy',\n",
       " u's',\n",
       " u'party',\n",
       " u'making',\n",
       " u'smart',\n",
       " u'alecky',\n",
       " u'remarks',\n",
       " u'there',\n",
       " u'oh',\n",
       " u'and',\n",
       " u'it',\n",
       " u'should',\n",
       " u'be',\n",
       " u'noted',\n",
       " u'that',\n",
       " u'the',\n",
       " u'actress',\n",
       " u'that',\n",
       " u'plays',\n",
       " u'the',\n",
       " u'daughter',\n",
       " u'who',\n",
       " u'they',\n",
       " u're',\n",
       " u'looking',\n",
       " u'for',\n",
       " u'after',\n",
       " u'she',\n",
       " u'disappeared',\n",
       " u'from',\n",
       " u'the',\n",
       " u'hospital',\n",
       " u'after',\n",
       " u'overdosing',\n",
       " u'on',\n",
       " u'some',\n",
       " u'drugs',\n",
       " u'is',\n",
       " u'none',\n",
       " u'other',\n",
       " u'than',\n",
       " u'susan',\n",
       " u'sarandon',\n",
       " u'making',\n",
       " u'her',\n",
       " u'film',\n",
       " u'debut',\n",
       " u'this',\n",
       " u'was',\n",
       " u'a',\n",
       " u'pretty',\n",
       " u'hard',\n",
       " u'hitting',\n",
       " u'movie',\n",
       " u'for',\n",
       " u'the',\n",
       " u'time',\n",
       " u'it',\n",
       " u'was',\n",
       " u'made',\n",
       " u'late',\n",
       " u's',\n",
       " u'early',\n",
       " u's',\n",
       " u'and',\n",
       " u'was',\n",
       " u'compelling',\n",
       " u'work',\n",
       " u'from',\n",
       " u'scripter',\n",
       " u'norman',\n",
       " u'wexler',\n",
       " u'later',\n",
       " u'of',\n",
       " u'saturday',\n",
       " u'night',\n",
       " u'fever',\n",
       " u'and',\n",
       " u'director',\n",
       " u'john',\n",
       " u'g',\n",
       " u'avildsen',\n",
       " u'later',\n",
       " u'to',\n",
       " u'do',\n",
       " u'save',\n",
       " u'the',\n",
       " u'tiger',\n",
       " u'rocky',\n",
       " u'and',\n",
       " u'the',\n",
       " u'karate',\n",
       " u'kid',\n",
       " u'certainly',\n",
       " u'the',\n",
       " u'ending',\n",
       " u'packs',\n",
       " u'a',\n",
       " u'wallop',\n",
       " u'even',\n",
       " u'today',\n",
       " u'after',\n",
       " u'all',\n",
       " u'these',\n",
       " u'years',\n",
       " u'highly',\n",
       " u'recommended',\n",
       " u'for',\n",
       " u'anyone',\n",
       " u'curious',\n",
       " u'about',\n",
       " u'the',\n",
       " u'counterculture',\n",
       " u'of',\n",
       " u'that',\n",
       " u'time',\n",
       " u'p',\n",
       " u's',\n",
       " u'among',\n",
       " u'the',\n",
       " u'cultural',\n",
       " u'artifacts',\n",
       " u'seen',\n",
       " u'here',\n",
       " u'are',\n",
       " u'a',\n",
       " u'raggedy',\n",
       " u'ann',\n",
       " u'doll',\n",
       " u'a',\n",
       " u'box',\n",
       " u'of',\n",
       " u'ritz',\n",
       " u'crackers',\n",
       " u'a',\n",
       " u'bottle',\n",
       " u'of',\n",
       " u'heinz',\n",
       " u'ketchup',\n",
       " u'and',\n",
       " u'unique',\n",
       " u'for',\n",
       " u'the',\n",
       " u'era',\n",
       " u'a',\n",
       " u'nixon',\n",
       " u'poster',\n",
       " u'asking',\n",
       " u'would',\n",
       " u'you',\n",
       " u'buy',\n",
       " u'a',\n",
       " u'used',\n",
       " u'car',\n",
       " u'from',\n",
       " u'this',\n",
       " u'man']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0].words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_average_vector(word2vec, wordlist):\n",
    "    wordlist = filter(lambda x: x in word2vec.vocab.keys(), wordlist)\n",
    "    vectors = np.array(list(map(lambda x: word2vec[x], wordlist)))\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "def sentences2avgvec(word2vec, sentences):\n",
    "    return np.array(list(map(lambda x: get_average_vector(word2vec, x), sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_average_vec = sentences2avgvec(model, labeled_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test_average_vec = sentences2avgvec(model, test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 300)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_average_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(10, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.49722986,  0.47046173,  0.49448378,  0.55950901,  0.60687917,\n",
       "        0.49080612,  0.50094137,  0.60064372,  0.36042358,  0.69751469])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(x, axis=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'and'"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re \n",
    "from six.moves import xrange\n",
    "import os\n",
    "\n",
    "def get_data(file_dirs, remove_stopwords=False):\n",
    "    label = []\n",
    "    txt = []\n",
    "    comp_re = re.compile('(\\d+)_(\\d+).txt')\n",
    "    for file_dir in file_dirs:\n",
    "        name_list = [x for x in os.listdir(file_dir) if '.txt' in x]\n",
    "        for x in iter(name_list):\n",
    "            f = open(os.path.join(file_dir, x), 'r')\n",
    "            # word_list = review_to_wordlist(f.read(),  remove_stopwords)\n",
    "            # review_text = BeautifulSoup(f.read(), 'lxml').get_text()\n",
    "            # review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "            # txt.append(review_text)\n",
    "            # txt.append(word_list)\n",
    "            txt.append(f.read())\n",
    "            f.close()\n",
    "            obj = comp_re.search(x)\n",
    "            star = float(obj.group(2))\n",
    "            if star > 5:\n",
    "                label.append(1)\n",
    "            else:\n",
    "                label.append(0)\n",
    "    return [txt, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "def review_to_sentences(review, remove_stopwords=False):\n",
    "    review = BeautifulSoup(review, 'lxml').get_text()\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentences) == 0:\n",
    "            continue\n",
    "        sentences.append(review_to_wordlist(raw_sentence, remove_stopwords))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 312 ms, sys: 268 ms, total: 580 ms\n",
      "Wall time: 577 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_unlabeled = get_data(['./aclImdb/train/unsup'], remove_stopwords=False)\n",
    "train_labeled = get_data(['./aclImdb/train/pos', './aclImdb/train/neg'], remove_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sentnces(data):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    ids = []\n",
    "    for idx, x in enumerate(data[0]):\n",
    "        _sentences = review_to_sentences(x)\n",
    "        if len(_sentences) == 0:\n",
    "            continue\n",
    "        sentences += _sentences\n",
    "        labels += [data[1][idx]] * len(_sentences)\n",
    "        ids += [idx]*len(_sentences)\n",
    "    return sentences, labels, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 47s, sys: 888 ms, total: 1min 48s\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "unlabeled_sentences, _, unlabeled_ids = get_sentnces(train_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(539897, 539897, 539897)\n"
     ]
    }
   ],
   "source": [
    "print(len(unlabeled_ids), len(unlabeled_sentences), len(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.2 s, sys: 616 ms, total: 54.9 s\n",
      "Wall time: 54.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "labeled_sentences, labeled_labels, labeled_ids = get_sentnces(train_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = [len(x) for x in labeled_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.774692175294586"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2b0c767c90>]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEACAYAAABPiSrXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFXFJREFUeJzt3X+MXeWd3/H31xhjE4PtQDze2DQmSwA7CiVkY7ZNd3s3\niwiQyCCtRNlGISxt/yjZBG2qFruVYkf7B6HabZM/4l1tNyXOr0VOqgZUpcGxyJDdVfiR8MMEGzOB\n2BgTj2kgJsaAPfjbP84ZfD2eGT8zd+6PmXm/pJHPfe5z7nmeOePzued5zrk3MhNJkkrM6XYDJEnT\nh6EhSSpmaEiSihkakqRihoYkqZihIUkqdsrQiIivRMRgRGxvKlsSEVsjYldE3BsRi5qeWx8RAxGx\nMyKubCq/LCK2R8TTEfHFqe+KJKndSs407gQ+MqJsHbAtMy8C7gPWA0TEauB6YBVwNbApIqJe56+A\nf5OZFwIXRsTI15Qk9bhThkZm/gPw8ojia4HN9fJm4Lp6eS1wV2YOZeZuYABYExHLgLMy8+G63tea\n1pEkTROTndNYmpmDAJm5H1haly8H9jbV21eXLQeebyp/vi6TJE0jUzUR7meRSNIsMHeS6w1GRF9m\nDtZDTwfq8n3AeU31VtRlY5WPKiIMIUmahMyMU9eavNIzjah/ht0D3FQvfxK4u6n8hoiYFxHnAxcA\nD9VDWAcjYk09MX5j0zqjyswZ+7Nhw4aut8G+2T/7N/N+OuGUZxoR8S2gAZwTEc8BG4AvAN+OiJuB\nPVRXTJGZOyJiC7ADOArcksd78ingq8B84HuZ+f2p7Yokqd1OGRqZ+a/HeOqKMerfDtw+SvlPgfdN\nqHWSpJ7iHeFd0Gg0ut2EtpnJfQP7N93N9P51QnRqHGwiIiJ7sV2S1MsiguyRiXBJ0jj+7u/gE5/o\ndivaz9CQpClw7Fj1M9MZGpKkYoaGJKmYoSFJKmZoSJKKGRqSpGKGhiSpmKEhSSpmaEiSihkakqRi\nhoYkqZihIUkqZmhIkooZGpKkYoaGJKmYoSFJKmZoSJKKGRqSpGKGhiSpmKEhSSpmaEiSihkakqRi\nhoYkqZihIUkqZmhIkooZGpKkYoaGJKmYoSFJKmZoSJKKGRqSpGKGhiSpmKEhSSpmaEiSirUUGhHx\nZxHxs4jYHhHfjIh5EbEkIrZGxK6IuDciFjXVXx8RAxGxMyKubL35kqROmnRoRMQ7gU8Dl2XmJcBc\n4I+BdcC2zLwIuA9YX9dfDVwPrAKuBjZFRLTWfElSJ7U6PHUa8LaImAssAPYB1wKb6+c3A9fVy2uB\nuzJzKDN3AwPAmha3L0nqoEmHRma+APwl8BxVWBzMzG1AX2YO1nX2A0vrVZYDe5teYl9dJkmaJuZO\ndsWIWEx1VvEu4CDw7Yj4OJAjqo58XGTjxo1vLTcaDRqNxqTaKUkzVX9/P/39/R3d5qRDA7gCeDYz\nXwKIiP8N/HNgMCL6MnMwIpYBB+r6+4DzmtZfUZeNqjk0JEknG/mG+vOf/3zbt9nKnMZzwO9GxPx6\nQvsPgR3APcBNdZ1PAnfXy/cAN9RXWJ0PXAA81ML2JUkdNukzjcx8KCK+AzwKHK3//RvgLGBLRNwM\n7KG6YorM3BERW6iC5ShwS2ZOauhKknrNbDmaRS8etyPCPJE0rXzjG/D971f/dktEkJltvZXBO8Il\nScUMDUlSMUNDklTM0JAkFTM0JEnFDA1JUjFDQ5JUzNCQJBUzNCRJxQwNSVIxQ0OSVMzQkCQVMzQk\nScUMDUlSMUNDklTM0JAkFTM0JEnFDA1JUjFDQ5JUzNCQJBUzNCRJxQwNSVIxQ0OSVMzQkCQVMzQk\nScUMDUlSMUNDklTM0JAkFTM0JEnFDA1JUjFDQ5JUzNCQJBUzNCRJxQwNSVIxQ0OSVKyl0IiIRRHx\n7YjYGRFPRsTlEbEkIrZGxK6IuDciFjXVXx8RA3X9K1tvviSpk1o90/gS8L3MXAX8U+ApYB2wLTMv\nAu4D1gNExGrgemAVcDWwKSKixe1Lkjpo0qEREWcDv5eZdwJk5lBmHgSuBTbX1TYD19XLa4G76nq7\ngQFgzWS3L0nqvFbONM4H/l9E3BkRj0TE30TEmUBfZg4CZOZ+YGldfzmwt2n9fXWZJGmaaCU05gKX\nAV/OzMuAV6mGpnJEvZGPJUnT1NwW1n0e2JuZP6kf/y+q0BiMiL7MHIyIZcCB+vl9wHlN66+oy0a1\ncePGt5YbjQaNRqOFpkpSe2UX3h739/fT39/f0W1GttDTiLgf+HeZ+XREbADOrJ96KTPviIjbgCWZ\nua6eCP8mcDnVsNQPgPfkKA2IiNGKJalnff3rsHVr9W+3RASZ2dYLjFo50wD4DPDNiDgdeBb4E+A0\nYEtE3AzsobpiiszcERFbgB3AUeAWk0GSppeWQiMzHwc+OMpTV4xR/3bg9la2KUnqHu8IlyQVMzQk\nScUMDUlSMUNDklTM0JAkFTM0JEnFDA1JUjFDQ5JUzNCQJBUzNCRJxQwNSVIxQ0OSVMzQkCQVMzQk\nScUMDUlSMUNDklTM0JAkFTM0JEnFDA1JUjFDQ5JUzNCQJBUzNCRJxQwNSVIxQ0OSVMzQkCQVMzQk\nScUMDUlSMUNDklTM0JAkFTM0JEnFDA1JUjFDQ5JUzNCQJBUzNCRJxQwNSVIxQ0OSVKzl0IiIORHx\nSETcUz9eEhFbI2JXRNwbEYua6q6PiIGI2BkRV7a6bUlSZ03FmcatwI6mx+uAbZl5EXAfsB4gIlYD\n1wOrgKuBTRERU7B9SVKHtBQaEbECuAb426bia4HN9fJm4Lp6eS1wV2YOZeZuYABY08r2JalXZHa7\nBZ3R6pnGfwf+I9D86+rLzEGAzNwPLK3LlwN7m+rtq8skadrLhNkwdjLp0IiIjwKDmfkYMN6vapbk\nr6TZbLaExtwW1v0QsDYirgEWAGdFxNeB/RHRl5mDEbEMOFDX3wec17T+irpsVBs3bnxrudFo0Gg0\nWmiqJLVfp0Ojv7+f/v7+jm4zcgoG4iLiXwL/ITPXRsR/BX6VmXdExG3AksxcV0+EfxO4nGpY6gfA\ne3KUBkTEaMWS1LPuvBPuvx+++tXutSEiyMy2RlcrZxpj+QKwJSJuBvZQXTFFZu6IiC1UV1odBW4x\nGSTNFA5PTUBm3g/cXy+/BFwxRr3bgdunYpuS1GtmQ2h4R7gkTYHZMm5iaEjSFJgtw1OGhiRNEUND\nklTE4SlJUjGHpyRJE2JoSJKKODwlSSrm8JQkaUIMDUlSEYenJEnFHJ6SJBUzNCRJE2JoSJKKOKch\nSSrm8JQkaUIMDUlSEYenJEnFHJ6SJE2IoSFJKuLwlCSpmMNTkqQJMTQkSUUcnpIkFXN4SpI0IYaG\nJKmIw1OSpGIOT0mSihkakqQJMTQkSUWc05AkFXN4SpI0IYaGJKmIw1OSpGIOT0mSJsTQkCQVcXjq\nFCJiRUTcFxFPRsQTEfGZunxJRGyNiF0RcW9ELGpaZ31EDETEzoi4cio6IEm9wOGpUxsCPpuZ7wX+\nGfCpiLgYWAdsy8yLgPuA9QARsRq4HlgFXA1sipgNv2JJs8VsOKJNOjQyc39mPlYvHwJ2AiuAa4HN\ndbXNwHX18lrgrswcyszdwACwZrLbl6Re4vDUBETESuBS4AGgLzMHoQoWYGldbTmwt2m1fXWZJE17\ns2V4am6rLxARC4HvALdm5qGIGJm3k8rfjRs3vrXcaDRoNBqTbaIktd0rr8CCBZ3dZn9/P/39/R3d\nZmQL51QRMRf4P8D/zcwv1WU7gUZmDkbEMuCHmbkqItYBmZl31PW+D2zIzAdHed1spV2S1Gmf+xwc\nPgx/8Rfda0NEkJltPd9pdXjqfwI7hgOjdg9wU738SeDupvIbImJeRJwPXAA81OL2JaknHD0Kb397\nt1vRfpMenoqIDwEfB56IiEephqH+M3AHsCUibgb2UF0xRWbuiIgtwA7gKHCLpxOSZoqjR+H007vd\nivabdGhk5j8Cp43x9BVjrHM7cPtktylJvWq2hIZ3hEvSFDA0JEnFDA1JUrEjRwwNSVKhX/0Khoa6\n3Yr2MzQkaQrMmQNLl5663nRnaEjSFHj5ZXjb27rdivYzNCRpCrz4onMakqQJcHhKklRk3z5YuLDb\nrWg/Q0OSpsCrr8KSJd1uRfsZGpLUotdeq75Pw4lwSdIp7d0L55wzO76EydCQpBb94hfwW7/V7VZ0\nhqEhSS36+c/h3e/udis6w9CQpBbt2AEXXNDtVnSGoSFJLdq+HVat6nYrOqOl7whvF78jXNJ0kVl9\n7tRTT8FFF3W3LdPhO8IlaVb74Q/hjDO6HxidYmhIUgv++q/hj/6o263oHIenJGmSfvMbOPtseOQR\neP/7u90ah6ckqad9+ctw+eW9ERid4pmGJE3CM8/A+94HP/oR/M7vdLs1Fc80JKkHvfgi/P7vw2c/\n2zuB0SmGhiRNwCOPVFdKNRrw53/e7dZ0nqEhSQVefx0+/Wn4wAfg1lvhG9+YHR9QOJKhIUnjePFF\n+Nznqo89f/BBePRR2LBhdgYGGBqSdJLDh+HOO+Gaa6qvcL3/frj7bnjoIbj00m63rru8ekrSrHfo\nEPz0p7B1K2zbVoXDqlVwww3wiU/A+ed3u4VlOnH1lKEhaVb59a+ryezHH69+HngAdu2qvg/jwx+G\nP/gDWLsW3vGObrd04gwNSZqgo0fhlVdgz57qG/Uee6z6d2AAfvzj6vn3vKe6IW/16uqS2csvh3PP\n7XbLW2doSFKToaHquyuOHavOFo4cqW6yO3AA9u2rvkHvhReqSeoFC6pA6OuDiy+uhptWr4aVK6sP\nGJyJDA1JM86RI/Dqq9Xy8MH/6NHq8VNPwcsvH19+6aXqo8cfeKAKgsOH4Z3vhCVLqu/kXrUKTj8d\nLrkE5s+v7tBevLgKhtnI0JDUU/bsqT6kb9gbb1RfQDQ0dLzsZz+rhoeGHThQDQ3Nqa/VfOYZmDev\n+jlyBM477/hXpc6bV12ddNppJy739R2vc+aZs/dy11MxNCSdZGjo+Dv1kfbuheefP7n8yJHq4D78\njn7Ym29Wk8FvvHFi+euvw8MPw9y5x8uOHYPXXquGeJrLli8/8Z39/PnVfMHwgT0C3vteOOus6vGC\nBfCudxV1VRNkaEg9aGDg5INvs9/8Bp58shpWGU1mdaB+7bXRnx8aqm4ga3733mz37mr7Cxac/Nyx\nY/DBD1bv0kd6xztG/x7rxYtH/6rSlSurK4qazZ9fDQepN83I0IiIq4AvUt1Y+JXMvGOUOobGDPPm\nm2MfJJud6oDa7IUXqgPoqRw8CDt3jn0QH7Z/fzWOPt4k6eHD1YHzvPPGrnPsWHVw7usbu87ChdX4\n+1jOPbe6wmc08+aN/ZxmtxkXGhExB3ga+EPgBeBh4IbMfGpEvRkdGv39/TQajZZf59ix6l1vya9q\nx47q4HkqmdUliq+/fuq6hw5V49fN2z90qJ+FCxsn1f3FL6rXnD9//NccGqomOJuHQMYyZ86Jwx7j\n+e3fru7sHU9ENawyXmj8/d/3c9VVjROGbWaSqfrb7FUzvX+dCI1O/+mvAQYycw9ARNwFXAs8Ne5a\nbTY0VI35jmXXruoqjvHWf/zx8V8DqrHmvXvh6af7ufDCxpj1nn0Wnntu9CGGZq+8Ug0tlNyENG8e\nXHZZ2QTi2WeXf9zzTTedOISxaVM/t9zSOKneGWfAhReWvWYv+8lP+vnYxxrdbkbbzPSD6kzvXyd0\nOjSWA3ubHj9PFSSndOxYddXFsF/+snr3Omy8YY1TjTFv314d1OaM8klcmdVk4JpxWplZDSec6qDY\n11fdcfrd78LHPz52vdNPrz5Jc7T2jLR4cW9dSdLXN/6wi6TprWdPsj/2serzX44dqx4fPFgNQ5xz\nzvE6l1xSjQ0PW7hw7A8Tu/FGWLZs9OcWLersdd07dsBHP9q57UnSVOn0nMbvAhsz86r68TogR06G\nR8TMndCQpDaaaRPhpwG7qCbCfwk8BPxxZu7sWCMkSZPW0eGpzHwzIv4U2MrxS24NDEmaJnry5j5J\nUm/qqW/ui4irIuKpiHg6Im7rdnvGExG7I+LxiHg0Ih6qy5ZExNaI2BUR90bEoqb66yNiICJ2RsSV\nTeWXRcT2us9fbCqfFxF31ev8OCL+SZv785WIGIyI7U1lHelPRHyyrr8rIm7sYP82RMTzEfFI/XPV\nNO7fioi4LyKejIgnIuIzdfm034ej9O3TdfmM2H8RcUZEPFgfS56IiA11eW/uu8zsiR+qAPs58C7g\ndOAx4OJut2uc9j4LLBlRdgfwn+rl24Av1MurgUephgNX1v0cPst7EPhgvfw94CP18r8HNtXL/wq4\nq839+RfApcD2TvYHWAI8AywCFg8vd6h/G4DPjlJ31TTs3zLg0np5IdXc4cUzYR+O07eZtP/OrP89\nDXiA6laEntx3vXSm8daNf5l5FBi+8a9XBSefqV0LbK6XNwPX1ctrqXbSUGbuBgaANRGxDDgrMx+u\n632taZ3m1/oO1cUDbZOZ/wC8PKK4nf35cL38EWBrZh7MzF9TzXe99Y5xqozRP6j240jXMv36tz8z\nH6uXDwE7gRXMgH04Rt+W10/PlP13uF48gyoMkh7dd70UGqPd+Ld8jLq9IIEfRMTDEfFv67K+zByE\n6g8dGP7gipF921eXLafq57DmPr+1Tma+Cfw6It7ejo6MY2kb+3Ow7s9Yr9UpfxoRj0XE3zad/k/r\n/kXESqqzqgdo799kx/vY1LcH66IZsf8iYk5EPArsB35QH/h7ct/1UmhMNx/KzMuAa4BPRcTvUQVJ\ns6m8yqAX7vueaf3ZBLw7My+l+s/6l1P42l3pX0QspHoneWv9rnzG/E2O0rcZs/8y81hmvp/q7HBN\nRLyXHt13vRQa+4Dmyd4VdVlPysxf1v++CHyXanhtMCL6AOpTxQN19X1A8+eiDvdtrPIT1onq/paz\nM3OcT8Bqi070p2v7PTNfzHpgF/gfHP9Im2nZv4iYS3VQ/Xpm3l0Xz4h9OFrfZtr+A8jMV4B+qiGi\n3tx3Uz2h08JE0GkcnwifRzURvqrb7RqjrWcCC+vltwH/CFxJNXF1W449cTUPOJ8TJ66GJ72CauLq\nqrr8Fo5PXN1AmyfC6+2sBJ5oetz2/nDiRNzw8uIO9W9Z0/KfAd+a5v37GvDfRpTNiH04Rt9mxP4D\nzqWefAYWAD+iGsHoyX3X1oPQJH55V1FdGTEArOt2e8Zp5/lUofYo8MRwW4G3A9vqPmxt/uUD6+ud\nuxO4sqn8A/VrDABfaio/A9hSlz8ArGxzn75F9XH1bwDPAX9S/xG1vT/ATXX508CNHezf14Dt9b78\nLtUY8nTt34eAN5v+Lh+p/z915G+ynX0cp28zYv8B76v79Fjdn/9Sl/fkvvPmPklSsV6a05Ak9ThD\nQ5JUzNCQJBUzNCRJxQwNSVIxQ0OSVMzQkCQVMzQkScX+P2HxXCjQyDGOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2c1c2f82d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sorted(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 10s, sys: 1.66 s, total: 2min 11s\n",
      "Wall time: 44.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "model = Word2Vec(unlabeled_sentences + labeled_sentences, size=100, \n",
    "                 window=5, min_count=5, workers=4, max_vocab_size=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'girl', 0.8241639137268066),\n",
       " (u'lady', 0.7883622646331787),\n",
       " (u'man', 0.775084376335144),\n",
       " (u'prostitute', 0.7727598547935486),\n",
       " (u'widow', 0.7150318622589111),\n",
       " (u'nun', 0.7095363736152649),\n",
       " (u'lad', 0.7027652263641357),\n",
       " (u'person', 0.6869978308677673),\n",
       " (u'housewife', 0.6725583076477051),\n",
       " (u'boy', 0.6619994044303894)]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29494, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = dict([(k, v.index) for k, v in model.vocab.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_list = []\n",
    "for x in labeled_sentences:\n",
    "    word_list += x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 µs, sys: 1 µs, total: 10 µs\n",
      "Wall time: 39.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def word2index(word):\n",
    "    try:\n",
    "        return vocab[word]\n",
    "    except:\n",
    "        return None\n",
    "index = map(word2index, word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x187fefba8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = model.syn0\n",
    "np.save(open(\"embbeding.npy\", 'wb'), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, Input\n",
    "\n",
    "def w2v_embedding_layer(embeddings_path):\n",
    "    weights = np.load(open(embeddings_path, 'rb'))\n",
    "    layer = Embedding(input_dim=weights.shape[0], \n",
    "                      output_dim=weights.shape[1], \n",
    "                      weights=[weights])\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D \n",
    "from keras.layers.core import Flatten, Lambda\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers import SpatialDropout2D\n",
    "from keras.layers import Dropout, Reshape\n",
    "from keras.layers import Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "class CNN(object):\n",
    "    def __init__(self, conf, sentences):\n",
    "        self.model_config = conf.model_config\n",
    "        self.n_emb = conf.n_emb\n",
    "        self.min_word_count = conf.min_word_count\n",
    "        self.n_context = conf.n_context\n",
    "        self.n_workers = 4\n",
    "        self.algo = conf.algo\n",
    "        self.n_epoch = conf.n_epoch\n",
    "        self.batch_size = conf.batch_size\n",
    "        self.maxlen = conf.maxlen\n",
    "        self.learning_rate = conf.learning_rate\n",
    "        \n",
    "        print(\"build word2vec ...\")\n",
    "        self.word2vec = Word2Vec(sentences, workers=self.n_workers, \n",
    "            size=self.n_emb, min_count = self.min_word_count, \n",
    "            window = self.n_context, sg=self.algo)\n",
    "        print(\"finished!\")\n",
    "        \n",
    "        self.vocab = dict([(k, v.index) for k, v in self.word2vec.vocab.items()])\n",
    "        self.n_vocab = len(self.vocab)\n",
    "        index = self.word2indexes(sentences)\n",
    "        \n",
    "        # avoid creating _LEARNING_PHASE outside the network\n",
    "        tf.reset_default_graph()\n",
    "        K.clear_session()\n",
    "        self.sess = tf.Session()\n",
    "        print(\"buiild model ...\")\n",
    "        self.build_model()\n",
    "        print(\"finished\")\n",
    "        \n",
    "    def train(self, input_data, target_data):\n",
    "        print(\"start training\")\n",
    "        index_data = self.word2indexes(input_data)\n",
    "        self.model.fit(index_data, target_data, nb_epoch=self.n_epoch, batch_size=self.batch_size)\n",
    "        print(\"finished\")\n",
    "        \n",
    "    def predict(self, input_data):\n",
    "        index_data = self.word2index(input_data)\n",
    "        return self.model.predict(index_data)\n",
    "    \n",
    "    def word2index(self, sentence):\n",
    "        def w2i(x):\n",
    "            try:\n",
    "                return self.vocab[x]\n",
    "            except:\n",
    "                return None\n",
    "        index = map(w2i, sentence)\n",
    "        index = filter(lambda x: x is not None, index)\n",
    "        return list(index)\n",
    "    \n",
    "    def word2indexes(self, sentences):\n",
    "        index = map(self.word2index, sentences)\n",
    "        return pad_sequences(list(index), maxlen=self.maxlen)\n",
    "    \n",
    "    def build_model(self):\n",
    "        self.input = tf.placeholder(tf.int32, [None, self.maxlen], name=\"input\")\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(input_dim=self.n_vocab, output_dim=self.n_emb, \n",
    "                            input_length=self.maxlen, name=\"embedding\", weights=[self.word2vec.syn0]))\n",
    "        model.add(Reshape([self.maxlen, self.n_emb, 1]))\n",
    "        self.model = self.build_network(self.model_config, model=model)\n",
    "        \n",
    "        self.output = self.model(self.input)\n",
    "        opt = Adam(lr=self.learning_rate)\n",
    "        self.model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['acc'])\n",
    "    \n",
    "    def build_network(self, conf, model=None, input_shape=None, is_conv=True):\n",
    "        \"\"\"Build network\"\"\"\n",
    "        _model = model\n",
    "        model = Sequential()\n",
    "        if _model is None:\n",
    "            model.add(Lambda(lambda x: x,  input_shape=input_shape))\n",
    "        else:\n",
    "            model.add(_model)\n",
    "            \n",
    "        for x in conf:\n",
    "            if x['is_drop']:\n",
    "                model.add(Dropout(x['drop_rate']))\n",
    "                \n",
    "            if x['type'] is 'full':\n",
    "                if is_conv:\n",
    "                    model.add(Flatten())\n",
    "                    is_conv = False\n",
    "                model.add(Dense(x['n_feature']))\n",
    "            elif x['type'] is 'conv':\n",
    "                model.add(Convolution2D(nb_filter=x['n_feature'], \n",
    "                                        nb_row=x['kw'], \n",
    "                                        nb_col=1, \n",
    "                                        border_mode='same'))  \n",
    "                is_conv=True\n",
    "                \n",
    "            if x['is_batch']:\n",
    "                if x['type'] is 'full':\n",
    "                    model.add(BatchNormalization(mode=1, axis=-1))\n",
    "                if x['type'] is 'conv':\n",
    "                    model.add(BatchNormalization(mode=2, axis=-1))\n",
    "            \n",
    "            if x['activation'] is None:\n",
    "                pass\n",
    "            if x['activation'] is 'prelu':\n",
    "                model.add(PReLU())\n",
    "            else:\n",
    "                model.add(Activation(x['activation']))\n",
    "            \n",
    "            if type(x['n_pool']) is int:\n",
    "                model.add(MaxPooling2D(pool_size=(x['n_pool'], 1), border_mode='same'))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    device = '/gpu:0'\n",
    "    save_path = '/home/tomoaki/work/github/jjakimoto.github.io/content'\n",
    "    is_load = False\n",
    "    n_batch = 32\n",
    "    n_epoch = 10\n",
    "    learning_rate = 1e-4\n",
    "    n_emb = 100\n",
    "    min_word_count = 5\n",
    "    n_context = 10\n",
    "    n_worker = 4\n",
    "    algo = 1\n",
    "    batch_size = 256\n",
    "    maxlen = 20\n",
    "    \n",
    "    model_config = [{'type':'conv', 'n_feature': 32, 'kw': 5,\n",
    "                    'activation': 'prelu', 'is_batch': True, 'is_drop': False,\n",
    "                    'n_pool': None},\n",
    "                    {'type':'conv', 'n_feature': 64, 'kw': 5,\n",
    "                    'activation': 'prelu', 'is_batch': True, 'is_drop': False,\n",
    "                    'n_pool': 2},\n",
    "                    {'type':'conv', 'n_feature': 64, 'kw': 5,\n",
    "                     'activation': 'prelu', 'is_batch': True, 'is_drop': False,\n",
    "                    'n_pool': 2},\n",
    "                    {'type':'full', 'n_feature': 32, 'kw': 4,\n",
    "                    'activation': 'prelu', 'is_batch': True, 'is_drop': False,\n",
    "                    'n_pool': None},\n",
    "                    {'type':'full', 'n_feature': 1, 'kw': 4,\n",
    "                     'activation': 'sigmoid', 'is_batch': False, 'is_drop': False,\n",
    "                    'n_pool': None}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build word2vec ...\n",
      "finished!\n",
      "buiild model ...\n",
      "finished\n",
      "start training\n",
      "Epoch 1/10\n",
      "271908/271908 [==============================] - 249s - loss: 0.6145 - acc: 0.6544   \n",
      "Epoch 2/10\n",
      "271908/271908 [==============================] - 249s - loss: 0.5692 - acc: 0.6984   \n",
      "Epoch 3/10\n",
      "271908/271908 [==============================] - 253s - loss: 0.5451 - acc: 0.7179   \n",
      "Epoch 4/10\n",
      "271908/271908 [==============================] - 249s - loss: 0.5216 - acc: 0.7353   \n",
      "Epoch 5/10\n",
      "271908/271908 [==============================] - 251s - loss: 0.4956 - acc: 0.7553   \n",
      "Epoch 6/10\n",
      "271908/271908 [==============================] - 251s - loss: 0.4663 - acc: 0.7751   \n",
      "Epoch 7/10\n",
      "271908/271908 [==============================] - 251s - loss: 0.4335 - acc: 0.7957   \n",
      "Epoch 8/10\n",
      "113408/271908 [===========>..................] - ETA: 145s - loss: 0.3923 - acc: 0.8202"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-189-3718071fec2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# cnn = CNN(conf, labeled_sentences + unlabeled_sentences)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabeled_sentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabeled_sentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabeled_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-175-d03ba3ee1884>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_data, target_data)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"start training\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mindex_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2indexes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"finished\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    619\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m                               sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m   1117\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1118\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1119\u001b[1;33m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[0;32m   1120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[0;32m    835\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 837\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    838\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[0mupdated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 766\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 964\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    965\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1014\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1015\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1022\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/tomoaki/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1003\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "conf = Config()\n",
    "# cnn = CNN(conf, labeled_sentences + unlabeled_sentences)\n",
    "cnn = CNN(conf, labeled_sentences)\n",
    "cnn.train(labeled_sentences, labeled_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/Users/admin/pokemon/PokemonGo-Bot/src/pgoapi',\n",
       " '/Users/admin/anaconda/lib/python35.zip',\n",
       " '/Users/admin/anaconda/lib/python3.5',\n",
       " '/Users/admin/anaconda/lib/python3.5/plat-darwin',\n",
       " '/Users/admin/anaconda/lib/python3.5/lib-dynload',\n",
       " '/Users/admin/anaconda/lib/python3.5/site-packages',\n",
       " '/Users/admin/anaconda/lib/python3.5/site-packages/Sphinx-1.3.5-py3.5.egg',\n",
       " '/Users/admin/anaconda/lib/python3.5/site-packages/aeosa',\n",
       " '/Users/admin/anaconda/lib/python3.5/site-packages/IPython/extensions',\n",
       " '/Users/admin/.ipython']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PYTHONPATH'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f357497d4da7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PYTHONPATH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpathsep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/admin/anaconda/lib/python3.5/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'PYTHONPATH'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTHONPATH'].split(os.pathsep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 4], [2, 4, 5, 6]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def f(x):\n",
    "    if x == 2:\n",
    "        return None\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "index = map(f, [[1, 2, 3, 4], [2, 4, 5, 6]])\n",
    "print(list(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = filter(lambda x: x is not None, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [2, 4, 5, 6]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = dict([(k, v.index) for k, v in model.vocab.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4964"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['fury']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = labeled_sentences[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = map(lambda x: vocab[x], sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def w2v(word):\n",
    "    try:\n",
    "        return vocab[word]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = map(w2v, sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 299, 5, 2, 1073, 200]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29494"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.3 s, sys: 7.16 s, total: 35.5 s\n",
      "Wall time: 36.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y = [t**2 for t in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.47 s, sys: 3.68 s, total: 5.14 s\n",
      "Wall time: 5.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y = map(lambda t: t**2, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
