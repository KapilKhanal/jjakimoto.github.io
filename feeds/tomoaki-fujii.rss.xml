<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Data Rounder - Tomoaki Fujii</title><link>http://jjakimoto.github.io/</link><description>Machine Learning, Finance, and Technologies</description><lastBuildDate>Fri, 22 Jun 2018 12:00:00 -0400</lastBuildDate><item><title>Toward Understanding Blockchain</title><link>http://jjakimoto.github.io/articles/2018/Jun/22/blockchain/</link><description>&lt;p&gt;Blockchain is one of the hottest technologies as well as AI/Machine Learning. Indeed,
a lot of startup are working in this fields. Besides that compared to another hot topic, Deep Learning, Blockchain is 
still in early stage and there is space you can get in &lt;a href="https://medium.freecodecamp.org/the-authoritative-guide-to-blockchain-development-855ab65b58bc"&gt;[1]&lt;/a&gt;.
I know that …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tomoaki Fujii</dc:creator><pubDate>Fri, 22 Jun 2018 12:00:00 -0400</pubDate><guid isPermaLink="false">tag:jjakimoto.github.io,2018-06-22:/articles/2018/Jun/22/blockchain/</guid><category>Blockchain</category></item><item><title>Bayesian Optimization of Hyperparameters with Python</title><link>http://jjakimoto.github.io/articles/2018/Mar/11/bayes_opt/</link><description>&lt;p&gt;Choosing a good set of hyperparameters is one of most important steps but also pretty much annoying and time consuming. The small number of hyperparameters may allow you to find an optimal hyperparameters after a few trials. This is, however, not the case for complex models like neural network.&lt;/p&gt;
&lt;p&gt;Indeed …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tomoaki Fujii</dc:creator><pubDate>Sun, 11 Mar 2018 12:00:00 -0400</pubDate><guid isPermaLink="false">tag:jjakimoto.github.io,2018-03-11:/articles/2018/Mar/11/bayes_opt/</guid><category>AutoML</category></item><item><title>Start Your Data Science Blog by Pelican</title><link>http://jjakimoto.github.io/articles/2018/Mar/01/start_blog/</link><description>&lt;p&gt;Blogging is one of the fantastic ways to demonstrate your projects and help you understand stuff in more depth. Especially, I believe that blogging helps you land a job more efficiently. Even if you are not looking for a new position, writing articles you are working on would be the …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tomoaki Fujii</dc:creator><pubDate>Thu, 01 Mar 2018 12:00:00 -0500</pubDate><guid isPermaLink="false">tag:jjakimoto.github.io,2018-03-01:/articles/2018/Mar/01/start_blog/</guid><category>Blog</category></item><item><title>Bootstrap and Backtest for Algorithmic Trading (Reality Check)</title><link>http://jjakimoto.github.io/articles/2017/Oct/26/RC/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Applying machine learning to algorithmic trading is getting more and more attention recently. Machine learning approach usually takes the following steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Build models&lt;/li&gt;
&lt;li&gt;Optimize model parameters&lt;/li&gt;
&lt;li&gt;Model selection or hyper parameters tuning&lt;/li&gt;
&lt;li&gt;Evaluate performances&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In the first and second stage, we build models and optimize their parameters on given data. Next, we evaluate several models' performances with their various hyperparameter configurations on out of samples. Then, we pick up the best performance one.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tomoaki Fujii</dc:creator><pubDate>Thu, 26 Oct 2017 12:00:00 -0400</pubDate><guid isPermaLink="false">tag:jjakimoto.github.io,2017-10-26:/articles/2017/Oct/26/RC/</guid><category>Hypothesis Test</category><category>Backtest</category></item><item><title>Data Explore and Visualization</title><link>http://jjakimoto.github.io/articles/2017/Mar/26/house_price/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Data exploration is important. Before jumping into analysis, you will get some intuition as to how to use data and establish more sophisticated modeling. In some cases, how to use data improve even models robust to high dimensional input like Deep Learning. In this article, we work on data exploration and visualization for the house price data from &lt;a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data"&gt;a kaggle competition&lt;/a&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tomoaki Fujii</dc:creator><pubDate>Sun, 26 Mar 2017 12:00:00 -0400</pubDate><guid isPermaLink="false">tag:jjakimoto.github.io,2017-03-26:/articles/2017/Mar/26/house_price/</guid><category>Feature Selection</category></item><item><title>Feature Selection and Random Forests</title><link>http://jjakimoto.github.io/articles/2017/Jan/28/RF/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In prediction tasks, given data does not necessary consist of only useful information. The data may contain irrelevant features, which impairs the performance of a predictor due to overfitting. This situation is often the case for medical data. Sometimes, only a few hundreds of samples are available while we have thousands of features. In this case, we have to extract a small subset of effective features to reduce computational costs and overfitting. Random forest is one of the popular predictors due to the robustness. As one of the useful byproducts, random forests are able to estimate how much each feature has an effect on a performance of the forests. Thus, random forests give us one of possible approaches to reduce the number features to use. In this article, we work on a binary classification task of &lt;a href="https://archive.ics.uci.edu/ml/datasets/Dorothea"&gt;“Dorothea Data Set” from UCI Machine Learning Repository&lt;/a&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tomoaki Fujii</dc:creator><pubDate>Sat, 28 Jan 2017 12:00:00 -0500</pubDate><guid isPermaLink="false">tag:jjakimoto.github.io,2017-01-28:/articles/2017/Jan/28/RF/</guid><category>Classification</category><category>NLP</category></item><item><title>Movie Review with Vector Representations</title><link>http://jjakimoto.github.io/articles/2017/Jan/13/movie/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Majority of data is expressed as text format such as news articles, SNS and speech. Each article has some meanings and opinions, which have significant effects on things around us like economics, politics, etc. Therefore, using these information for prediction systems is important. Most of prediction algorithms, however, take input in the form of tensor (1st-order tensor is vector), which requires us to represent text data in the tensor(vector) form. In this article, we review popular three vector representation: Bag or Words, Word2Vec, and Doc2Vec. Then, we compare these qualities through sentiment analysis for movie reviews of &lt;a href="http://ai.stanford.edu/~amaas/data/sentiment"&gt;IMDb&lt;/a&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tomoaki Fujii</dc:creator><pubDate>Fri, 13 Jan 2017 12:00:00 -0500</pubDate><guid isPermaLink="false">tag:jjakimoto.github.io,2017-01-13:/articles/2017/Jan/13/movie/</guid><category>NLP</category></item><item><title>Reinforcement Learning for Stock Trading</title><link>http://jjakimoto.github.io/articles/2017/Jan/07/RL_trade/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Reinforcement learning has recently been succeeded to go over the human's ability in video games and Go. This implies possiblities to beat human's performance in other fields where human is doing well. Stock trading can be one of such fields. Some professional  In this article, we consider application of reinforcement learning to stock trading. Especially, we work on constructing a portoflio to make profit. Since portfolio can take inifinite number, we tackle this task based on Deep Deterministic Policy Gradient (DDPG). The behavior of stock prices is konwn to depend on history and several time scales, which leads us to use multiscale CNN for Q and actor network. We show that our algorithm has better performance than monkey trading(taking actions at random).&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tomoaki Fujii</dc:creator><pubDate>Sat, 07 Jan 2017 12:00:00 -0500</pubDate><guid isPermaLink="false">tag:jjakimoto.github.io,2017-01-07:/articles/2017/Jan/07/RL_trade/</guid><category>Reinforcement Learning</category><category>Trading</category></item><item><title>Duplication of S&amp;P500 with Stock Prices</title><link>http://jjakimoto.github.io/articles/2016/Dec/31/sp500/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Economic indicators are statistics to measure growth and contraction of economics. Trading based on such indicators, what is called technical trading, is one of the main trends in recent stock trading. Especially S&amp;P500;(Standard and Poor's 500 Index) is frequently used as a bench mark to evaluate portfolio -- a grouping of financial assets like stocks. Roughly speaking, constructing a portfolio with better return and lower risk than S&amp;P500; is one of the main goals for stock trading. Therefore, clarifying the relation between S&amp;P500; and stock prices are important to construct a good portfolio.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tomoaki Fujii</dc:creator><pubDate>Sat, 31 Dec 2016 12:00:00 -0500</pubDate><guid isPermaLink="false">tag:jjakimoto.github.io,2016-12-31:/articles/2016/Dec/31/sp500/</guid><category>Regression</category><category>SP500</category></item></channel></rss>