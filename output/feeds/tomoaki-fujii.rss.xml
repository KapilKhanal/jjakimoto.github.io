<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Data Rounder - Tomoaki Fujii</title><link>http://jjakimoto.github.io/</link><description>Machine Learning and Programming</description><lastBuildDate>Sun, 26 Mar 2017 12:00:00 +0900</lastBuildDate><item><title>Data Explore and Visualization</title><link>http://jjakimoto.github.io/articles/2017/Mar/26/house_price/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Data exploration is important. Before jumping into analysis, you will get some intuition as to how to use data and establish more sophisticated modeling. In some cases, how to use data improve even models robust to high dimensional input like Deep Learning. In this article, we work on data exploration and visualization for the house price data from &lt;a href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data"&gt;a kaggle competition&lt;/a&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tomoaki Fujii</dc:creator><pubDate>Sun, 26 Mar 2017 12:00:00 +0900</pubDate><guid isPermaLink="false">tag:jjakimoto.github.io,2017-03-26:/articles/2017/Mar/26/house_price/</guid><category>Feature Selection</category></item><item><title>Feature Selection and Random Forests</title><link>http://jjakimoto.github.io/articles/2017/Jan/28/RF/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In prediction tasks, given data does not necessary consist of only useful information. The data may contain irrelevant features, which impairs the performance of a predictor due to overfitting. This situation is often the case for medical data. Sometimes, only a few hundreds of samples are available while we have thousands of features. In this case, we have to extract a small subset of effective features to reduce computational costs and overfitting. Random forest is one of the popular predictors due to the robustness. As one of the useful byproducts, random forests are able to estimate how much each feature has an effect on a performance of the forests. Thus, random forests give us one of possible approaches to reduce the number features to use. In this article, we work on a binary classification task of &lt;a href="https://archive.ics.uci.edu/ml/datasets/Dorothea"&gt;“Dorothea Data Set” from UCI Machine Learning Repository&lt;/a&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tomoaki Fujii</dc:creator><pubDate>Sat, 28 Jan 2017 12:00:00 +0900</pubDate><guid isPermaLink="false">tag:jjakimoto.github.io,2017-01-28:/articles/2017/Jan/28/RF/</guid><category>Classification</category></item><item><title>Movie Review with Vector Representations</title><link>http://jjakimoto.github.io/articles/2017/Jan/13/movie/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Majority of data is expressed as text format such as news articles, SNS and speech. Each article has some meanings and opinions, which have significant effects on things around us like economics, politics, etc. Therefore, using these information for prediction systems is important. Most of prediction algorithms, however, take input in the form of tensor (1st-order tensor is vector), which requires us to represent text data in the tensor(vector) form. In this article, we review popular three vector representation: Bag or Words, Word2Vec, and Doc2Vec. Then, we compare these qualities through sentiment analysis for movie reviews of &lt;a href="http://ai.stanford.edu/~amaas/data/sentiment"&gt;IMDb&lt;/a&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tomoaki Fujii</dc:creator><pubDate>Fri, 13 Jan 2017 12:00:00 +0900</pubDate><guid isPermaLink="false">tag:jjakimoto.github.io,2017-01-13:/articles/2017/Jan/13/movie/</guid><category>NLP</category></item><item><title>Reinforcement Learning for Stock Trading</title><link>http://jjakimoto.github.io/articles/2017/Jan/07/RL_trade/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Reinforcement learning has recently been succeeded to go over the human's ability in video games and Go. This implies possiblities to beat human's performance in other fields where human is doing well. Stock trading can be one of such fields. Some professional  In this article, we consider application of reinforcement learning to stock trading. Especially, we work on constructing a portoflio to make profit. Since portfolio can take inifinite number, we tackle this task based on Deep Deterministic Policy Gradient (DDPG). The behavior of stock prices is konwn to depend on history and several time scales, which leads us to use multiscale CNN for Q and actor network. We show that our algorithm has better performance than monkey trading(taking actions at random).&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tomoaki Fujii</dc:creator><pubDate>Sat, 07 Jan 2017 12:00:00 +0900</pubDate><guid isPermaLink="false">tag:jjakimoto.github.io,2017-01-07:/articles/2017/Jan/07/RL_trade/</guid><category>Reinforcement Learning</category></item><item><title>Duplication of S&amp;P500 with Stock Prices</title><link>http://jjakimoto.github.io/articles/2016/Dec/31/sp500/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Economic indicators are statistics to measure growth and contraction of economics. Trading based on such indicators, what is called technical trading, is one of the main trends in recent stock trading. Especially S&amp;P500;(Standard and Poor's 500 Index) is frequently used as a bench mark to evaluate portfolio -- a grouping of financial assets like stocks. Roughly speaking, constructing a portfolio with better return and lower risk than S&amp;P500; is one of the main goals for stock trading. Therefore, clarifying the relation between S&amp;P500; and stock prices are important to construct a good portfolio.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Tomoaki Fujii</dc:creator><pubDate>Sat, 31 Dec 2016 12:00:00 +0900</pubDate><guid isPermaLink="false">tag:jjakimoto.github.io,2016-12-31:/articles/2016/Dec/31/sp500/</guid><category>Regresion</category></item></channel></rss>